# JP+ Power Ratings Model - Architecture & Documentation

**Last Updated:** February 10, 2026 (auto-generated by generate_docs.py)

## Overview

**JP+** is a College Football power ratings model designed for sports betting analysis, inspired by Bill Connelly's SP+. The model generates predicted point spreads for games and compares them against Vegas lines to identify betting opportunities.

### Goals
- Predict game margins with low Mean Absolute Error (MAE)
- Achieve >52% win rate Against The Spread (ATS) for profitable betting
- Identify high-confidence plays where model disagrees significantly with Vegas

---

## Backtest Performance (2022-2025)

Walk-forward backtest across 4 seasons covering the full CFB calendar (3,273 games). Model trained on data available at prediction time â€” no future leakage.

*All metrics verified 2026-02-10.*

### Understanding the Metrics

- **MAE (Mean Absolute Error):** Average points off from actual margin. Vegas closing lines typically have MAE ~11-12 vs actuals â€” college football is inherently unpredictable.
- **RMSE (Root Mean Squared Error):** Like MAE but penalizes large misses more. RMSE > MAE indicates occasional blowout misses; the gap shows tail risk.
- **ATS (Against The Spread):** Win rate vs Vegas spread. 52.4%+ is profitable at -110 odds.
- **CLV (Closing Line Value):** How the market moves after we identify an edge. Positive CLV = sharp money agrees with us. Gold standard for real edge.

### Performance by Season Phase

| Phase | Weeks | Games | MAE | RMSE | ATS % (Close) | ATS % (Open) | 3+ Edge (Close) | 5+ Edge (Close) | 5+ Edge (Open) |
|-------|-------|-------|-----|------|---------------|--------------|-----------------|-----------------|----------------|
| Calibration | 1-3 | 608 | 14.77 | 18.61 | 47.1% | 48.6% | 47.6% | 48.6% | 49.8% |
| **Core** | **4-15** | **2,489** | **12.50** | **15.82** | **52.2%** | **53.5%** | **54.0%** | **54.7%** | **57.8%** |
| Postseason | 16+ | 176 | 13.41 | 16.82 | 47.4% | 48.3% | 46.7% | 46.7% | 46.8% |
| **Full Season** | All | 3,273 | 12.97 | 16.43 | 51.0% | 52.3% | 52.2% | 52.7% | 55.2% |

**Phase insights:**
- **Calibration (Weeks 1-3)**: Model relies heavily on preseason priors; ATS underperforms until in-season data accumulates
- **Core (Weeks 4-15)**: Profitable zone â€” 54.7% ATS at 5+ edge vs closing, 57.8% vs opening
- **Postseason (Weeks 16+)**: Bowl games struggle due to unmodeled factors: player opt-outs, motivation variance, 3-4 week layoffs

### Core Season Detail (Weeks 4-15)

The Core phase is where the model is profitable. Detailed breakdowns below focus on this 2,489-game sample.

#### Against The Spread (ATS)

| Edge Filter | vs Closing Line | vs Opening Line |
|-------------|-----------------|-----------------|
| **All picks** | 1272-1165 (52.2%) | 1311-1139 (53.5%) |
| **3+ pt edge** | 764-650 (54.0%) | 810-648 (55.6%) |
| **5+ pt edge** | 473-391 (54.7%) | 525-384 (57.8%) |

Opening line performance exceeds closing line by ~2%, indicating the model captures value that the market prices out by game time.

#### ATS by Season (Core, vs Closing Line)

| Year | Games | ATS % | 3+ Edge | 5+ Edge |
|------|-------|-------|---------|---------|
| 2022 | 605 | 53.2% | 188-172 (52.2%) | 117-105 (52.7%) |
| 2023 | 611 | 52.5% | 203-165 (55.2%) | 124-101 (55.1%) |
| 2024 | 631 | 50.4% | 193-167 (53.6%) | 124-101 (55.1%) |
| 2025 | 638 | 52.7% | 180-146 (55.2%) | 108-84 (56.2%) |

2024 was the weakest overall ATS year, but the Core 5+ edge still hit 55.1%. The edge concentrates in high-conviction plays regardless of year.

#### ATS by Season (Core, vs Opening Line)

| Year | Games | ATS % | 3+ Edge | 5+ Edge |
|------|-------|-------|---------|---------|
| 2022 | 605 | 52.6% | 192-160 (54.5%) | 118-100 (54.1%) |
| 2023 | 611 | 54.8% | 202-158 (56.1%) | 132-97 (57.6%) |
| 2024 | 631 | 52.0% | 200-173 (53.6%) | 144-101 (58.8%) |
| 2025 | 638 | 53.7% | 197-151 (56.6%) | 115-84 (57.8%) |

#### Closing Line Value (CLV)

CLV measures how the market moves after we identify an edge. Positive CLV = sharp money agrees with us.

**Full Season (Weeks 1+, 3,258 games with lines):**

| Edge Filter | N | Mean CLV | CLV > 0 | ATS % (Close) |
|-------------|---|----------|---------|---------------|
| All picks | 3,258 | -0.32 | 29.0% | 51.1% |
| 3+ pt edge | 1,997 | -0.43 | 26.2% | 51.8% |
| **5+ pt edge** | **1,294** | **-0.50** | **23.3%** | **52.3%** |
| 7+ pt edge | 779 | -0.51 | 21.2% | 53.0% |

**CLV vs Opening Line (value available at bet time):**

| Edge Filter | N | Mean CLV (Openâ†’Close) | ATS % (Open) |
|-------------|---|----------------------|--------------|
| All picks | 3,258 | +0.44 | 52.7% |
| 3+ pt edge | 2,001 | +0.61 | 53.6% |
| **5+ pt edge** | **1,339** | **+0.75** | **54.4%** |
| 7+ pt edge | 824 | +0.93 | 55.4% |

When measured against opening lines, CLV is strongly positive (+0.75 at 5+ edge) and monotonically increasing with edge size â€” the market moves toward JP+'s predictions by closing. This is a classic indicator of real edge.

**Interpretation:** CLV vs closing is slightly negative (the market doesn't fully move to us), but ATS is strongly positive. This pattern suggests JP+ exploits structural inefficiencies (public bias, schedule spots) rather than information sharps eventually price in.

### MAE & RMSE by Season

| Year | Games (Full) | MAE (Full) | RMSE (Full) | MAE (Core) | RMSE (Core) | MAE (Cal) | MAE (Post) |
|------|-------------|------------|-------------|------------|-------------|-----------|------------|
| 2022 | 802 | 13.28 | 16.95 | 12.72 | 16.24 | 15.63 | 12.90 |
| 2023 | 816 | 13.04 | 16.49 | 12.42 | 15.75 | 14.60 | 16.11 |
| 2024 | 818 | 13.13 | 16.39 | 12.68 | 15.76 | 15.48 | 12.09 |
| 2025 | 837 | 12.45 | 15.90 | 12.19 | 15.55 | 13.42 | 12.72 |
| **All** | **3,273** | **12.97** | **16.43** | **12.50** | **15.82** | **14.77** | **13.41** |

**Notes:**
- Best MAE in 2025 (12.19 Core), improving from 12.72 in 2022
- Calibration MAE drops significantly in 2025 (13.42 vs 14-16 in prior years) â€” better priors calibration
- RMSE/MAE ratio ~1.27 across all slices, indicating reasonably consistent error distribution

### 2025 Season Performance

JP+'s most recent season â€” best Core MAE (12.19) and strongest 5+ Edge performance across all years.

| Phase | Weeks | Games | MAE | RMSE | ATS % (Close) | ATS % (Open) | 3+ Edge (Close) | 5+ Edge (Close) | 5+ Edge (Open) |
|-------|-------|-------|-----|------|---------------|--------------|-----------------|-----------------|----------------|
| Calibration | 1-3 | 153 | 13.42 | 17.33 | 50.7% | 50.7% | 54-51 (51.4%) | 37-34 (52.1%) | 37-32 (53.6%) |
| **Core** | **4-15** | **638** | **12.19** | **15.55** | **52.7%** | **54.1%** | **180-146 (55.2%)** | **108-84 (56.2%)** | **118-84 (58.4%)** |
| Postseason | 16+ | 46 | 12.72 | 15.66 | 43.5% | 43.5% | 11-15 (42.3%) | 8-9 (47.1%) | 8-7 (53.3%) |
| **Full Season** | **All** | **837** | **12.45** | **15.90** | **51.8%** | **52.9%** | **245-212 (53.6%)** | **153-127 (54.6%)** | **163-123 (57.0%)** |

**2025 highlights:**
- Core 5+ Edge at 56.2% (Close) and 58.4% (Open) â€” strongest single-season performance
- Full-season 5+ Edge profitable at 54.6% (Close) even including weak Calibration/Postseason phases
- Postseason weakness persists (43.5% ATS) â€” bowl opt-outs and motivation remain unmodeled

### 2025 Top 25 (End of Season Including CFP)

| Rank | Team | Overall | Off (rank) | Def (rank) | ST (rank) |
|------|------|---------|------------|------------|-----------|
| 1 | **Ohio State** | +30.3 | +12.7 (8) | +15.6 (3) | +2.00 (13) |
| 2 | Indiana | +29.5 | +17.1 (2) | +11.0 (8) | +1.54 (19) |
| 3 | Miami | +26.5 | +10.5 (14) | +13.4 (4) | +2.49 (8) |
| 4 | Notre Dame | +26.3 | +12.9 (7) | +12.4 (5) | +0.97 (33) |
| 5 | Texas Tech | +25.3 | +4.9 (36) | +17.5 (1) | +2.87 (5) |
| 6 | Oregon | +24.0 | +13.0 (6) | +10.2 (10) | +0.82 (44) |
| 7 | Alabama | +22.0 | +9.8 (16) | +11.8 (6) | +0.39 (61) |
| 8 | Utah | +21.9 | +13.5 (4) | +7.5 (22) | +0.87 (39) |
| 9 | Vanderbilt | +20.3 | +18.6 (1) | -1.0 (71) | +2.84 (6) |
| 10 | Georgia | +19.7 | +8.1 (19) | +8.6 (18) | +3.04 (4) |
| 11 | Oklahoma | +19.0 | +2.1 (51) | +15.8 (2) | +1.20 (27) |
| 12 | Ole Miss | +17.7 | +12.2 (11) | +2.0 (47) | +3.49 (2) |
| 13 | Louisville | +17.4 | +6.4 (29) | +8.5 (19) | +2.48 (9) |
| 14 | Tennessee | +17.1 | +11.1 (12) | +1.9 (49) | +4.09 (1) |
| 15 | Washington | +16.7 | +10.9 (13) | +6.4 (28) | -0.57 (91) |
| 16 | South Florida | +16.1 | +8.0 (21) | +7.2 (23) | +0.94 (34) |
| 17 | Florida State | +16.1 | +12.3 (10) | +1.7 (50) | +2.06 (12) |
| 18 | Texas A&M | +15.2 | +7.5 (23) | +7.2 (24) | +0.52 (56) |
| 19 | BYU | +15.1 | +7.5 (24) | +7.0 (25) | +0.58 (53) |
| 20 | James Madison | +14.7 | +4.8 (37) | +9.0 (16) | +0.89 (38) |
| 21 | Missouri | +14.2 | +4.5 (40) | +10.3 (9) | -0.56 (90) |
| 22 | SMU | +12.9 | +7.3 (25) | +5.5 (31) | +0.09 (71) |
| 23 | Penn State | +12.5 | +8.6 (18) | +3.5 (39) | +0.40 (60) |
| 24 | USC | +12.4 | +12.4 (9) | -0.6 (67) | +0.59 (52) |
| 25 | Virginia | +12.1 | +1.0 (55) | +9.9 (12) | +1.25 (26) |

**Ohio State** â€” JP+ #1 despite losing to Indiana in CFP semifinal. Best combination of offense (#8) and elite defense (#3). The model values consistent efficiency over tournament results.

**Indiana** â€” National Champions. Beat Alabama 38-3, Oregon 56-22, and Miami 27-21 in CFP. JP+ #2 overall with the #2 offense in the country.

### Betting Line Data Sources

JP+ uses a dual-source approach for betting lines:

#### Historical Data (2022-2025): CFBD API

For historical backtesting, lines are sourced from the [CFBD API](https://collegefootballdata.com/), which aggregates lines from multiple sportsbooks. Provider priority:

1. **DraftKings** (preferred)
2. **ESPN Bet**
3. **Bovada**
4. Fallback to any available (William Hill, Consensus, Caesars)

**FBS games coverage (2022-2025):**
| Provider | Games Used | With Opening Line |
|----------|------------|-------------------|
| DraftKings | 1,360 (39%) | 1,265 (93%) |
| ESPN Bet | 1,007 (29%) | 101 (10%) |
| Bovada | 547 (16%) | 541 (99%) |
| William Hill | 301 (8%) | 0 (0%) |
| Consensus | 241 (7%) | 0 (0%) |
| Other | 44 (1%) | 0 (0%) |
| **Total** | **3,500** | **3,178 (91%)** |

**Note:** Opening line availability varies significantly by provider. DraftKings and Bovada provide opening lines for nearly all their games, while William Hill and Consensus only provide closing lines.

#### Future Data (2026+): The Odds API

For ongoing seasons, opening and closing lines are captured from [The Odds API](https://the-odds-api.com/):

- **Opening lines**: Captured Sunday morning after lines post
- **Closing lines**: Captured Saturday morning before games
- **Cost**: 2 credits/week (1 for opening, 1 for closing)
- **Provider priority**: FanDuel (posts first), DraftKings, BetMGM, Caesars, Bovada

**Capture scripts:**
- `scripts/weekly_odds_capture.py --opening` (run Sunday ~6 PM ET)
- `scripts/weekly_odds_capture.py --closing` (run Saturday ~9 AM ET)

**Data storage:** SQLite database at `data/odds_api_lines.db`

**Merge logic:** The `src/data/betting_lines.py` module merges both sources, preferring The Odds API data when available for better opening line coverage.

---

## Model Architecture

JP+ is built on a foundation model plus an adjustments layer.

### Efficiency Foundation Model (EFM)

The core engine of JP+. Built on play-level efficiency metrics rather than game margins. This approach is more predictive because it measures *how* teams play, not just final scores.

**Key Insight:** "Do not regress on the final score. Regress on the Success Rate per game so that we are measuring efficiency, not just the scoreboard outcome."

#### Components

| Component | Weight | Description |
|-----------|--------|-------------|
| **Success Rate** | 45% | Opponent-adjusted success rate via ridge regression |
| **Explosiveness (IsoPPP)** | 45% | Average EPA on successful plays only |
| **Turnover Margin** | 10% | Per-game turnover differential (see below) |
| **Red Zone Leverage** | Play weighting | Up-weight plays near goal line (see below) |

#### Success Rate Definition
- **1st down:** Gain â‰¥50% of yards needed
- **2nd down:** Gain â‰¥70% of yards needed
- **3rd/4th down:** Gain 100% of yards needed (first down or TD)

#### Garbage Time Filter (Asymmetric)
Garbage time is handled asymmetrically based on which team is winning:
- **Winning team (offense):** Full weight (1.0x) - they earned the blowout
- **Trailing team (offense):** Down-weighted (0.1x) - garbage time noise

Garbage time thresholds:
- 28+ points in 2nd half (quarters 3-4)
- 21+ points in 3rd quarter
- 14+ points in 4th quarter

This preserves signal from dominant teams (Indiana: 56% SR in garbage time) while filtering noise from trailing teams.

#### Red Zone Leverage (Play-Level Weighting)

Plays near the goal line are more predictive of scoring ability than plays in the middle of the field. We apply field-position-based weights at the play level:

| Field Position | Weight | Rationale |
|----------------|--------|-----------|
| Inside 10-yard line | 2.0x | Goal-to-go efficiency is critical |
| Inside 20-yard line | 1.5x | Red zone execution matters more |
| Between opp 40-20 | 0.7x | "Empty yards" â€” successful but didn't threaten |
| Elsewhere | 1.0x | Standard weight |

This integrates red zone efficiency directly into the EFM ridge regression rather than as a post-hoc adjustment. The weighting is applied in `_prepare_plays()` before calculating success rate and IsoPPP.

**Note:** A separate Finishing Drives model (Bayesian regression on drive-level RZ outcomes) was tested but shelved after 4 backtest rejections due to 70-80% signal overlap with IsoPPP. Play-level weighting captures the signal without redundancy.

**Why this matters:** Getting TO the red zone is sustainable skill (captured by Success Rate). Scoring TDs IN the red zone has some variance early in the season, but over 15 games becomes a reliable signal of scheme and talent. The prior_strength was reduced from 20 to 10 to better credit elite red zone teams at end of season.

#### Turnover Margin Component

Turnovers are a significant predictor of team success that pure efficiency metrics miss. A team that forces turnovers and protects the ball gains a systematic advantage not fully captured by Success Rate.

**Implementation:**
1. Identify turnover plays from play-by-play data (interceptions, fumble recoveries)
2. Count turnovers forced (defense) and turnovers lost (offense) per team per game
3. Calculate per-game turnover margin: (forced - lost) / games_played
4. Apply Bayesian shrinkage toward 0 (see below)
5. Convert to point value using `POINTS_PER_TURNOVER = 4.5`

**Turnover play types detected** (verified against CFBD API):
- Fumble Recovery (Opponent)
- Pass Interception Return
- Interception
- Fumble Return Touchdown
- Interception Return Touchdown

**Bayesian Shrinkage:** Turnover margin is 50-70% luck (fumble bounces, tipped passes). To prevent overweighting small-sample noise, JP+ applies shrinkage:

```
shrinkage = games_played / (games_played + prior_strength)
shrunk_margin = raw_margin Ã— shrinkage
```

With `turnover_prior_strength = 10`:
- 5 games: keeps 33% of margin (5/15)
- 10 games: keeps 50% of margin (10/20)
- 15 games: keeps 60% of margin (15/25)

This means early-season turnover outliers regress heavily, while sustained end-of-season performance is mostly trusted.

**Why 10% weight?** This mirrors SP+'s approach where turnovers contribute 10% of the overall rating. Higher weights would overfit to turnover luck, while lower weights would miss legitimate ball-security/ball-hawking skill.

**Impact:** Adding the turnover component captures teams like Indiana (2025: +15 margin) and Notre Dame (+17 margin) who create systematic turnover advantages. Ohio State's narrower +3 margin means their efficiency advantage is partially offset by weaker turnover performance.

#### FBS-Only Filtering

The ridge regression training data **excludes plays involving FCS opponents**. When an FBS team plays an FCS opponent (e.g., Indiana vs Indiana State), those plays are removed from the regression entirely.

**Why this matters:**
- FCS teams have too few games against FBS opponents to estimate reliable coefficients
- Including FCS plays pollutes the regression with unreliable team strength estimates
- FCS opponents are handled separately via the tiered FCS Penalty adjustment (+18/+32 pts)

This is implemented in `backtest.py` by filtering plays where both offense and defense are in the FBS teams set before passing to the EFM.

#### Special Teams (PBTA)

The special teams model calculates marginal point contribution (PBTA - Points Better Than Average) for each team's ST unit. All components are converted to points per game.

**Components:**

| Component | Calculation | Typical Range |
|-----------|-------------|---------------|
| **Field Goals** | PAAE (Points Added Above Expected) based on make rates by distance | -2 to +1.5 pts/game |
| **Punting** | Net yards vs expected (40 yds) Ã— 0.04 pts/yd + inside-20 bonus (+0.5) + touchback penalty (-0.3) | -1 to +1.5 pts/game |
| **Kickoffs** | Coverage (TB rate, return yards allowed) + Returns (return yards gained), all Ã— 0.04 pts/yd | -0.5 to +0.5 pts/game |

**Overall ST = FG + Punt + Kickoff** (simple sum since all in points)

**FBS Distribution:** Mean ~0, Std ~1.0, 95% range [-2, +2] pts/game

**Integration:** ST ratings are displayed separately from the O/D total. In spread prediction, the ST differential between teams is applied as an adjustment.

#### Key Files
- `src/models/efficiency_foundation_model.py` - Core EFM implementation (includes RZ Leverage weighting)
- `src/models/special_teams.py` - Complete ST model (FG + Punt + Kickoff)
- Ridge regression on Success Rate (Y=0/1 success, X=sparse team/opponent IDs)
- Converts efficiency metrics to point equivalents for spread prediction

---

---

## Adjustments Layer

EFM ratings feed into `SpreadGenerator` which applies game-specific adjustments. These are organized into four categories.

### Summary Table

| Category | Adjustment | Range | Description |
|----------|------------|-------|-------------|
| **Game Context** | Home Field Advantage | 1.5-4.0 pts | Team-specific based on stadium environment |
| | Travel | 0-2.5 pts | Distance and timezone penalties |
| | Altitude | 0-3 pts | High altitude venues (BYU, Air Force, Colorado) |
| | Correlated Stack Smoothing | - | Prevents over-prediction when HFA+travel+altitude combine |
| **Scheduling** | Rest Differential | Â±1.5 pts | Based on actual days between games |
| | Short Week Penalty | -2.5 pts | One team on short week (â‰¤5 days) vs normal/rested opponent |
| | Consecutive Road | -1.5 pts | Second straight road game (travel fatigue compounds) |
| | Letdown Spot | -2.0/-2.5 pts | Big win last week (ranked or rival), facing unranked |
| | Lookahead Spot | -1.5 pts | Rival or top-10 opponent next week |
| | Sandwich Spot | -1.0 pts extra | BOTH letdown AND lookahead (compounding) |
| | Rivalry Boost | +1.0 pts | Underdog in rivalry game only |
| **Opponent/Pace** | FCS Penalty | +18/+32 pts | Tiered: Elite FCS (+18), Standard FCS (+32) |
| | Special Teams | -3 to +3 pts | Full ST differential (FG+Punt+Kickoff PBTA) |
| | Pace (Triple-Option) | -10% to -15% | Spread compression for low-play-count games |
| **Manual** | QB Injury | Â±3-10 pts | Flag when starting QB is out |
| **Totals Only** | Weather | varies | Wind, cold, precipitation penalties |

---

### Game Context Adjustments

#### Home Field Advantage

JP+ uses team-specific HFA values based on stadium environment and crowd intensity:

| Tier | HFA Range | Example Teams |
|------|-----------|---------------|
| Elite | 3.5 - 4.0 | LSU, Alabama, Ohio State, Penn State |
| Strong | 3.0 - 3.25 | Nebraska, Wisconsin, Auburn, Boise State |
| Above Average | 2.75 | Texas, Miami, Virginia Tech, James Madison |
| Conference Default | 2.0 - 2.75 | Varies by conference |
| Below Average | 2.0 - 2.25 | Maryland, Rutgers, Vanderbilt |
| Weak | 1.5 - 1.75 | Kent State, Akron, Temple, UMass |

**Conference Defaults:** SEC/Big Ten: 2.75 | Big 12/ACC/Ind: 2.50 | AAC/MW/Sun Belt: 2.25 | MAC/CUSA: 2.00

**Trajectory Modifier:** HFA is adjusted Â±0.5 pts for rising/declining programs. Calculated once at season start by comparing prior year win % to 3-year baseline. Rising programs (Vanderbilt, Indiana 2024) get boost; declining programs get penalty. Natural decay as success becomes the new baseline.

#### Travel

| Component | Value | Condition |
|-----------|-------|-----------|
| **Timezone (East)** | 0.5 pts/zone | Full penalty (losing time) |
| **Timezone (West)** | 0.4 pts/zone | 80% penalty (gaining time) |
| **Distance** | 0.25 pts | 300-1000 miles |
| **Distance** | 0.5 pts | 1000-2000 miles |
| **Distance** | 1.0 pts | 2000+ miles |
| **Hawaii Special** | +2.0 pts | Mainland â†’ Hawaii |

**Distance-Based TZ Dampening:** Short-distance games crossing timezone lines (DST quirks, CT/ET border) were over-penalized. Fix: <400mi = no TZ penalty; 400-700mi = 50% TZ penalty; >700mi = full penalty.

#### Altitude

High-altitude venues (BYU 4,551ft, Air Force 6,621ft, Colorado 5,328ft) penalize visiting sea-level teams 0-3 pts based on elevation differential.

#### Consolidated Adjustment Smoothing (AdjustmentAggregator)

All game adjustments pass through a single aggregator that applies unified environmental stack smoothing to prevent double-counting correlated factors.

**Three-Bucket Architecture:**

| Bucket | Factors | Smoothing | Rationale |
|--------|---------|-----------|-----------|
| **Environmental Stack** | HFA, travel, altitude, rest, consecutive_road | Single-layer soft cap | All physical/venue factors sum linearly, then soft cap for extreme stacks only |
| **Mental** | letdown, lookahead, sandwich | Standard (100%/50%/25%) | Mental factors compound with diminishing returns |
| **Boosts** | rivalry | Linear sum | Positive factors are rare, stack fully |

**Environmental Stack Details:**
- All environmental factors (HFA + travel + altitude + rest + consecutive_road) sum linearly first
- **Soft cap applied only to extreme stacks:** Threshold = 5.0 pts, excess weight = 60%
- If |stack| â‰¤ 5.0: no dampening (standard games use linear sum)
- If |stack| > 5.0: `env_score = 5.0 + (excess Ã— 0.60)` with appropriate sign
- This single-layer approach avoids the "double damping" bug where separate bucket smoothing + soft cap created two layers of penalty

**Mental Bucket Details:**
- Largest at 100%, second at 50%, remaining at 25%
- Rationale: A team in letdown AND lookahead is distracted, but distractions don't fully stack

**Global Cap:** Â±7.0 points maximum total adjustment

**Example:** Away team at high-altitude venue with HFA=3.0, travel=1.5, altitude=1.0, rest=0.5:
- Raw env stack: 3.0 + 1.5 + 1.0 + 0.5 = 6.0 pts
- Exceeds threshold (5.0), so: 5.0 + (1.0 Ã— 0.60) = 5.6 pts (not 6.0 raw)
- Standard game with stack â‰¤5.0 gets no dampening at all

---

### Scheduling Adjustments

#### Rest Day Calculation

CFB scheduling creates meaningful rest differentials beyond simple bye weeks:

| Scenario | Days Rest | Example |
|----------|-----------|---------|
| Season Opener | 14 days | Team hasn't played yet this season |
| Bye Week | 14+ days | Didn't play previous week |
| Mini-Bye | 9-10 days | Thursday â†’ Saturday |
| Normal | 6-7 days | Saturday â†’ Saturday |
| Short Week | 4-5 days | Saturday â†’ Thursday |

**Season Opener Advantage:** A team playing their Week 1 opener gets 14 days rest (maximum), giving them a rest advantage over a team that played in Week 0. This correctly models that a fresh team faces a team with normal wear.

**Non-Linear Short Week Penalty:** When one team is on a short week (â‰¤5 days rest) and the other is on normal/rested schedule (>6 days), a hardcoded -2.5 pt penalty applies (not a linear calculation). This reflects that short-week disadvantage is severe and non-linearâ€”it's not just "2 fewer rest days."

**Linear Rest (Other Cases):** `rest_advantage = (home_rest - away_rest) Ã— 0.5 pts/day` (capped at Â±1.5 pts)

**Example:** Oregon (9 days after Thursday game) vs Texas (7 days) = +1.0 pts Oregon

#### Consecutive Road Games Penalty

Teams playing their second consecutive road game receive a -1.5 pt penalty. Travel fatigue compoundsâ€”the physical and mental toll of back-to-back away games exceeds the sum of individual road trips.

**Implementation:** Check if the team's *last played game* (not necessarily last week due to byes) was also an away game. If so, apply the penalty.

**Travel Correlation:** When travel penalty exceeds 1.5 pts (indicating significant distance), the consecutive road penalty is reduced by 50% to prevent double-counting the fatigue component.

#### Letdown, Lookahead, Sandwich, and Rivalry

| Factor | Value | Condition |
|--------|-------|-----------|
| **Letdown Spot (home)** | -2.0 pts | "Big win" last week, facing unranked opponent |
| **Letdown Spot (away)** | -2.5 pts | Same, but traveling (sleepy road game) |
| **Lookahead Spot** | -1.5 pts | Rival or top-10 opponent next week |
| **Sandwich Spot** | -1.0 pts extra | BOTH letdown AND lookahead apply to same team |
| **Rivalry Boost** | +1.0 pts | Underdog in rivalry game only |

**Letdown "Big Win" Criteria (either triggers):**
1. Beat a top-15 ranked team (using historical ranking at time of game)
2. Beat an arch-rival (regardless of rival's ranking) â€” "Rivalry Hangover"

**Bye Week Persistence:** If a team has a bye week after a big win, the letdown effect persists. Sitting on a big win for two weeks maintains the "rust" and "hangover" effect. The model finds the team's *last played game* regardless of which week it occurred.

**Staleness Threshold (3 weeks):** If the big win was more than 3 weeks ago (e.g., start of season, multiple byes), the emotional effect has faded and letdown doesn't trigger.

**Sleepy Road Game Multiplier:** Analysis of 89 letdown games (2022-2024) showed clear venue effect:
- Home letdown: 52.4% ATS, +0.1 pts vs spread (crowd keeps team engaged)
- Away letdown: 48.9% ATS, -2.5 pts vs spread (sleepy road game)

The 1.25x away multiplier captures this: home = -2.0 pts, away = -2.5 pts.

**Sandwich Spot:** The most dangerous scheduling spot in CFB. When a team is coming off a massive emotional win (letdown) AND has a massive game on deck next week (lookahead), the unranked team in the middle is the "meat" of the sandwich. Analysis showed sandwich teams cover only **36.4% ATS** (4/11 games). Total penalty: -4.5 to -5.0 pts.

**Historical Rankings:** Letdown detection uses **ranking at time of game**, not current ranking. JP+ fetches AP poll week-by-week from CFBD `/rankings` endpoint. Example: If Oregon beat #2 Ohio State in Week 7 (who later dropped to #20), Week 8 still shows letdown spot.

*Note: All situational factors feed into the consolidated AdjustmentAggregator (see Game Context section) for four-bucket smoothing.*

---

### Opponent & Pace Adjustments

#### FCS Opponent Penalty (Tiered)

| FCS Tier | Penalty | Examples |
|----------|---------|----------|
| **Elite FCS** | +18 pts | NDSU, Montana State, South Dakota State, Sacramento State, Idaho |
| **Standard FCS** | +32 pts | All other FCS teams |

Based on 359 FCS games (2022-2024): mean FBS margin vs standard FCS ~30 pts; vs elite FCS only +2 to +15 pts. Impact: 5+ edge ATS improved 56.0% â†’ 56.9%.

#### Pace Adjustment (Triple-Option)

Triple-option teams (Army, Navy, Air Force, Kennesaw State) run ~55 plays/game vs ~70 normal. Analysis shows 30% worse MAE (16.09 vs 12.36, p=0.001).

JP+ compresses spreads 10% toward zero for triple-option games (15% if both teams). This reflects fundamental uncertainty in low-possession games.

**Triple-Option Rating Boost (+6 pts):** Service academies are systematically underrated by efficiency metrics. JP+ applies rating boost and uses 100% prior (no talent blend) to correct this.

---

### Manual Adjustments

#### QB Injury

The single biggest unmodeled source of prediction error. Manual flagging system:

1. Pre-compute depth charts from CFBD player PPA data (starter = most pass attempts)
2. Calculate PPA differential between starter and backup
3. Adjustment = `PPA_drop Ã— 30 plays/game`

| Team (2024) | Starter | PPA | Backup | PPA | Adjustment |
|-------------|---------|-----|--------|-----|------------|
| Georgia | Beck | 0.353 | Stockton | 0.125 | **-6.8 pts** |
| Ohio State | Howard | 0.575 | Brown | 0.243 | **-10.0 pts** |
| Texas | Ewers | 0.322 | A. Manning | 0.589 | **+8.0 pts** |
| Alabama | Milroe | 0.321 | Simpson | 0.215 | **-3.2 pts** |

**Usage:** `python scripts/run_weekly.py --qb-out Georgia Texas`

---

### Weather Adjustments (Totals Only)

Weather adjustments use **non-linear thresholds** based on sharp betting research. The edge is in **timing** â€” capture forecasts Thursday before market moves, confirm Saturday with accurate 6-12h forecasts.

#### Data Source
- **API:** Tomorrow.io Hourly Forecast API (free tier: 25 calls/hour, 500/day)
- **Database:** `data/weather_forecasts.db` (SQLite)
- **Venue data:** 795 FBS/FCS stadiums with coordinates + dome detection
- **Rate limiting:** Scripts default to `--limit 20` per run (free tier safe)

#### Confidence Gating

**All weather adjustments are scaled by forecast confidence** based on hours until kickoff:

| Hours Until Game | Confidence Factor | Effect on -6.0 raw |
|------------------|-------------------|-------------------|
| â‰¤6h | 0.95 | -5.7 pts |
| 6-12h | 0.90 | -5.4 pts |
| 12-24h | 0.85 | -5.1 pts |
| 24-48h | 0.75 | -4.5 pts |
| >48h (Thursday) | 0.65 | -3.9 pts |

**HIGH_VARIANCE Flag:** If `confidence < 0.75` AND `abs(raw_adjustment) > 3.0`, the game is flagged `high_variance=True`. **Rule: Never bet OVER on these games** â€” weather is uncertain but potentially severe.

#### Wind Thresholds (Non-Linear Tiers)

Wind is the #1 driver of totals movement. Uses **effective wind = (wind_speed + wind_gust) / 2**.

| Effective Wind | Base Adjustment | Rationale |
|----------------|-----------------|-----------|
| <12 mph | 0.0 pts | No impact |
| 12-15 mph | -1.5 pts | Deep passing degraded |
| 15-20 mph | -4.0 pts | Kicking range reduced, deep ball erased |
| >20 mph | -6.0 pts | Run-only game profiles, clock runs constantly |

**"Passing Team" Multiplier:** Continuous scaling based on combined pass rate:
```
multiplier = combined_pass_rate / 0.50 (clamped to [0.5, 1.5])
```

| Team Style | Pass Rate | Multiplier | 20 mph Wind (after scaling) |
|------------|-----------|------------|----------------------------|
| Triple Option (Army) | 35% | 0.70x | -4.2 pts |
| Run-Heavy | 40% | 0.80x | -4.8 pts |
| Balanced | 50% | 1.00x | -6.0 pts |
| Pass-Heavy | 60% | 1.20x | -7.2 pts |
| Air Raid (Ole Miss) | 65% | 1.30x | -7.8 pts |

#### Temperature Thresholds

| Temperature | Adjustment | Rationale |
|-------------|------------|-----------|
| >32Â°F | 0.0 pts | No impact |
| 20-32Â°F | -1.0 pts | "Rock effect" â€” cold balls harder to catch/kick |
| <20Â°F | -3.0 pts | Severe mechanics impact |

#### Precipitation Thresholds

**The "Slick Trap":** Light rain does NOT hurt totals. Defenders slip, miss tackles, games can go OVER.

| Condition | Adjustment | Rationale |
|-----------|------------|-----------|
| Light rain (<0.1 in/hr) | 0.0 pts | The "slick trap" â€” no penalty |
| Heavy rain (>0.3 in/hr) | -2.5 pts | Ball security issues, conservative playcalling |
| Snow with wind (â‰¥12 mph) | -3.0 pts | Visual impairment, footing, swirling snow |
| Snow without wind | 0.0 pts | "Overreaction Fade" â€” sharps bet OVER |

**"Snow Overreaction Fade":** Public loves betting "Snow Unders" but snow without wind often goes OVER. Defenders slip, receivers know their routes. Only apply snow penalty if wind â‰¥12 mph.

#### Two-Stage Capture Workflow

| Stage | Timing | Confidence | Purpose |
|-------|--------|------------|---------|
| Thursday 6 AM | 72h out | 65% | Early alert, bet before market moves |
| Saturday 8 AM | 6-12h out | 90%+ | Confirmation, final model input |

**Saturday comparison:** Uses **earliest** forecast per game (not latest) to ensure comparison against original Thursday morning capture, even if script was re-run for debugging.

**Cron automation:** `./scripts/setup_weather_cron.sh install`

#### Integration with JP+ TotalsModel

The Thursday/Saturday capture scripts:
1. Train TotalsModel walk-forward on weeks 1 to (current_week - 1)
2. Predict JP+ total for each game
3. Apply weather adjustment to JP+ prediction
4. Compare to Vegas total to calculate edge
5. Generate watchlist sorted by edge (most negative = strongest UNDER signal)

**Edge interpretation:**
- Edge < -3 pts = ðŸ”¥ STRONG UNDER
- Edge < 0 pts = ðŸ“‰ LEAN UNDER
- Edge > 0 pts = Skip (JP+ higher than Vegas)

**Indoor games** (via dome detection) receive no weather adjustment.

**Scripts:**
- `scripts/weather_thursday_capture.py` â€” Main capture + watchlist
- `scripts/weather_thursday_capture.py --saturday` â€” Saturday confirmation mode

---

### Adjustments Key Files

| File | Purpose |
|------|---------|
| `src/predictions/spread_generator.py` | Combines all components |
| `src/adjustments/aggregator.py` | Four-bucket smoothing for all adjustments |
| `src/adjustments/home_field.py` | Team-specific HFA & trajectory |
| `src/adjustments/travel.py` | Distance/timezone |
| `src/adjustments/altitude.py` | Altitude adjustment |
| `src/adjustments/situational.py` | Rest, letdown, lookahead, rivalry (raw values) |
| `src/adjustments/qb_adjustment.py` | QB injury system |
| `src/adjustments/weather.py` | Weather adjuster (non-linear thresholds, pass rate scaling) |
| `src/api/tomorrow_io.py` | Tomorrow.io forecast API client + venue database |
| `scripts/weather_thursday_capture.py` | Thursday/Saturday capture workflow |

---

## Preseason Priors

Bayesian blending of preseason expectations with in-season performance.

### Prior Sources (weighted blend)
1. **Previous year's SP+ ratings** (60%) - Regressed toward mean based on returning production
2. **Composite recruiting rankings** (40%) - Talent level

### Returning Production Adjustment

The regression factor for prior year ratings is adjusted based on returning production (% of PPA returning):

| Returning PPA | Regression Factor | Effect |
|---------------|-------------------|--------|
| 100% | 10% | Trust prior rating (same team) |
| 50% | 30% | Baseline regression |
| 0% | 50% | Heavy regression (roster turnover) |

This prevents overvaluing teams that lost key players and undervaluing teams returning most of their production.

### Asymmetric Regression

Standard regression pulls all teams toward the mean uniformlyâ€”but this compresses the true spread between elite and terrible teams. A very bad team at -25 shouldn't gain 7.5 points just from regression.

JP+ applies **asymmetric regression**: teams far from the mean regress less than teams near the mean.

| Distance from Mean | Regression Multiplier | Effective Regression |
|-------------------|----------------------|---------------------|
| Â±8 pts | 1.0x | 30% (baseline) |
| Â±14 pts | 0.67x | 20% |
| Â±20+ pts | 0.33x | 10% |

**Example:** Kent State at raw -25 rating:
- Old (uniform): -25 Ã— 0.7 = -17.5 (lost 7.5 pts of badness)
- New (asymmetric): -25 Ã— 0.9 = -22.5 (kept most of badness)

**Extremity-Weighted Talent:** For extreme teams (20+ pts from mean), talent blend weight is reduced from 40% to 20%. This trusts proven performance over talent projections for outlier teams, preventing the talent component from compressing ratings back toward average.

### Transfer Portal Adjustment

The returning production metric only captures players who stayedâ€”it doesn't account for incoming transfers. JP+ uses a **unit-level approach** with scarcity-based position weights and level-up discounts to value all portal activity (100% coverage vs the old 18% player-matching approach).

#### Scarcity-Based Position Weights

Reflects 2026 market reality where elite trench play is the primary driver of rating stability:

| Tier | Position | Weight | Rationale |
|------|----------|--------|-----------|
| Premium | QB | 1.00 | Highest impact position |
| Premium | OT | 0.90 | Elite blindside protector |
| Anchor | EDGE | 0.75 | Premium pass rushers |
| Anchor | IDL | 0.75 | Interior pressure + run stuffing |
| Support | IOL | 0.60 | Interior OL (guards/centers) |
| Support | LB, S | 0.55 | Run defense, coverage |
| Skill | WR, CB | 0.45 | Higher replacement rate |
| Skill | RB | 0.40 | Most replaceable skill position |

#### Level-Up Discount (G5 â†’ P4 Transfers)

Players transferring from G5 to P4 conferences receive position-based discounts reflecting the competition gap:

| Position Type | Discount | Rationale |
|---------------|----------|-----------|
| Trench (OT, IOL, IDL, LB, EDGE) | 25% | Physicality Tax - steep curve in P4 trench play |
| Skill (WR, RB, CB, S) | 10% | Athleticism translates more easily |
| P4 â†’ P4 | 0% | No discount for lateral moves |
| P4 â†’ G5 | -10% | Boost for proven higher-level players |

#### Continuity Tax

Losing incumbents hurts more than raw talent value suggests (chemistry, scheme fit, experience). Outgoing player values are amplified by ~11% (factor of 0.90).

#### Parameters

| Parameter | Value | Description |
|-----------|-------|-------------|
| `portal_scale` | 0.06 | Converts raw value to % impact |
| `impact_cap` | Â±12% | Maximum team-wide adjustment |
| `continuity_tax` | 0.90 | Loss amplification factor |

#### Example 2024 Portal Winners/Losers

| Winners | Impact | Losers | Impact |
|---------|--------|--------|--------|
| Ole Miss | +12% | USC | -12% |
| Colorado | +5% | Stanford | -12% |
| SMU | +7% | Washington | -12% |
| Rice | +8% | Texas | -12% |

#### Blue Blood Validation

Blue Bloods hitting the -12% portal cap show minimal final rating impact because their elite talent composite offsets the losses:

| Team | Portal Impact | Talent Score | Rating Î” |
|------|---------------|--------------|----------|
| Alabama | -12% | +26.0 | -0.3 pts |
| Ohio State | -12% | +24.6 | -0.3 pts |
| Georgia | -12% | +25.2 | -0.4 pts |

The model correctly captures heavy portal losses while talent integration provides the expected offset.

#### Backtest Impact (2024-2025)

A/B comparison shows minimal but slightly positive effect on Core Season 5+ edge:

| Phase | With Portal | Without Portal | Î” |
|-------|-------------|----------------|---|
| Calibration (1-3) 5+ Edge | 47.5% | 48.2% | -0.7% |
| Core (4-15) 5+ Edge | **55.5%** | 54.8% | **+0.7%** |

The muted effect is expected: portal adjusts regression factor (indirect), talent composite provides primary Blue Blood offset, and preseason priors fade by week 8.

### Coaching Change Regression

When a new head coach arrives at an underperforming team (talent rank > performance rank), JP+ dampens the prior year's "drag" and weights talent more heavily. This captures the reality that a talented team stuck under a bad coach may improve significantly with new leadership.

#### The "Forget Factor"

```
talent_gap = performance_rank - talent_rank  (positive = underperformer)
base_forget = min(0.5, talent_gap / 60)
final_forget = min(0.5, base_forget Ã— coach_pedigree)

prior_weight = 0.6 Ã— (1 - final_forget)
talent_weight = 1 - prior_weight
```

#### Coach Pedigree (Data-Driven)

Pedigree scores are calculated from historical coaching records:
- **Career win %** - Primary driver (+0.25 for 70%+, -0.15 for <45%)
- **P5 HC experience** - +0.03 per year, capped at +0.12
- **Longevity bonus** - +0.03 if 5+ years HC experience

| Tier | Pedigree | Example Coaches |
|------|----------|-----------------|
| Elite | 1.27 - 1.30 | Kiffin (67%, 10 P5 yrs), Kirby Smart (85%), DeBoer (78%) |
| Strong | 1.20 - 1.25 | Cignetti (83% at JMU), Sumrall (78% at Tulane) |
| Above Avg | 1.10 - 1.19 | Rhule (51%, 5 P5 yrs), Venables (56%) |
| Average | 1.05 - 1.09 | Brent Key (53%), Sam Pittman (49%) |
| Neutral | 1.00 | First-time HCs, no record |
| Below Avg | 0.88 - 0.97 | Clark Lea (33%), Jeff Lebby (17%) |

#### Impact Examples

| Scenario | Talent | Perf | Gap | Pedigree | Weight Shift | Rating Î” |
|----------|--------|------|-----|----------|--------------|----------|
| Florida 2025 (Sumrall) | #8 | #45 | 37 | 1.25 | 60/40 â†’ 30/70 | +2 to +4 pts |
| Indiana 2024 (Cignetti) | #50 | #85 | 35 | 1.25 | 60/40 â†’ 30/70 | +2 to +4 pts |
| LSU 2025 (Kiffin) | #6 | #15 | 9 | 1.30 | 60/40 â†’ 48/52 | +0.5 pts |
| Alabama 2024 (DeBoer) | #3 | #5 | 2 | 1.30 | No change | 0 pts |

**Key insight:** First-time HCs (like Brent Key at Georgia Tech, Deion Sanders at Colorado) are **excluded entirely** from the adjustment. We have no basis to predict they'll improve the program, so they receive no boost. The model won't predict their breakout, but it also won't penalize the program.

**Known limitation:** Career win % embeds "opportunity" (better jobs â†’ higher win %), not purely coaching skill. A 65% win rate at Alabama means something different than 65% at Kansas. Ideally we'd normalize by prior team talent, but this adds complexity for a feature with small sample size.

**Backtest validation:** The coaching change adjustment showed neutral impact on MAE/ATS across 2023-2025 (sample of affected games too small). This is a qualitative signal with limited statistical powerâ€”included for conceptual completeness but shouldn't be expected to provide measurable ATS lift.

### Decay Schedule
| Week | Preseason Weight | In-Season Weight |
|------|------------------|------------------|
| 1 | 100% | 0% |
| 4 | 62% | 38% |
| 8 | 15% | 85% |
| 12+ | 0% | 100% |

#### Key Files
- `src/models/preseason_priors.py` - Prior calculation, returning production adjustment, and blending

---

## Data Pipeline

### Data Sources
- **College Football Data API (CFBD)** - Games, plays, betting lines, team info
- API client: `src/api/cfbd_client.py`

### Data Flow
```
CFBD API
    â”‚
    â”œâ”€â”€ Games (scores, neutral site, dates)
    â”œâ”€â”€ Betting Lines (spreads, totals)
    â”œâ”€â”€ Play-by-Play (down, distance, yards, PPA)
    â”œâ”€â”€ Field Goal Plays (distance, made/missed)
    â”œâ”€â”€ Transfer Portal (player movements, ratings)
    â”œâ”€â”€ Player Usage (prior-year PPA by player)
    â”œâ”€â”€ Returning Production (% PPA returning)
    â”œâ”€â”€ Team Info (FBS teams, conferences)
    â”œâ”€â”€ Weather (temperature, wind, precipitation, indoor flag)
    â”œâ”€â”€ SP+ Ratings (external benchmark)
    â””â”€â”€ FPI Ratings (ESPN, external benchmark)
    â”‚
    â–¼
Preseason Priors
    â”‚
    â”œâ”€â”€ Prior SP+ ratings (regressed)
    â”œâ”€â”€ Talent composite
    â”œâ”€â”€ Transfer portal net impact
    â””â”€â”€ Coaching change adjustment
    â”‚
    â–¼
EFM Training
    â”‚
    â”œâ”€â”€ Success Rate calculation per play
    â”œâ”€â”€ Garbage time filtering
    â”œâ”€â”€ Ridge regression for opponent adjustment
    â””â”€â”€ FG efficiency calculation (PAAE)
    â”‚
    â–¼
SpreadGenerator
    â”‚
    â””â”€â”€ Apply adjustments â†’ Predicted Spread
```

---

## File Structure

```
CFB Power Ratings Model/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py              # Configuration management
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ cfbd_client.py       # CFBD API client
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ processors.py        # Data processing
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ efficiency_foundation_model.py  # Core EFM engine (includes RZ Leverage)
â”‚   â”‚   â”œâ”€â”€ preseason_priors.py  # Preseason ratings & coaching regression
â”‚   â”‚   â”œâ”€â”€ special_teams.py     # FG + punt + kickoff efficiency
â”‚   â”‚   â””â”€â”€ finishing_drives.py  # [SHELVED] RZ model (replaced by RZ Leverage in EFM)
â”‚   â”œâ”€â”€ adjustments/
â”‚   â”‚   â”œâ”€â”€ home_field.py        # Team-specific HFA & trajectory
â”‚   â”‚   â”œâ”€â”€ travel.py            # Travel adjustments
â”‚   â”‚   â”œâ”€â”€ altitude.py          # Altitude adjustments
â”‚   â”‚   â”œâ”€â”€ situational.py       # Situational factors
â”‚   â”‚   â”œâ”€â”€ qb_adjustment.py     # QB injury adjustment system
â”‚   â”‚   â””â”€â”€ weather.py           # Weather adjustments for totals
â”‚   â””â”€â”€ predictions/
â”‚       â”œâ”€â”€ spread_generator.py  # Combines all components
â”‚       â””â”€â”€ vegas_comparison.py  # Compare to Vegas lines
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ backtest.py              # Walk-forward backtesting
â””â”€â”€ docs/
    â””â”€â”€ MODEL_ARCHITECTURE.md    # This file
```

---

## Usage

### Running Backtests

```bash
# Standard JP+ backtest (uses optimized defaults)
python scripts/backtest.py --use-efm

# Parameter sweep
python scripts/backtest.py --use-efm --sweep

# Custom parameters
python scripts/backtest.py --years 2024 2025 --use-efm --alpha 50 --fcs-penalty-elite 18 --fcs-penalty-standard 32
```

### CLI Options

| Flag | Default | Description |
|------|---------|-------------|
| `--years` | 2022-2025 | Years to backtest |
| `--start-week` | 4 | First week to predict |
| `--use-efm` | Required | Use JP+ (EFM-based) model - always include this flag |
| `--alpha` | 50.0 | Ridge regularization strength (optimized via sweep) |
| `--hfa` | 2.5 | Base home field advantage in points |
| `--fcs-penalty-elite` | 18.0 | Points added for FBS vs elite FCS |
| `--fcs-penalty-standard` | 32.0 | Points added for FBS vs standard FCS |
| `--no-asymmetric-garbage` | False | Disable asymmetric garbage time (enabled by default) |
| `--no-portal` | False | Disable transfer portal adjustment |
| `--portal-scale` | 0.15 | Weight for transfer portal impact |
| `--sweep` | False | Run parameter grid search |
| `--no-priors` | False | Disable preseason priors |

### Weekly Predictions (run_weekly.py)

```bash
# Generate predictions for current week
python scripts/run_weekly.py --year 2025 --week 10

# With QB injury adjustments
python scripts/run_weekly.py --year 2025 --week 10 --qb-out Georgia Texas

# With delta cache (only fetches current week from API, loads historical from Parquet cache)
python scripts/run_weekly.py --year 2025 --week 10 --use-delta-cache
```

| Flag | Default | Description |
|------|---------|-------------|
| `--year` | Current | Season year |
| `--week` | Current | Week to predict |
| `--qb-out` | None | Teams whose starting QB is out (space-separated) |
| `--use-delta-cache` | Off | Load historical weeks from Parquet cache, fetch only current week from API |

---

## Key Design Decisions

### 1. Why Efficiency-Based (not Margin-Based)?
- Margins are noisy (turnovers, garbage time, late scores)
- Success Rate is more stable and predictive
- Play-level data captures *how* teams perform, not just outcomes

### 2. Why Ridge Regression?
- Handles opponent adjustment naturally (sparse team IDs as features)
- Regularization prevents overfitting to small samples
- Fast and interpretable

### 3. Why Preseason Priors?
- Early season has insufficient data
- Recruiting rankings and prior performance are predictive
- Bayesian blending smoothly transitions to in-season data

### 4. Double-Counting Prevention
- Base ratings contain ONLY the EFM output + preseason blend
- All adjustments (HFA, FCS penalty, FG efficiency, etc.) applied ONCE at prediction time
- SpreadGenerator is the single point where components combine

### 5. Neutral-Field Ridge Regression

JP+ uses a neutral-field ridge regression to produce true team strength ratings that are independent of home field advantage.

**The Problem (before fix):** The CFBD EPA values (which feed into EFM) implicitly contain home field advantageâ€”home teams naturally generate better EPA due to crowd noise, familiarity, etc. Without correction, the ridge regression learns team coefficients that include this implicit HFA. When SpreadGenerator adds explicit HFA, this caused double-counting and a systematic -6.7 mean error.

**The Solution:** Add a home field indicator column to the ridge regression design matrix:
- `+1` when the offense is the home team (home advantage)
- `-1` when the defense is the home team (away disadvantage)
- `0` for neutral site plays

This allows the model to separately learn:
1. **Team strength** (neutral-field) - the team coefficients
2. **Implicit HFA** - the home indicator coefficient

**Results:**
| Metric | Before | After |
|--------|--------|-------|
| Mean Error (2024) | -6.7 pts | **-0.40 pts** |
| Mean Error (2022-2024) | ~-6.7 pts | **+0.51 pts** |

The mean error is now essentially zero, confirming that double-counting has been eliminated.

**Learned Implicit HFA:**
- Success Rate: ~0.006 (home teams have ~0.6% higher SR)
- IsoPPP: ~0.02 (home teams have ~0.02 higher EPA on successful plays)
- Combined in points: ~0.8 pts of implicit HFA in the play-level data

The learned implicit HFA is small (~0.8 pts) compared to the explicit HFA (~2.5 pts) applied by SpreadGenerator. This is expectedâ€”most HFA manifests at the scoring/outcome level (special teams, turnovers, momentum) rather than pure play-by-play efficiency.

### 6. Opponent-Adjusted Metric Caching

Ridge regression for Success Rate and IsoPPP is computationally intensive. During walk-forward backtesting, this led to O(nÂ²) work accumulationâ€”each prediction week recomputes from scratch, rebuilding the sparse design matrix and fitting the model.

**Two-tier caching strategy:**

**Tier 1 â€” X_base Matrix Cache:** The sparse design matrix (team indicators + home field) is cached separately from weights and targets. X_base depends only on play structure (which teams, which plays) and is independent of time decay, so it can be reused when only the eval_week changes.

```python
# X_base cache key: hash of play structure (teams, home_team, n_plays)
# X_base cache value: (sparse CSR matrix, has_home_info)
```

**Tier 2 â€” Result Cache:** Full Ridge regression results cached by `(season, eval_week, metric_name, ridge_alpha, time_decay, data_hash)`:

```python
# Result cache key structure
cache_key = (2024, 5, "is_success", 50.0, 1.0, "a1b2c3d4e5f6")
#            ^     ^   ^              ^     ^     ^
#            |     |   |              |     |     â””â”€ Data fingerprint
#            |     |   |              |     â””â”€ Time decay factor
#            |     |   |              â””â”€ Ridge alpha
#            |     |   â””â”€ Metric column
#            |     â””â”€ Max training week
#            â””â”€ Season year
```

**Weight pipeline (in `_prepare_plays`):**
- `base_weight` = GT Ã— OOC Ã— RZ Ã— empty_yards (all non-temporal weights, cacheable with X_base)
- `weight` = `base_weight` Ã— time_decay (applied dynamically per eval_week in `_ridge_adjust_metric`)

**Why caching is safe:**
- Ridge regression is deterministic: same inputs â†’ same outputs
- Cache keys include all parameters that affect results
- `data_hash` guards against edge cases where same (season, week) has different data
- X_base is purely structural (team indicators) â€” independent of weights, targets, and time decay

**API:**
```python
from src.models.efficiency_foundation_model import (
    clear_ridge_cache,          # Clear result cache and return stats
    clear_base_matrix_cache,    # Clear X_base cache and return stats
    get_ridge_cache_stats,      # Get hits, misses, size, hit_rate
)
```

---

## Totals Model Baseline (2023-2025)

Separate model for over/under prediction using game-level scoring data (not play-level efficiency like EFM).

### Architecture

- **Training data:** Each game â†’ 2 rows: home team scores X vs away defense, away team scores Y vs home defense
- **Ridge regression:** Solves for team off/def adjustments relative to FBS average (~24 ppg)
- **Learned HFA:** Home field advantage learned via Ridge column (+3.5 to +4.5 pts typical)
- **Walk-forward:** Only uses games from weeks prior to prediction week

**Prediction formula:**
```
home_expected = baseline + (home_off_adj + away_def_adj) / 2 + hfa_coef
away_expected = baseline + (away_off_adj + home_def_adj) / 2
predicted_total = home_expected + away_expected
```

### Performance by Phase (vs Closing Line)

| Phase | Weeks | Games | MAE | ATS % | 3+ Edge | 5+ Edge |
|-------|-------|-------|-----|-------|---------|---------|
| Calibration | 1-3 | 169 | 12.42 | 57.9% | 56.7% (59-45) | **61.1%** (44-28) |
| **Core** | **4-15** | **1,824** | **13.09** | **53.9%** | **54.7%** (539-446) | **54.5%** (334-279) |
| Postseason | 16+ | 134 | 13.57 | 53.2% | 55.0% (44-36) | 56.5% (26-20) |
| **Full Season** | **All** | **2,127** | **13.07** | **54.1%** | **54.9%** (642-527) | **55.3%** (404-327) |

### Performance by Phase (vs Opening Line)

| Phase | Weeks | Games | MAE | ATS % | 3+ Edge | 5+ Edge |
|-------|-------|-------|-----|-------|---------|---------|
| Calibration | 1-3 | 169 | 12.42 | 55.4% | 57.0% (57-43) | **58.7%** (37-26) |
| **Core** | **4-15** | **1,824** | **13.09** | **53.4%** | **54.2%** (528-447) | **55.3%** (330-267) |
| Postseason | 16+ | 134 | 13.57 | 54.8% | 55.6% (45-36) | 55.8% (24-19) |
| **Full Season** | **All** | **2,127** | **13.57** | **53.6%** | **54.5%** (630-526) | **55.6%** (391-312) |

### Full Season by Year

| Year | Games | MAE | 3+ Edge (Close) | 3+ Edge (Open) | 5+ Edge (Close) | 5+ Edge (Open) |
|------|-------|-----|-----------------|----------------|-----------------|----------------|
| 2023 | 713 | 13.37 | 55.0% (204-167) | 53.5% (192-167) | 54.0% (143-122) | 55.3% (135-109) |
| **2024** | **706** | **13.03** | **56.2%** (230-179) | **55.6%** (225-180) | **58.6%** (143-101) | **58.2%** (139-100) |
| 2025 | 708 | 12.80 | 53.5% (208-181) | 54.3% (213-179) | 53.2% (118-104) | 53.2% (117-103) |

### Configuration

| Parameter | Value | Notes |
|-----------|-------|-------|
| Years | 2023-2025 | 2022 excluded (scoring environment transition, 49% ATS) |
| Ridge Alpha | 10.0 | Optimal for 5+ Edge |
| Decay Factor | 1.0 | No within-season decay (walk-forward handles temporality) |
| Learned HFA | +3.5 to +4.5 pts | Via Ridge column, not fixed value |
| OT Protection | Disabled | Final scores used (Vegas prices OT potential) |
| Weather | Optional | Available but no ATS improvement |

### Key Findings

- **Calibration phase strongest** â€” opposite of spreads model. Early-season totals more predictable.
- **2024 exceptional** â€” 59.5% 5+ Edge may reflect market recalibration after scoring shift.
- **Learned HFA critical** â€” improved 5+ Edge by +1.6% (Close), +2.1% (Open) vs no/fixed HFA.

---

## Open Items

### Needs Validation
- [x] **EFM alpha parameter sweep** - âœ… DONE. Swept alphas 25-200 across 2022-2025. Optimal: alpha=50 (MAE 12.54, 5+ edge 56.0% vs 55.3% at alpha=100). Updated defaults.

---

## Future Improvements

### High Priority
- [x] **Expose separate O/D/ST ratings** - âœ… DONE. JP+ now exposes separate offensive, defensive, and special teams ratings via `get_offensive_rating()`, `get_defensive_rating()`, `get_special_teams_rating()`, and in `get_ratings_df()` output. This enables future game totals prediction.
- [x] **Add quarterback-specific adjustments for injuries** - âœ… DONE. Added `QBInjuryAdjuster` class that pre-computes depth charts from CFBD player PPA data. Manual flagging via `--qb-out TEAM` CLI flag. Adjustment = PPA drop Ã— 30 plays/game.
- [x] **Game totals prediction (over/under)** - âœ… DONE. Separate TotalsModel using Ridge regression on game-level points (not play-level efficiency). Learned HFA via Ridge column (+3.5 to +4.5 pts). Core 5+ Edge: 54.5% (Close), 55.3% (Open). See "Totals Model Baseline" section.
- [x] **Improve situational adjustment calibration** - âœ… DONE. Two major calibrations: (1) HFA Global Offset (-0.50 pts) reduced systematic home bias from +0.90 to +0.46, improving 5+ Edge by +0.6%; (2) Correlated stack smoothing applies soft cap when HFA+travel+altitude exceeds 5 pts. Both validated via error cohort analysis.

### Medium Priority
- [x] **Multi-year backtesting to validate stability** - âœ… DONE. Walk-forward backtest across 2022-2025 (4 seasons). See "Backtest Performance" section at top of file for current metrics.
- [x] **Weather impact modeling** - âœ… DONE. Full weather system for totals: Tomorrow.io API for forecasts (not CFBD look-back), non-linear thresholds (wind tiers at 12/15/20 mph), "slick trap" (light rain = no penalty), "passing team multiplier" (wind scaled by combined pass rate), "snow overreaction fade" (snow without wind = no penalty). Two-stage capture: Thursday 6 AM (early alert) + Saturday 8 AM (confirmation). Backtest shows market already prices weather (no ATS improvement), but timing edge exists for early movers.
- [x] **Expand special teams beyond FG** - âœ… DONE. Added punt and kickoff ratings to complete ST model. All components expressed as PBTA (Points Better Than Average) per game. Punt rating: net yards vs expected (40 yds) converted to points + inside-20/touchback adjustments. Kickoff rating: coverage (touchback rate, return yards allowed) + returns (return yards gained). Overall = FG + Punt + Kickoff. FBS distribution: mean ~0, std ~1.0, 95% within Â±2 pts/game.

### Low Priority
- [ ] Real-time line movement tracking

### 2026 Production Planning

#### Bet Execution Automation

**Problem:** Major US sportsbooks (DraftKings, FanDuel, BetMGM, Caesars) prohibit API-based betting. All wagers must be placed manually through their apps/websites, creating friction between model signal and bet execution.

**Solution: Discord-Based Alert System with Deep Links**

1. **Discord Bot Integration**
   - Model generates betting signals (Thursday weather watchlist, weekly spread picks)
   - Bot posts to private Discord channel with formatted alerts
   - Alerts include: matchup, JP+ line, Vegas line, edge, recommended stake
   - Supports role-based notifications (@weather-bets, @spread-bets, @5pt-edge)

2. **Mobile Deep Links**
   - Generate sportsbook-specific deep links that open directly to the bet slip
   - DraftKings: `draftkings://sportsbook/event/{event_id}`
   - FanDuel: `fanduel://sportsbook/event/{event_id}`
   - One-tap from Discord notification â†’ pre-populated bet slip
   - Reduces execution time from ~60 seconds to ~10 seconds

3. **Execution Tracking**
   - Bot tracks which alerts were acted on (reaction-based confirmation)
   - Logs actual bet placement for P&L tracking
   - Compares intended vs actual execution for slippage analysis

**Implementation:** `src/notifications/discord_bot.py`, `src/notifications/deep_links.py`

#### API Betting Exchanges (Full Automation)

**Opportunity:** Sports betting exchanges allow programmatic order placement, enabling true automation without manual intervention.

**Platforms to Evaluate:**

1. **Sporttrade**
   - US-regulated exchange (NJ, CO)
   - REST API for order placement
   - Spread betting via limit orders
   - Commission: ~2% on winnings
   - **Key question:** Liquidity depth on CFB spreads/totals. NFL likely deep, CFB may be thin.

2. **ProphetX (Prophet Exchange)**
   - US-regulated (NJ)
   - WebSocket API for real-time odds
   - Supports spread and total markets
   - Commission: ~2% on winnings
   - **Key question:** Can we get filled at our target price, or do we move the market?

3. **Novig**
   - Peer-to-peer model
   - Lower margins than traditional books
   - API access available
   - **Key question:** Counterparty availability for CFB markets

**Liquidity Analysis Required:**
- Monitor order book depth for 20+ CFB games across 4 weeks
- Measure bid-ask spread at various stake sizes ($100, $500, $1000)
- Track fill rates and slippage on simulated orders
- Compare effective odds to DK/FD closing lines

**If Liquidity Sufficient:**
- Full automation pipeline: Model signal â†’ API order â†’ Execution confirmation
- Kelly-sized stakes based on edge magnitude
- Real-time P&L dashboard
- Automatic hedging on line movement

**Implementation:** `src/betting/exchange_client.py`, `src/betting/order_manager.py`

#### Kelly Criterion Stake Sizing

**Problem:** Current system treats all bets equally (flat betting). A 3-point edge and an 8-point edge get the same stake, leaving money on the table.

**Solution: Kelly Criterion for Optimal Bankroll Growth**

The Kelly formula maximizes long-term bankroll growth by sizing bets proportional to edge:

```
f* = (bp - q) / b

where:
  f* = fraction of bankroll to wager
  b  = decimal odds - 1 (for -110 juice, b = 0.909)
  p  = probability of winning (derived from JP+ edge)
  q  = probability of losing (1 - p)
```

**Edge-to-Win-Probability Conversion:**

| JP+ Edge | Implied Win % | Full Kelly | Half Kelly |
|----------|---------------|------------|------------|
| 3 pts | 54.5% | 4.5% | 2.25% |
| 5 pts | 57.5% | 9.5% | 4.75% |
| 7 pts | 60.0% | 14.0% | 7.0% |
| 10 pts | 64.0% | 21.0% | 10.5% |

**Practical Implementation:**
1. **Use Half-Kelly or Quarter-Kelly** â€” Full Kelly is mathematically optimal but assumes perfect edge estimation. Fractional Kelly reduces variance and accounts for model uncertainty.
2. **Cap maximum stake** â€” Never exceed 5% of bankroll on single bet regardless of calculated Kelly.
3. **Bankroll tracking** â€” Maintain running bankroll ledger to recalculate stakes weekly.
4. **Confidence adjustment** â€” Scale Kelly fraction by model confidence (Phase 1 bets get smaller Kelly than Phase 2).

**Bankroll Simulation (Backtest):**
- Simulate 2022-2025 seasons with Kelly sizing vs flat betting
- Measure: Total return, max drawdown, Sharpe ratio, risk of ruin
- Validate that Kelly outperforms flat betting on historical data

**Implementation:** `src/betting/kelly.py`, `src/betting/bankroll.py`

### Parking Lot (Needs Evidence Before Implementation)
- [x] **Pace-based margin scaling** - Theory: Fast games have more plays, so efficiency edges should compound into larger margins. JP+ should scale predicted margins by expected pace. **Status:** INVESTIGATED, NOT IMPLEMENTING. Empirical analysis (2023-2025) shows the theory doesn't match reality: (1) Fast games actually have smaller margins (RÂ²=2.2% correlation), (2) JP+ over-predicts fast game margins (mean error -2.1), not under-predicts, (3) ATS is actually better in fast games (73% vs 67.6%). Vegas already prices pace. Efficiency metrics implicitly capture tempo. Adding pace scaling would add complexity without benefit.
- [x] **Mercy Rule Dampener (non-linear margins)** - Theory: Coaches tap brakes in blowouts, so efficiency models over-predict large margins. Apply logistic dampening to extreme spreads. **Status:** INVESTIGATED, NOT IMPLEMENTING. The bias EXISTS (mean error -38.7 on 21+ spreads), and dampening DOES improve MAE (-1.66 pts). BUT dampening HURTS ATS (-2.8pp) because our large edges against Vegas are correct directionally even when magnitude is off. A spread of -28 vs Vegas -21 may be "wrong" by 7 points but RIGHT about home covering. Since ATS is our optimization target (Rule #3), we accept worse MAE to maintain betting edge.
- [x] **Soft cap on asymmetric garbage time** - Concern: winning team can accumulate unlimited full-weight plays in blowouts, potentially inflating ratings. **Status:** INVESTIGATED, NOT IMPLEMENTING. Tested GT weight variants (leading=0.5, 0.7, symmetric) â€” ALL degraded 5+ Edge from 53.5% to 52.2-52.5%. Asymmetric GT (leading=1.0) generates real predictive signal; winner's GT plays ARE informative. Big 12 bubble (UCF, Baylor, Colorado over-rated) is conference circularity, not GT weighting.
- [x] **Reduce turnover weight to improve 3+ edge** - Turnovers help 5+ edge but slightly hurt 3+ edge. **Status:** INVESTIGATED, KEEPING 10%. The 3+/5+ Edge divergence pattern is documented across 3+ experiments (conf anchor, churn penalty, LASR). 5+ Edge (~2% over vig) is the binding constraint; 3+ Edge (~1.3% over vig) is secondary. Optimizing for 3+ Edge consistently degrades 5+ Edge. Current 10% is optimal.
- [ ] **Normalize coaching pedigree by prior team talent** - Career win % embeds opportunity (better jobs â†’ higher win %), not purely skill. Normalizing by talent level of teams coached would be more accurate. **Status:** Small sample size (~10-15 coaching changes/year) makes this hard to validate. Current neutral backtest impact suggests feature is already appropriately weighted.
- [x] **EV-weighted performance metric** - Current metrics (MAE, ATS %) treat all bets equally. **Status:** PARTIALLY IMPLEMENTED. CLV (Closing Line Value) tracking now integrated into backtest output. CLV measures how much value we capture before market closes â€” monotonically increasing at higher edge thresholds (+0.75 at 5+ edge). Full Kelly criterion sizing not implemented, but core "weight by betting value" concept is captured via edge threshold filtering (3+, 5+ pt edge buckets). Remaining: Kelly fraction calculations, bankroll simulation.

---

## References

### Methodology Inspiration
- **SP+ (Bill Connelly)** - Success Rate + Explosiveness foundation; JP+ naming is an homage to SP+
- FPI (ESPN) - Efficiency-based ratings
- Sagarin - Ridge regression approach

### Key Metrics
- **Success Rate:** % of plays achieving down-specific yardage thresholds
- **IsoPPP (Isolated Points Per Play):** EPA on successful plays only
- **EPA (Expected Points Added):** Point value added by each play

---

## Changelog

### February 2026
- **Totals Model (Over/Under Prediction)** - NEW production module for game totals prediction. Separate architecture from EFM: Ridge regression on game-level points scored/allowed (not play-level efficiency). Key innovation: HFA learned via Ridge column (+3.5 to +4.5 pts) rather than assumed fixed value â€” improved 5+ Edge by +1.6% (Close), +2.1% (Open). Configuration: alpha=10.0, decay=1.0, years 2023-2025 (2022 excluded as scoring transition year). Performance: Core 5+ Edge 54.5% (Close), 55.3% (Open); Full Season 5+ Edge 55.3% (Close), 55.6% (Open). Files: `src/models/totals_model.py`, `scripts/backtest_totals.py`.
- **HFA Global Offset Calibration (-0.50 pts)** - Error cohort analysis revealed +0.90 pts systematic home bias across 2,489 core games. Added `global_offset` parameter to `HomeFieldAdvantage` that subtracts a fixed amount from ALL team HFA values (floor=0.5). 6-variant sweep (0.0, 0.25, 0.375, 0.50, 0.75, 1.00): offset=0.50 optimal â€” 5+ Edge Close +0.6% (54.1%â†’54.7%), Open +0.5% (57.3%â†’57.8%), mean error halved from +0.90 to +0.46, MAE flat. First experiment where 3+ and 5+ Edge improve together without divergence. CLI: `--hfa-offset` (default 0.50). Also applied in `run_weekly.py` for production.
- **Conference Strength Anchor (OOC Weighting + Bayesian Anchors)** - Two-mechanism approach to reduce conference circularity: (1) 1.5x play weight for OOC FBS games in Ridge regression, (2) post-Ridge separate offensive and defensive Bayesian conference anchors using OOC scoring data. Parameters: anchor_scale=0.08, prior_games=30, max_adjustment=Â±2.0. A conference can now have positive offensive anchor but negative defensive anchor. 4-variant sweep tested (0.08, 0.12, 0.15, 0.20) â€” 0.08 preserved 5+ Edge best; larger scales improved 3+ Edge but degraded 5+ Edge (binding constraint).
- **Red Zone Leverage Weighting + Empty Yards Filter** - Play-level weighting in `_prepare_plays()`: inside-10=2.0x, inside-20=1.5x, empty yards zone (opp 40-20)=0.7x for successful plays that don't enter RZ. 5+ Edge +0.2%, MAE +0.02 (within tolerance). No outcome data â€” purely spatial signal.
- **X_base Sparse Matrix Caching** - Refactored EFM Ridge regression pipeline to precompute and cache the sparse design matrix (X_base) separately from sample weights. X_base encodes play structure only (team indicators + home field) and is independent of time decay, enabling reuse when only the eval_week changes. Time decay moved from `_prepare_plays()` to `_ridge_adjust_metric()` for dynamic per-week application. New `base_weight` column stores all non-temporal weights (GT Ã— OOC Ã— RZ Ã— empty_yards). Two-tier caching: X_base by play structure hash, results by (season, week, metric, alpha, time_decay, data_hash). Backtest output identical.
- **Week-Level Delta Cache for run_weekly.py** - Wired up the existing `WeekDataCache` infrastructure to `run_weekly.py` via `--use-delta-cache` flag. When enabled, historical weeks [1, week-2] are loaded from Parquet cache on disk and only the most recent completed week is fetched from the CFBD API. Graceful cold start: first run populates the cache; subsequent runs fetch 1 API week instead of N-1. Schema enforced via explicit Polars dtypes. Zero behavior change when flag is off.
- **Explosiveness Uplift: EFM Weights 54/36/10 â†’ 45/45/10** - Equal weighting of Success Rate and IsoPPP (Explosiveness) better captures boom-or-bust offensive teams. Previous 54/36 split over-weighted consistency vs big plays. Results: Core ATS (Close) improved 51.3% â†’ 52.4% (+1.1%), Core ATS (Open) improved 52.8% â†’ 54.0% (+1.2%). Core 5+ Edge (Open) 56.9%, CLV positive and monotonically increasing (+0.75 at 5+ edge). Core MAE +0.02 (12.49 â†’ 12.51, within strict tolerance). All six files updated: `efficiency_foundation_model.py`, `backtest.py`, `calibrate_situational.py`, `benchmark_backtest.py`, `compare_ratings.py`, and documentation.
- **P0 Audit Fixes (Postseason Chronology + EFM Robustness)** - Fixed 6 structural issues from code audit: (1) Postseason games now mapped to sequential pseudo-weeks by date instead of all lumped into week 16, preserving walk-forward chronology; (2) home_team validated via game join on game_id for reliable neutral-field ridge regression; (3) ATS unmatched mask uses vegas_spread.isna() instead of game_id.isna(); (4) EFM uses pd.notna() for home_team check with coverage logging; (5) Ridge cache hash strengthened with MD5 of team sequences + metric stats; (6) Unused imports removed. Performance tables refreshed with post-fix baseline: Core MAE 12.55, Core ATS 52.0%, Core 5+ Edge 53.2%.
- **Fixed Double-Damping Bug with Unified Environmental Stack** - Major fix to the adjustment aggregator. The previous four-bucket design applied smoothing to the physical bucket (100%/25%) and then soft cap on top, creating two layers of penalty that destroyed valid betting edges. The fix consolidates all environmental factors (HFA, travel, altitude, rest, consecutive_road) into a single stack with one soft cap layer: threshold 5.0 pts, excess weight 60%. Standard games (stack â‰¤5.0) get no dampening at allâ€”only extreme stacks are smoothed. Mental bucket (letdown, lookahead, sandwich) unchanged at 100%/50%/25%. Boosts bucket (rivalry) unchanged as linear sum. Performance restored to baseline: Core MAE 12.21, Core 5+ Edge 57.1%.
- **Consolidated All Adjustment Smoothing into AdjustmentAggregator** - Major architectural refactor to eliminate double-smoothing. All game adjustments (HFA, travel, altitude, rest, letdown, lookahead, sandwich, consecutive road, rivalry) now flow through a single aggregator. Global cap at Â±7.0 points. This replaces the previous separate smoothing in `smooth_correlated_stack()` and `SituationalFactors.__post_init__()`. New file: `src/adjustments/aggregator.py`.
- **Simplified SituationalFactors to Raw Container** - Removed all smoothing logic from SituationalFactors dataclass. It now stores raw adjustment values only. Added `get_matchup_factors()` method that returns raw factors for the aggregator. Legacy `get_matchup_adjustment()` retained for backward compatibility.
- **Added Consecutive Road Games Penalty** - Teams playing their second consecutive road game receive -1.5 pt penalty. Travel fatigue compoundsâ€”back-to-back away games exceed the sum of individual road trips. Implementation checks team's last played game (not necessarily previous week due to byes). Travel-consecutive correlation in aggregator reduces consecutive_road by 50% when travel > 1.5 pts.
- **Refactored Short Week to Non-Linear Penalty** - When one team is on short week (â‰¤5 days) and opponent is on normal/rested schedule (>6 days), a hardcoded -2.5 pt penalty applies instead of linear calculation. Short week disadvantage is severe and non-linearâ€”not just "2 fewer rest days." Linear rest calculation still applies for other scenarios (bye vs bye, mini-bye vs normal, etc.).
- **Added Letdown Persistence Through Bye Weeks** - Letdown spot now persists through bye weeks by finding the team's *last played game* regardless of which week it occurred. If a team has a big win followed by a bye, they still get letdown penalty in their next game. Added 3-week staleness thresholdâ€”after 3+ weeks since the big win, the emotional effect has faded and letdown doesn't trigger.
- **Season Opener Gets Maximum Rest** - Teams playing their first game of the season now get 14 days rest (maximum) instead of 7 days. This correctly models that a fresh team facing a Week 0 opponent has a rest advantage.
- **Integrated The Odds API for Betting Lines** - Added dual-source approach for betting line data: CFBD API for historical data (2022-2025, 91% FBS opening line coverage), The Odds API for future seasons (2026+). Created `src/api/odds_api_client.py` for API access, `src/api/betting_lines.py` for unified data merging, `scripts/capture_odds.py` for backfill/one-time captures, and `scripts/weekly_odds_capture.py` for scheduled weekly captures (opening lines Sunday, closing lines Saturday). Data stored in SQLite at `data/odds_api_lines.db`. Cost: 2 credits/week for ongoing captures. Note: Historical backfill requires paid Odds API plan; free tier (500 credits/month) supports current odds only.
- **Added 2022-2025 Backtest Performance Section** - Comprehensive walk-forward backtest results across 4 seasons (3,273 games total, 2,485 Core weeks 4-15). Key findings: Core MAE 12.55, ATS 52.0% vs closing lines. At 5+ point edge: 53.2% vs closing, 57.0% vs opening. Opening line performance significantly exceeds closing line, indicating model captures value that the market prices out by game time. Results broken down by year show consistent improvement in MAE (12.87â†’12.21) and stable ATS performance. Added P3.4 sanity report infrastructure for data and prediction validation.
- **Implemented Correlated Stack Smoothing** - Fixed systematic over-prediction in high-stack games (HFA + travel + altitude combined). Analysis of 2024-2025 data revealed games with >5 pts combined adjustment over-predicted home team margins by ~2.3 pts. The fix applies two mechanisms: (1) **Altitude-travel interaction**: When travel > 1.5 pts AND altitude > 0, reduce altitude by 30% to account for partial overlap between effects; (2) **Soft cap**: When combined stack exceeds 5 pts, reduce excess by 50% and distribute reduction proportionally across all three components. Example: stack of 7 â†’ 5 + (7-5)Ã—0.5 = 6 effective. Results: max stack reduced from 6.41 to 5.71 pts, error-per-stack-point reduced from 0.94 to 0.88. Added `smooth_correlated_stack()` function to `spread_generator.py` with parameters `smooth_stacks`, `stack_cap_start`, `stack_cap_factor`, `altitude_travel_interaction`. Enabled by default.
- **Added Distance-Based Timezone Penalty Dampening** - Fixed over-aggressive timezone penalty for short-distance regional games. Analysis showed 500-800mi games crossing timezone lines (due to DST quirks or CT/ET border) had +3.83 mean error vs -0.87 for no-TZ games. The fix: (1) **<400 miles**: TZ penalty eliminated entirely (truly regional games like Illinois @ Purdue); (2) **400-700 miles**: TZ penalty reduced by 50% (e.g., Arizona @ Colorado at 623mi now gets 0.25 pts instead of 0.50); (3) **>700 miles**: Full TZ penalty (true cross-country travel). This ensures timezone effects are only applied when there's meaningful travel fatigue. Updated `get_total_travel_adjustment()` in `travel.py`.
- **Expanded Special Teams to Full PBTA Model** - Complete overhaul of special teams from FG-only to comprehensive FG + Punt + Kickoff model. All components now expressed as PBTA (Points Better Than Average) - the marginal point contribution per game compared to a league-average unit. Key changes: (1) Added `YARDS_TO_POINTS = 0.04` constant for field position value conversion, (2) Punt rating now converts net yards above expected (40 yds) to points + inside-20 bonus (+0.5 pts) + touchback penalty (-0.3 pts), (3) Kickoff rating combines coverage (touchback rate, return yards allowed) and returns (return yards gained), all converted to points, (4) Overall ST = simple sum of components (no weighting needed since all in points). FBS distribution: mean ~0, std ~1.0, 95% range [-2, +2] pts/game. Top 2024 ST unit: Vanderbilt (+2.34 pts/game), worst: UTEP (-2.83 pts/game). Added `calculate_punt_ratings_from_plays()`, `calculate_kickoff_ratings_from_plays()`, and `calculate_all_st_ratings_from_plays()` to `src/models/special_teams.py`.
- **Implemented Neutral-Field Ridge Regression (MAJOR FIX)** - Fixed systematic -6.7 mean error caused by double-counting home field advantage. The issue: CFBD EPA data implicitly contains HFA (home teams naturally generate better EPA), so ridge regression learned team coefficients with HFA baked in. When SpreadGenerator added explicit HFA, this caused double-counting. The fix: Add a home field indicator column to the ridge regression design matrix (+1 for offense=home, -1 for offense=away, 0 for neutral). This separates true team strength from implicit HFA. The learned implicit HFA is ~0.006 SR (~0.6% success rate advantage) and ~0.02 IsoPPP (~0.8 pts combined)â€”much smaller than explicit HFA (~2.5 pts), confirming most HFA manifests at scoring/outcome level rather than play-level efficiency. Results: Mean error improved from -6.7 to -0.40 (2024) and +0.51 (2022-2024), a 94% reduction in systematic bias. ATS performance maintained at 50.9% overall, 56.2% at 5+ edge.
- **Added Weather Adjustment Module** - New `WeatherAdjuster` class for totals prediction. Fetches weather data from CFBD API (`get_weather` endpoint) and calculates adjustments based on wind speed (>10 mph: -0.3 pts/mph, capped at -6.0), temperature (<40Â°F: -0.15 pts/degree, capped at -4.0), and precipitation (>0.02 in: -3.0 pts, >0.05 in: -5.0 pts). Indoor games (`game_indoors=True`) receive no adjustment. Added `get_weather()` method to `CFBDClient`. Weather data includes temperature, wind speed/direction, precipitation, snowfall, humidity, and weather condition text. Analysis of 2024 late-season games showed: 19/757 indoor games, temperatures ranging 16Â°F-86Â°F, wind up to 26 mph, 39 games with precipitation.
- **Added FPI Ratings Comparison** - New `scripts/compare_ratings.py` for 3-way JP+ vs FPI vs SP+ validation. Added `get_fpi_ratings()` and fixed `get_sp_ratings()` in CFBD client to use correct `RatingsApi` endpoint. Initial 2025 comparison shows JP+ correlates r=0.956 with FPI, r=0.937 with SP+. Key divergence: JP+ ranks Ohio State #1, Indiana #2; FPI/SP+ have Indiana #1.
- **Fixed Sign Convention Bugs** - Complete audit found 2 bugs: (1) `spread_generator.py:386` had `home_is_favorite = prelim_spread < 0` (wrong, should be `> 0`), causing rivalry boost to be applied to favorites instead of underdogs; (2) `html_report.py:250` had inverted CSS class logic. Backtest comparison: 3+ edge ATS improved from 53.3% to **54.0%** (+0.7%, +8 net wins). MAE improved from 12.39 to 12.37. Documented sign conventions in SESSION_LOG Rules section.
- **Investigated Mercy Rule Dampener (NOT implemented)** - Theory: coaches tap brakes in blowouts, so apply non-linear dampening to extreme spreads. Finding: Bias exists (-38.7 mean error on 21+ spreads) and dampening improves MAE (-1.66), BUT hurts ATS (-2.8pp). Our large edges are correct directionally even when magnitude is off. Decision: Accept worse MAE to maintain betting edge.
- **Investigated Pace-Based Margin Scaling (NOT implemented)** - Theory suggested fast games should have larger margins (more plays to compound efficiency edge). Empirical analysis showed opposite: fast games have smaller margins (RÂ²=2.2%), JP+ over-predicts (not under-predicts) fast games, and ATS is actually better in fast games (73% vs 67.6%). Vegas already prices pace. Decision: Do not implement.
- **Documented Mean Error vs ATS Trade-off** - Investigated -6.7 mean error. Root cause: CFBD EPA data implicitly contains home field advantage, causing double-counting with explicit HFA. **UPDATE:** This issue was FIXED in February 2026 via neutral-field ridge regression (see above). Mean error is now ~0.
- **Updated 2025 Top 25 with Full CFP Data** - Top 25 now includes all 46 postseason games and 6,223 playoff plays. Indiana (#2, National Champions) beat Alabama 38-3, Oregon 56-22, and Miami 27-21 in CFP.
- **Added Rules & Conventions to SESSION_LOG** - Critical rules: (1) Top 25 must use end-of-season + playoffs, (2) ATS from walk-forward only, (3) optimize for ATS not mean error, (4) parameters flow through config, (5) sign conventions documented.
- **Added Asymmetric Regression for Preseason Priors** - Fixed spread compression problem for blowout games. Standard regression pulled ALL teams toward mean uniformly, causing bad teams (Kent State -25) to gain 7.5 pts they didn't earn. Now regression scales by distance from mean: teams within Â±8 pts get normal 30% regression, teams 20+ pts from mean get only 10% regression. Additionally, talent weight is halved (40%â†’20%) for extreme teams to trust proven performance over talent projections. Result: rating spread preserved at 90% vs 70% before.
- **Added Triple-Option Team Adjustment** - Fixed systematic underrating of triple-option teams (Navy, Army, Air Force, Kennesaw State). These teams were showing as underdogs when Vegas had them as favorites because: (1) SP+ efficiency metrics don't capture their scheme's value, (2) service academies have artificially low recruiting rankings. Applied +6 pt boost to raw SP+ ratings and 100% prior weight (no talent blend). Result: 2024 early season ATS improved from 49.5% to 51.1%.
- **Added QB Injury Adjustment System** - Manual flagging system for starter injuries. Pre-computes depth charts from CFBD player PPA data, calculates starter/backup differential, applies adjustment = PPA_drop Ã— 30 plays/game. Usage: `--qb-out TEAM` CLI flag. Example adjustments: Georgia -6.8 pts, Ohio State -10.0 pts, Texas +8.0 pts (Arch Manning backup is better).
- **Added Time Decay Parameter (but NOT used)** - Tested time decay (weighting recent games more) in 2D sweep with alpha. Finding: decay consistently hurts performance across all alpha values. Best config is alpha=50, decay=1.0 (no decay). Walk-forward already ensures temporal validity. Parameter added but defaults to 1.0.
- **Tested Havoc Rate (NOT implemented)** - Investigated replacing turnovers with Havoc Rate (TFLs, sacks, PBUs). Finding: Havoc correlates with turnovers forced (r=0.425) but neither provides ATS edgeâ€”Vegas already prices both. Kept current turnover approach.
- **Tested Style Mismatch Adjustment (NOT implemented)** - Tested rush/pass style profiles for matchup advantages. Finding: Made predictions worse (ATS -0.2pp, MAE +0.09). Vegas already prices style matchups efficiently.
- **Added Turnover Margin Component (10%)** - JP+ now includes per-game turnover margin as 10% of the overall rating, matching SP+'s approach. Turnovers are identified from play-by-play data (interceptions, fumble recoveries) and converted to point value using 4.5 points per turnover. The efficiency and explosiveness weights were adjusted from 60/40 to 54/36 to accommodate the new component. (Later rebalanced to 45/45/10 via Explosiveness Uplift.) **Bayesian shrinkage** (prior_strength=10) regresses turnover margin toward 0 based on games played, preventing overweighting of small-sample luck while trusting sustained performance. This captures teams like Indiana (+15 margin) and Notre Dame (+17 margin) who create systematic turnover advantages that pure efficiency metrics miss.
- **Reduced Red Zone Regression Strength (20â†’10)** - The prior_strength for RZ TD rate regression was reduced from 20 to 10 to better credit elite RZ teams at end of season. Impact: 5+ edge ATS improved from 54.8% to 55.3%.
- **Added FBS-Only Filtering** - Ridge regression training data now excludes plays involving FCS opponents. FCS teams have insufficient games against FBS opponents to estimate reliable coefficients, so including them pollutes the regression. FCS games are handled separately via the FCS Penalty (+24 pts). Impact: 5+ pt edge improved from 54.0% â†’ 54.8% (+0.8%). This is the cleanest data pipeline for opponent adjustment.
- **Validated Asymmetric Garbage Time** - After implementing FBS-only filtering, re-tested symmetric vs asymmetric GT. Asymmetric remains superior: 5+ edge 54.8% vs 53.0% for symmetric. Asymmetric GT also improves Indiana's ranking (#4 â†’ #2), properly crediting teams that maintain efficiency in blowouts.

### January 2026
- **Added Transfer Portal Integration** - Preseason priors now incorporate net transfer portal impact on rosters. Fetches portal entries from CFBD API, matches transfers to prior-year player usage (PPA), and calculates net incoming - outgoing production for each team. The portal adjustment modifies effective returning production with `portal_scale=0.15` and caps at Â±15%. This addresses the gap where returning production only captured players who stayed, not incoming transfers. Impact: 5+ pt edge improved from 53.3% â†’ 53.7% (+0.4%). Added `fetch_transfer_portal()`, `fetch_player_usage()`, `calculate_portal_impact()` to `preseason_priors.py`. New CLI flags: `--no-portal`, `--portal-scale`.
- **Tuned efficiency/explosiveness weights from 65/35 to 60/40** - Comparison with SP+ identified that explosive teams (Ole Miss, Texas Tech) were being underrated with 35% explosiveness weight. Tested weight configurations across 2022-2025: 60/40 showed best multi-year performance (MAE 12.63, ATS 51.3%, 5+ edge 54.5%). This better captures big-play ability while maintaining efficiency as the dominant signal.
- **Exposed separate O/D/ST ratings** - EFM now calculates and exposes separate offensive, defensive, and special teams ratings. The `TeamEFMRating` dataclass includes `offensive_rating`, `defensive_rating`, and `special_teams_rating` fields. New methods: `get_offensive_rating()`, `get_defensive_rating()`, `get_special_teams_rating()`, `set_special_teams_rating()`. The `get_ratings_df()` output now includes offense, defense, and special_teams columns. This enables future game totals prediction by predicting each team's expected points scored.
- **Added FG Efficiency Adjustment** - Integrated field goal Points Above Average Expected (PAAE) into spread predictions. Calculates each team's kicking efficiency vs expected make rates by distance (<30yd: 92%, 30-40: 83%, 40-50: 72%, 50-55: 55%, 55+: 30%). The FG differential is applied as an adjustment to the spread. Impact: ATS improved from 50.6% â†’ 51.2% (+0.6%), MAE improved from 12.57 â†’ 12.47 (-0.10). Added `calculate_fg_ratings_from_plays()` and `get_fg_differential()` to `src/models/special_teams.py`.
- **Added FCS Penalty (+24 pts)** - When FBS teams play FCS opponents, add 24 points to the FBS team's predicted margin. Diagnostic analysis revealed JP+ was under-predicting blowouts by 26 points (99.5% of errors were under-predictions). The penalty directly addresses this: MAE improved from 13.11 â†’ 12.57 (-0.54 pts), 5+ edge ATS improved to 53.2%. Only affects ~3% of games (FCS matchups).
- **Named the overall model JP+** (homage to SP+); EFM remains the core engine
- **Added Returning Production adjustment** - Prior year ratings now regressed based on % of PPA returning. High returning production = less regression, low returning = more regression. Improved ATS from 51.0% to 51.3%.
- **Implemented team-specific HFA** - Replaced flat 2.5 pt HFA with curated team-specific values (1.5-4.0 range) based on stadium environment. Elite venues like LSU (4.0) get more credit; weak environments like UMass (1.5) get less. Conference defaults used for unlisted teams.
- **Added HFA trajectory modifier** - Dynamic adjustment (Â±0.5 pts) for rising/declining programs. Compares recent win % (1 year) to baseline (prior 3 years). Rising programs like Vanderbilt and Indiana get HFA boost; declining programs get penalty. Captures that home field advantage evolves with program trajectory.
- **Added Coaching Change Regression** - When a new HC arrives at an underperforming team, JP+ dampens prior year drag and weights talent more heavily. Uses data-driven coach pedigree scores (calculated from career win %, P5 experience) to determine how much to "forget" prior underperformance. Elite coaches (Kiffin, Cignetti, Sumrall) at talent-rich programs can see +2 to +4 point rating boosts. First-time HCs receive neutral treatment (no prediction, no penalty).
- Created Efficiency Foundation Model (EFM) as the core engine
- Added garbage time filtering (down-weight blowout plays)
- Fixed double-counting issues in adjustment layer
- Comprehensive documentation created
- **Added Red Zone regression (Finishing Drives)** - Implemented Bayesian regression for red zone TD rate toward league mean (58%). Uses prior_strength=10 to pull extreme rates toward average while trusting actual performance. Multi-year validation showed consistent improvement: MAE improved 0.04-0.10 pts and ATS improved 1-2% across all four years (2022-2025). This is now part of the EFM pipeline.
- **Reduced Red Zone regression strength (prior_strength 20â†’10)** - Analysis showed the original prior_strength=20 was too aggressive for end-of-season ratings. With 150+ RZ plays per team, elite RZ performance (like Indiana's 87% TD rate) is a genuine skill, not luck. Reducing to 10 better credits teams that sustain elite RZ efficiency over a full season. This fixed an issue where regression was flipping Indiana's RZ advantage over Ohio State.

### Explored but Not Included
- **OOC Credibility Weighting (Rejection #12)** - Hypothesis: weight intra-conference plays by opponent's OOC exposure density to improve relative ordering within G5 conferences. Implementation: Z = ooc_games / league_avg, multiplier `1.0 + scale*(Z-1.0)` for intra-conf plays. 5-variant sweep (0.0, 0.25, 0.50, 0.75, 1.0): monotonic 5+ Edge degradation 54.7%â†’54.1%. Root cause: G5 circularity is variance-driven (<0.5% bias), so no play-level weight geometry change helps. Infrastructure preserved (default 0.0 = disabled).
- **Penalty Discipline PPA (Rejection #11)** - Hypothesis: penalty yards per play is a persistent coaching signal not captured by SR/IsoPPP. 3 variants tested (0.5/1.0/2.0 pts per stddev of penalty rate). All degraded 5+ Edge by 0.5-0.9%. Failure mode: market-visible signal â€” penalties are in every box score, so novel to model but not novel to market.
- **LASR Money Down Weighting (Rejection #10)** - Hypothesis: 3rd/4th down plays are more revealing of team quality. Weight multiplier for conversion situations. 5+ Edge degraded -0.7%. Failure mode: sub-metric redundancy â€” success rate already captures conversion efficiency.
- **Roster Churn Penalty (Rejection #9)** - Portal churn percentage as early-season penalty. 3+ Edge improved but 5+ Edge degraded -0.4%. Classic 3+/5+ divergence pattern.
- **Defensive Weight Split (Rejection #7)** - Hypothesis: defense controls SR more than IsoPPP, so shift defensive weighting toward SR. 3 variants (55/35, 60/30, 65/25): all degraded 5+ Edge monotonically. Surprise finding: defensive IsoPPP IS predictive â€” preventing big plays is a persistent trait.
- **MOV Calibration (Rejection #2)** - 4 weights (0.05-0.20) tested. All degraded 5+ Edge. MOV makes model more like market, reducing edge. The model's value is efficiency insights the market doesn't capture.
- **Finishing Drives (Rejections #1, 4 variants)** - Post-hoc sub-model with 70-80% signal overlap with EFM's IsoPPP. Not opponent-adjusted. Games with highest FD contribution had worst MAE. Shelved; RZ efficiency integrated as EFM Ridge feature instead.
- **Time Decay / Recency Weighting** - Full 5Ã—5 grid sweep: 5 alphas Ã— 5 decays (1.0 to 0.92). No decay (1.0) was best across ALL alpha values. Walk-forward already ensures temporal validity; early data provides opponent graph calibration.
- **Defense Full-Weight Garbage Time** - Hypothesis: when a team is winning by 17+ in Q4, their defense should get full weight (1.0) instead of asymmetric weighting (where trailing offense gets 0.1x). This would give defensive dominance full credit in blowouts. Implementation added `defense_full_weight_gt` parameter with separate O/D regression weights. Results: Rankings improved for teams like Indiana (#4â†’#2), Georgia (#9â†’#8), Ole Miss (#14â†’#12), which matched better with consensus rankings. BUT 5+ edge ATS regressed from 57.3% to 56.5% (-0.8%). Decision: **REJECTED**. The "right" rankings hurt predictive accuracy. Current asymmetric GT appears correctly calibratedâ€”giving defense extra credit in garbage time may overcredit "prevent defense" situations that don't reflect true skill. ATS is our optimization target (Rule #4), so we keep standard asymmetric weighting.
- **Dynamic Ridge Alpha** - Hypothesis: use higher regularization (alpha=75) early season when data is noisy, lower (alpha=35) late season to let elite teams separate more. Results: Dynamic alpha (75â†’50â†’35 by week) produced same MAE but hurt 5+ edge ATS from 56.4% to 55.7% (-0.7%). Decision: **REJECTED**. Walk-forward backtesting already self-regularizes via sample size. Lower alpha late-season benefits ALL teams equally, not just elite ones.
- **Increased Turnover Shrinkage** - Hypothesis: turnovers are ~50-70% luck, so prior_strength=10 may over-credit turnover margin. Tested prior_strength 5/10/20/30. Results: prior_strength=10 is optimal for 5+ edge (56.4%). Higher shrinkage (20-30) slightly improved 3+ edge but hurt high-conviction bets. Decision: **KEEP current** prior_strength=10.
- **Turnover-Worthy Plays (TWP) proxy** - Built model using pass breakups and sacks as proxies for interceptable passes and fumble-worthy plays. Multi-year validation showed inconsistent results (helped 2023/2025, hurt 2024). Removed to avoid overfitting.
- **Field Position Component** - Investigated adding field position as JP+ component (SP+ uses 10% weight). Data source: CFBD DrivesApi provides start_yardline. **Problem:** Raw field position is heavily confounded by scheduleâ€”good teams have WORSE raw FP (r = -0.56 with SP+) because they face better punters/coverage and score more TDs (receiving kickoffs at own 25). Even after ridge regression opponent adjustment, correlation remains negative (r = -0.63). Tried cleaner "Return Game Rating" using punt/kick return yards: weak correlation with team quality (r = +0.20) and very weak correlation with overperformance (r = +0.06). Top 30 return teams overperformed by only +5.3 ranks on average. Decision: **TABLED**. Signal too weak to justify complexity. May revisit with proper ATS backtest.

<!-- Last validated: 2026-02-10 by generate_docs.py -->
