# JP+ Power Ratings Model - Architecture & Documentation

**Last Updated:** February 14, 2026 (auto-generated by generate_docs.py)

## Overview

**JP+** is a College Football power ratings model designed for sports betting analysis, inspired by Bill Connelly's SP+. The model generates predicted point spreads for games and compares them against Vegas lines to identify betting opportunities.

### Goals
- Predict game margins with low Mean Absolute Error (MAE)
- Achieve >52% win rate Against The Spread (ATS) for profitable betting
- Identify high-confidence plays where model disagrees significantly with Vegas

---

## Backtest Performance (2022-2025)

Walk-forward backtest across 4 seasons covering the full CFB calendar (3,657 games). Model trained on data available at prediction time â€” no future leakage.

*All metrics verified 2026-02-14.*

### Understanding the Metrics

- **MAE (Mean Absolute Error):** Average points off from actual margin. Vegas closing lines typically have MAE ~11-12 vs actuals â€” college football is inherently unpredictable.
- **RMSE (Root Mean Squared Error):** Like MAE but penalizes large misses more. RMSE > MAE indicates occasional blowout misses; the gap shows tail risk.
- **ATS (Against The Spread):** Win rate vs Vegas spread. 52.4%+ is profitable at -110 odds.
- **CLV (Closing Line Value):** How the market moves after we identify an edge. Positive CLV = sharp money agrees with us. Gold standard for real edge.

### Performance by Season Phase

| Phase | Weeks | Games | MAE | RMSE | ATS % (Close) | ATS % (Open) | 3+ Edge (Close) | 5+ Edge (Close) | 5+ Edge (Open) |
|-------|-------|-------|-----|------|---------------|--------------|-----------------|-----------------|----------------|
| Calibration | 1-3 | 960 | 14.01 | 17.51 | 46.9% | 47.1% | 47.9% | 51.1% | 50.9% |
| **Core** | **4-15** | **2,485** | **12.51** | **15.82** | **51.7%** | **53.0%** | **53.1%** | **55.1%** | **57.0%** |
| Postseason | 16+ | 176 | 13.38 | 16.78 | 48.0% | 49.4% | 47.7% | 47.3% | 48.7% |
| **Full Season** | All | 3,657 | 12.92 | 16.29 | 50.2% | 51.2% | 51.3% | 53.3% | 54.6% |

**Phase insights:**
- **Calibration (Weeks 1-3)**: Model relies heavily on preseason priors; ATS underperforms until in-season data accumulates
- **Core (Weeks 4-15)**: Profitable zone â€” 55.1% ATS at 5+ edge vs closing, 57.0% vs opening
- **Postseason excluded**: Bowl/CFP games have unmodeled factors (opt-outs, coaching changes, transfer portal, motivation variance) â€” essentially a different sport

### Core Season Detail (Weeks 4-15)

The Core phase is where the model is profitable. Detailed breakdowns below focus on this 2,489-game sample.

#### Against The Spread (ATS)

| Edge Filter | vs Closing Line | vs Opening Line |
|-------------|-----------------|-----------------|
| **All picks** | 1260-1177 (51.7%) | 1299-1151 (53.0%) |
| **3+ pt edge** | 737-652 (53.1%) | 791-637 (55.4%) |
| **5+ pt edge** | 463-378 (55.1%) | 509-384 (57.0%) |

Opening line performance exceeds closing line by ~2-3%, indicating the model captures value that the market prices out by game time. LSA (Learned Situational Adjustment) can further improve 5+ Edge vs closing.

#### ATS by Season (Core, vs Closing Line)

| Year | Games | ATS % | 3+ Edge | 5+ Edge |
|------|-------|-------|---------|---------|
| 2022 | 605 | 53.2% | 188-172 (52.2%) | 117-105 (52.7%) |
| 2023 | 611 | 52.5% | 203-165 (55.2%) | 124-101 (55.1%) |
| 2024 | 631 | 50.4% | 193-167 (53.6%) | 124-101 (55.1%) |
| 2025 | 638 | 52.7% | 180-146 (55.2%) | 108-84 (56.2%) |

2024 was the weakest overall ATS year, but the Core 5+ edge still hit 55.1%. The edge concentrates in high-conviction plays regardless of year.

#### ATS by Season (Core, vs Opening Line)

| Year | Games | ATS % | 3+ Edge | 5+ Edge |
|------|-------|-------|---------|---------|
| 2022 | 605 | 52.6% | 192-160 (54.5%) | 118-100 (54.1%) |
| 2023 | 611 | 54.8% | 202-158 (56.1%) | 132-97 (57.6%) |
| 2024 | 631 | 52.0% | 200-173 (53.6%) | 144-101 (58.8%) |
| 2025 | 638 | 53.7% | 197-151 (56.6%) | 115-84 (57.8%) |

#### Closing Line Value (CLV)

CLV measures how the market moves after we identify an edge. Positive CLV = sharp money agrees with us.

**Regular Season (Weeks 1-15, 3,445 games):**

| Edge Filter | N | Mean CLV | CLV > 0 | ATS % (Close) |
|-------------|---|----------|---------|---------------|
| All picks | 3,621 | -0.29 | 28.6% | 50.7% |
| 3+ pt edge | 2,233 | -0.41 | 26.0% | 51.6% |
| **5+ pt edge** | **1,486** | **-0.43** | **25.0%** | **52.6%** |
| 7+ pt edge | 920 | -0.46 | 22.5% | 51.6% |

**CLV vs Opening Line (value available at bet time):**

| Edge Filter | N | Mean CLV (Openâ†’Close) | CLV > 0 | ATS % (Open) |
|-------------|---|----------------------|---------|--------------|
| All picks | 3,621 | +0.43 | 38.6% | 51.6% |
| 3+ pt edge | 2,237 | +0.60 | 39.5% | 53.4% |
| **5+ pt edge** | **1,528** | **+0.73** | **40.7%** | **54.5%** |
| 7+ pt edge | 955 | +0.88 | 39.5% | 54.5% |

When measured against opening lines, CLV is strongly positive (+0.73 at 5+ edge) and monotonically increasing with edge size â€” the market moves toward JP+'s predictions by closing. This is a classic indicator of real edge.

**Interpretation:** CLV vs closing is slightly negative (the market doesn't fully move to us), but ATS is strongly positive. This pattern suggests JP+ exploits structural inefficiencies (public bias, schedule spots) rather than information sharps eventually price in.

### MAE & RMSE by Season (Regular Season Only)

| Year | Games | MAE | RMSE | MAE (Core) | RMSE (Core) | MAE (Cal) |
|------|-------|-----|------|------------|-------------|-----------|
| 2022 | 852 | 13.30 | 16.88 | 12.67 | 16.24 | 14.96 |
| 2023 | 866 | 12.74 | 16.13 | 12.48 | 15.75 | 13.06 |
| 2024 | 872 | 13.08 | 16.35 | 12.66 | 15.76 | 14.97 |
| 2025 | 855 | 12.47 | 15.80 | 12.25 | 15.55 | 13.09 |
| **All** | **3,445** | **12.90** | **16.27** | **12.51** | **15.82** | **14.01** |

**Notes:**
- Best MAE in 2025 (12.25 Core), improving from 12.67 in 2022
- Calibration MAE drops significantly in 2025 (13.09 vs 14-15 in prior years) â€” better priors calibration
- RMSE/MAE ratio ~1.26 across all slices, indicating reasonably consistent error distribution

### 2025 Season Performance

JP+'s most recent season â€” best Core MAE (12.25) and solid 5+ Edge performance.

| Phase | Weeks | Games | MAE | RMSE | ATS % (Close) | ATS % (Open) | 3+ Edge (Close) | 3+ Edge (Open) | 5+ Edge (Close) | 5+ Edge (Open) |
|-------|-------|-------|-----|------|---------------|--------------|-----------------|----------------|-----------------|----------------|
| Calibration | 1-3 | 244 | 13.09 | 16.60 | 51.2% | 49.6% | 86-66 (56.6%) | 83-69 (54.6%) | 67-47 (58.8%) | 65-49 (57.0%) |
| **Core** | **4-15** | **638** | **12.25** | **15.60** | **51.9%** | **52.5%** | **177-150 (54.1%)** | **192-153 (55.7%)** | **100-86 (53.8%)** | **113-89 (55.9%)** |
| **Regular Season** | **1-15** | **882** | **12.47** | **15.80** | **51.7%** | **51.7%** | **263-216 (54.9%)** | **275-222 (55.3%)** | **167-133 (55.7%)** | **178-138 (56.3%)** |

**2025 highlights:**
- Calibration phase shows strongest 5+ Edge (58.8% Close, 57.0% Open) â€” QB Continuous helping early-season predictions
- Core 5+ Edge solid at 53.8% (Close) and 55.9% (Open)
- Regular Season 5+ Edge: 55.7% (Close), 56.3% (Open)

### 2025 Top 25 (End of Season Including CFP)

*Note: Backtest metrics use regular season only (weeks 1-15), but final power ratings include postseason to capture each team's full body of work.*

| Rank | Team | Overall | Off (rank) | Def (rank) | ST (rank) |
|------|------|---------|------------|------------|-----------|
| 1 | **Ohio State** | +30.3 | +12.7 (8) | +15.6 (3) | +2.00 (13) |
| 2 | Indiana | +29.5 | +17.1 (2) | +11.0 (8) | +1.54 (19) |
| 3 | Miami | +26.5 | +10.5 (14) | +13.4 (4) | +2.49 (8) |
| 4 | Notre Dame | +26.3 | +12.9 (7) | +12.4 (5) | +0.97 (33) |
| 5 | Texas Tech | +25.3 | +4.9 (36) | +17.5 (1) | +2.87 (5) |
| 6 | Oregon | +24.0 | +13.0 (6) | +10.2 (10) | +0.82 (44) |
| 7 | Alabama | +22.0 | +9.8 (16) | +11.8 (6) | +0.39 (61) |
| 8 | Utah | +21.9 | +13.5 (4) | +7.5 (22) | +0.87 (39) |
| 9 | Vanderbilt | +20.3 | +18.6 (1) | -1.0 (71) | +2.84 (6) |
| 10 | Georgia | +19.7 | +8.1 (19) | +8.6 (18) | +3.04 (4) |
| 11 | Oklahoma | +19.0 | +2.1 (51) | +15.8 (2) | +1.20 (27) |
| 12 | Ole Miss | +17.7 | +12.2 (11) | +2.0 (47) | +3.49 (2) |
| 13 | Louisville | +17.4 | +6.4 (29) | +8.5 (19) | +2.48 (9) |
| 14 | Tennessee | +17.1 | +11.1 (12) | +1.9 (49) | +4.09 (1) |
| 15 | Washington | +16.7 | +10.9 (13) | +6.4 (28) | -0.57 (91) |
| 16 | South Florida | +16.1 | +8.0 (21) | +7.2 (23) | +0.94 (34) |
| 17 | Florida State | +16.1 | +12.3 (10) | +1.7 (50) | +2.06 (12) |
| 18 | Texas A&M | +15.2 | +7.5 (23) | +7.2 (24) | +0.52 (56) |
| 19 | BYU | +15.1 | +7.5 (24) | +7.0 (25) | +0.58 (53) |
| 20 | James Madison | +14.7 | +4.8 (37) | +9.0 (16) | +0.89 (38) |
| 21 | Missouri | +14.2 | +4.5 (40) | +10.3 (9) | -0.56 (90) |
| 22 | SMU | +12.9 | +7.3 (25) | +5.5 (31) | +0.09 (71) |
| 23 | Penn State | +12.5 | +8.6 (18) | +3.5 (39) | +0.40 (60) |
| 24 | USC | +12.4 | +12.4 (9) | -0.6 (67) | +0.59 (52) |
| 25 | Virginia | +12.1 | +1.0 (55) | +9.9 (12) | +1.25 (26) |

**Ohio State** â€” JP+ #1 despite losing to Indiana in CFP semifinal. Best combination of offense (#8) and elite defense (#3). The model values consistent efficiency over tournament results.

**Indiana** â€” National Champions. Beat Alabama 38-3, Oregon 56-22, and Miami 27-21 in CFP. JP+ #2 overall with the #2 offense in the country.

### Betting Line Data Sources

JP+ uses a dual-source approach for betting lines:

#### Historical Data (2022-2025): CFBD API

For historical backtesting, lines are sourced from the [CFBD API](https://collegefootballdata.com/), which aggregates lines from multiple sportsbooks. Provider priority:

1. **DraftKings** (preferred)
2. **ESPN Bet**
3. **Bovada**
4. Fallback to any available (William Hill, Consensus, Caesars)

**FBS games coverage (2022-2025):**
| Provider | Games Used | With Opening Line |
|----------|------------|-------------------|
| DraftKings | 1,360 (39%) | 1,265 (93%) |
| ESPN Bet | 1,007 (29%) | 101 (10%) |
| Bovada | 547 (16%) | 541 (99%) |
| William Hill | 301 (8%) | 0 (0%) |
| Consensus | 241 (7%) | 0 (0%) |
| Other | 44 (1%) | 0 (0%) |
| **Total** | **3,500** | **3,178 (91%)** |

**Note:** Opening line availability varies significantly by provider. DraftKings and Bovada provide opening lines for nearly all their games, while William Hill and Consensus only provide closing lines.

#### Future Data (2026+): The Odds API

For ongoing seasons, opening and closing lines are captured from [The Odds API](https://the-odds-api.com/):

- **Opening lines**: Captured Sunday morning after lines post
- **Closing lines**: Captured Saturday morning before games
- **Cost**: 2 credits/week (1 for opening, 1 for closing)
- **Provider priority**: FanDuel (posts first), DraftKings, BetMGM, Caesars, Bovada

**Capture scripts:**
- `scripts/weekly_odds_capture.py --opening` (run Sunday ~8 AM ET)
- `scripts/weekly_odds_capture.py --closing` (run Saturday ~9 AM ET)

**Data storage:** SQLite database at `data/odds_api_lines.db`

**Merge logic:** The `src/data/betting_lines.py` module merges both sources, preferring The Odds API data when available for better opening line coverage.

---

## Model Architecture

JP+ is built on a foundation model plus an adjustments layer.

### Efficiency Foundation Model (EFM)

The core engine of JP+. Built on play-level efficiency metrics rather than game margins. This approach is more predictive because it measures *how* teams play, not just final scores.

**Key Insight:** "Do not regress on the final score. Regress on the Success Rate per game so that we are measuring efficiency, not just the scoreboard outcome."

#### Components

| Component | Weight | Description |
|-----------|--------|-------------|
| **Success Rate** | 45% | Opponent-adjusted success rate via ridge regression |
| **Explosiveness (IsoPPP)** | 45% | Average EPA on successful plays only |
| **Turnover Margin** | 10% | Per-game turnover differential (see below) |
| **Red Zone Leverage** | Play weighting | Up-weight plays near goal line (see below) |

#### Success Rate Definition
- **1st down:** Gain â‰¥50% of yards needed
- **2nd down:** Gain â‰¥70% of yards needed
- **3rd/4th down:** Gain 100% of yards needed (first down or TD)

#### Garbage Time Filter (Asymmetric)
Garbage time is handled asymmetrically based on which team is winning:
- **Winning team (offense):** Full weight (1.0x) - they earned the blowout
- **Trailing team (offense):** Down-weighted (0.1x) - garbage time noise

Garbage time thresholds:
- 28+ points in 2nd half (quarters 3-4)
- 21+ points in 3rd quarter
- 14+ points in 4th quarter

This preserves signal from dominant teams (Indiana: 56% SR in garbage time) while filtering noise from trailing teams.

#### Red Zone Leverage (Play-Level Weighting)

Plays near the goal line are more predictive of scoring ability than plays in the middle of the field. We apply field-position-based weights at the play level:

| Field Position | Weight | Rationale |
|----------------|--------|-----------|
| Inside 10-yard line | 2.0x | Goal-to-go efficiency is critical |
| Inside 20-yard line | 1.5x | Red zone execution matters more |
| Between opp 40-20 | 0.7x | "Empty yards" â€” successful but didn't threaten |
| Elsewhere | 1.0x | Standard weight |

This integrates red zone efficiency directly into the EFM ridge regression rather than as a post-hoc adjustment. The weighting is applied in `_prepare_plays()` before calculating success rate and IsoPPP.

**Note:** A separate Finishing Drives model (Bayesian regression on drive-level RZ outcomes) was tested but shelved after 4 backtest rejections due to 70-80% signal overlap with IsoPPP. Play-level weighting captures the signal without redundancy.

**Why this matters:** Getting TO the red zone is sustainable skill (captured by Success Rate). Scoring TDs IN the red zone has some variance early in the season, but over 15 games becomes a reliable signal of scheme and talent. The prior_strength was reduced from 20 to 10 to better credit elite red zone teams at end of season.

#### Turnover Margin Component

Turnovers are a significant predictor of team success that pure efficiency metrics miss. A team that forces turnovers and protects the ball gains a systematic advantage not fully captured by Success Rate.

**Implementation:**
1. Identify turnover plays from play-by-play data, classified as interceptions or fumbles
2. Track separately: INTs thrown/forced and fumbles lost/recovered per team per game
3. Apply **different Bayesian shrinkage** for INTs vs fumbles (see below)
4. Convert to point value using `POINTS_PER_TURNOVER = 4.5`

**Turnover play types detected** (verified against CFBD API):

| Category | Play Types |
|----------|------------|
| **Interceptions** | Interception, Interception Return, Interception Return Touchdown, Pass Interception Return |
| **Fumbles** | Fumble Recovery (Opponent), Fumble Return Touchdown |

**Separate INT/Fumble Shrinkage:** Research shows interceptions correlate year-to-year (QB decision-making, defensive scheme) while fumble recoveries are essentially random coin flips. JP+ applies different shrinkage strengths:

```
shrink_int = games_played / (games_played + k_int)     # k_int = 10 (moderate)
shrink_fum = games_played / (games_played + k_fumble)  # k_fumble = 30 (strong)
```

| Games | INT Shrinkage (k=10) | Fumble Shrinkage (k=30) |
|-------|---------------------|------------------------|
| 5 | 33% (5/15) | 14% (5/35) |
| 10 | 50% (10/20) | 25% (10/40) |
| 15 | 60% (15/25) | 33% (15/45) |

**Rationale:** INTs are treated as 50% skill, so they're modestly regressed. Fumble recoveries are treated as ~90% luck, so they're heavily regressed toward zero. This separation improved Core 5+ ATS by +0.3pp vs unified shrinkage in backtesting.

**Why 10% weight?** This mirrors SP+'s approach where turnovers contribute 10% of the overall rating. Higher weights would overfit to turnover luck, while lower weights would miss legitimate ball-security/ball-hawking skill.

**Impact:** Adding the turnover component captures teams like Indiana (2025: +15 margin) and Notre Dame (+17 margin) who create systematic turnover advantages. Ohio State's narrower +3 margin means their efficiency advantage is partially offset by weaker turnover performance.

#### FBS-Only Filtering

The ridge regression training data **excludes plays involving FCS opponents**. When an FBS team plays an FCS opponent (e.g., Indiana vs Indiana State), those plays are removed from the regression entirely.

**Why this matters:**
- FCS teams have too few games against FBS opponents to estimate reliable coefficients
- Including FCS plays pollutes the regression with unreliable team strength estimates
- FCS opponents are handled separately via the dynamic FCS Strength Estimator (10-45 pts based on prior game margins)

This is implemented in `backtest.py` by filtering plays where both offense and defense are in the FBS teams set before passing to the EFM.

#### Special Teams (PBTA)

The special teams model calculates marginal point contribution (PBTA - Points Better Than Average) for each team's ST unit. All components are converted to points per game.

**Components:**

| Component | Calculation | Typical Range |
|-----------|-------------|---------------|
| **Field Goals** | PAAE (Points Added Above Expected) based on make rates by distance | -2 to +1.5 pts/game |
| **Punting** | Net yards vs expected (40 yds) Ã— 0.04 pts/yd + inside-20 bonus (+0.5) + touchback penalty (-0.3) | -1 to +1.5 pts/game |
| **Kickoffs** | Coverage (TB rate, return yards allowed) + Returns (return yards gained), all Ã— 0.04 pts/yd | -0.5 to +0.5 pts/game |

**Overall ST = FG + Punt + Kickoff** (simple sum since all in points)

**FBS Distribution:** Mean ~0, Std ~1.0, 95% range [-2, +2] pts/game

**Integration:** ST ratings are displayed separately from the O/D total. In spread prediction, the ST differential between teams is applied as an adjustment, **capped at Â±2.5 pts** to prevent noisy outliers from dominating the spread. This margin-level cap preserves the underlying ratings while limiting extreme matchup differentials.

#### Key Files
- `src/models/efficiency_foundation_model.py` - Core EFM implementation (includes RZ Leverage weighting)
- `src/models/special_teams.py` - Complete ST model (FG + Punt + Kickoff)
- Ridge regression on Success Rate (Y=0/1 success, X=sparse team/opponent IDs)
- Converts efficiency metrics to point equivalents for spread prediction

---

---

## Adjustments Layer

EFM ratings feed into `SpreadGenerator` which applies game-specific adjustments. These are organized into four categories.

### Summary Table

| Category | Adjustment | Range | Description |
|----------|------------|-------|-------------|
| **Game Context** | Home Field Advantage | 1.5-4.0 pts | Team-specific based on stadium environment |
| | Travel | 0-2.5 pts | Distance and timezone penalties |
| | Altitude | 0-3 pts | High altitude venues (BYU, Air Force, Colorado) |
| | Correlated Stack Smoothing | - | Prevents over-prediction when HFA+travel+altitude combine |
| **Scheduling** | Rest Differential | Â±1.5 pts | Based on actual days between games |
| | Short Week Penalty | -2.5 pts | One team on short week (â‰¤5 days) vs normal/rested opponent |
| | Consecutive Road | -1.5 pts | Second straight road game (travel fatigue compounds) |
| | Letdown Spot | -2.0/-2.5 pts | Big win last week (ranked or rival), facing unranked |
| | Lookahead Spot | -1.5 pts | Rival or top-10 opponent next week |
| | Sandwich Spot | -1.0 pts extra | BOTH letdown AND lookahead (compounding) |
| | ~~Rivalry Boost~~ | ~~+1.0 pts~~ | **REMOVED** â€” Ablation test (2026-02-12) showed boost was noise |
| **Opponent/Pace** | FCS Penalty | 10-45 pts | Dynamic: Bayesian shrinkage from prior FBS-FCS margins |
| | Special Teams | Â±2.5 pts max | ST differential capped to prevent outlier-driven spreads |
| | Pace (Triple-Option) | -10% to -15% | Spread compression for low-play-count games |
| **Manual** | QB Injury | Â±3-10 pts | Flag when starting QB is out |
| **Totals Only** | Weather | varies | Wind, cold, precipitation penalties |

---

### Game Context Adjustments

#### Home Field Advantage

JP+ uses team-specific HFA values based on stadium environment and crowd intensity:

| Tier | HFA Range | Example Teams |
|------|-----------|---------------|
| Elite | 3.5 - 4.0 | LSU, Alabama, Ohio State, Penn State |
| Strong | 3.0 - 3.25 | Nebraska, Wisconsin, Auburn, Boise State |
| Above Average | 2.75 | Texas, Miami, Virginia Tech, James Madison |
| Conference Default | 2.0 - 2.75 | Varies by conference |
| Below Average | 2.0 - 2.25 | Maryland, Rutgers, Vanderbilt |
| Weak | 1.5 - 1.75 | Kent State, Akron, Temple, UMass |

**Conference Defaults:** SEC/Big Ten: 2.75 | Big 12/ACC/Ind: 2.50 | AAC/MW/Sun Belt: 2.25 | MAC/CUSA: 2.00

**Trajectory Modifier:** HFA is adjusted Â±0.5 pts for rising/declining programs. Calculated once at season start by comparing prior year win % to 3-year baseline. Rising programs (Vanderbilt, Indiana 2024) get boost; declining programs get penalty. Natural decay as success becomes the new baseline.

#### Travel

| Component | Value | Condition |
|-----------|-------|-----------|
| **Timezone (East)** | 0.5 pts/zone | Full penalty (losing time) |
| **Timezone (West)** | 0.4 pts/zone | 80% penalty (gaining time) |
| **Distance** | 0.25 pts | 300-1000 miles |
| **Distance** | 0.5 pts | 1000-2000 miles |
| **Distance** | 1.0 pts | 2000+ miles |
| **Hawaii Special** | +2.0 pts | Mainland â†’ Hawaii |

**Distance-Based TZ Dampening:** Short-distance games crossing timezone lines (DST quirks, CT/ET border) were over-penalized. Fix: <400mi = no TZ penalty; 400-700mi = 50% TZ penalty; >700mi = full penalty.

#### Altitude

High-altitude venues (BYU 4,551ft, Air Force 6,621ft, Colorado 5,328ft) penalize visiting sea-level teams 0-3 pts based on elevation differential.

#### Consolidated Adjustment Smoothing (AdjustmentAggregator)

All game adjustments pass through a single aggregator that applies unified environmental stack smoothing to prevent double-counting correlated factors.

**Three-Bucket Architecture:**

| Bucket | Factors | Smoothing | Rationale |
|--------|---------|-----------|-----------|
| **Environmental Stack** | HFA, travel, altitude, rest, consecutive_road | Single-layer soft cap | All physical/venue factors sum linearly, then soft cap for extreme stacks only |
| **Mental** | letdown, lookahead, sandwich | Standard (100%/50%/25%) | Mental factors compound with diminishing returns |
| **Boosts** | ~~rivalry~~ (removed) | Linear sum | Empty after rivalry boost removal (2026-02-12) |

**Environmental Stack Details:**
- All environmental factors (HFA + travel + altitude + rest + consecutive_road) sum linearly first
- **Soft cap applied only to extreme stacks:** Threshold = 5.0 pts, excess weight = 60%
- If |stack| â‰¤ 5.0: no dampening (standard games use linear sum)
- If |stack| > 5.0: `env_score = 5.0 + (excess Ã— 0.60)` with appropriate sign
- This single-layer approach avoids the "double damping" bug where separate bucket smoothing + soft cap created two layers of penalty

**Mental Bucket Details:**
- Largest at 100%, second at 50%, remaining at 25%
- Rationale: A team in letdown AND lookahead is distracted, but distractions don't fully stack

**Global Cap:** Â±7.0 points maximum total adjustment

**Example:** Away team at high-altitude venue with HFA=3.0, travel=1.5, altitude=1.0, rest=0.5:
- Raw env stack: 3.0 + 1.5 + 1.0 + 0.5 = 6.0 pts
- Exceeds threshold (5.0), so: 5.0 + (1.0 Ã— 0.60) = 5.6 pts (not 6.0 raw)
- Standard game with stack â‰¤5.0 gets no dampening at all

---

### Scheduling Adjustments

#### Rest Day Calculation

CFB scheduling creates meaningful rest differentials beyond simple bye weeks:

| Scenario | Days Rest | Example |
|----------|-----------|---------|
| Season Opener | 14 days | Team hasn't played yet this season |
| Bye Week | 14+ days | Didn't play previous week |
| Mini-Bye | 9-10 days | Thursday â†’ Saturday |
| Normal | 6-7 days | Saturday â†’ Saturday |
| Short Week | 4-5 days | Saturday â†’ Thursday |

**Season Opener Advantage:** A team playing their Week 1 opener gets 14 days rest (maximum), giving them a rest advantage over a team that played in Week 0. This correctly models that a fresh team faces a team with normal wear.

**Non-Linear Short Week Penalty:** When one team is on a short week (â‰¤5 days rest) and the other is on normal/rested schedule (>6 days), a hardcoded -2.5 pt penalty applies (not a linear calculation). This reflects that short-week disadvantage is severe and non-linearâ€”it's not just "2 fewer rest days."

**Linear Rest (Other Cases):** `rest_advantage = (home_rest - away_rest) Ã— 0.5 pts/day` (capped at Â±1.5 pts)

**Example:** Oregon (9 days after Thursday game) vs Texas (7 days) = +1.0 pts Oregon

#### Consecutive Road Games Penalty

Teams playing their second consecutive road game receive a -1.5 pt penalty. Travel fatigue compoundsâ€”the physical and mental toll of back-to-back away games exceeds the sum of individual road trips.

**Implementation:** Check if the team's *last played game* (not necessarily last week due to byes) was also an away game. If so, apply the penalty.

**Travel Correlation:** When travel penalty exceeds 1.5 pts (indicating significant distance), the consecutive road penalty is reduced by 50% to prevent double-counting the fatigue component.

#### Letdown, Lookahead, and Sandwich

| Factor | Value | Condition |
|--------|-------|-----------|
| **Letdown Spot (home)** | -2.0 pts | "Big win" last week, facing unranked opponent |
| **Letdown Spot (away)** | -2.5 pts | Same, but traveling (sleepy road game) |
| **Lookahead Spot** | -1.5 pts | Rival or top-10 opponent next week |
| **Sandwich Spot** | -1.0 pts extra | BOTH letdown AND lookahead apply to same team |
| ~~**Rivalry Boost**~~ | ~~+1.0 pts~~ | **REMOVED** â€” Ablation test (2026-02-12) showed boost was noise, not signal |

**Letdown "Big Win" Criteria (either triggers):**
1. Beat a top-15 ranked team (using historical ranking at time of game)
2. Beat an arch-rival (regardless of rival's ranking) â€” "Rivalry Hangover"

**Bye Week Persistence:** If a team has a bye week after a big win, the letdown effect persists. Sitting on a big win for two weeks maintains the "rust" and "hangover" effect. The model finds the team's *last played game* regardless of which week it occurred.

**Staleness Threshold (3 weeks):** If the big win was more than 3 weeks ago (e.g., start of season, multiple byes), the emotional effect has faded and letdown doesn't trigger.

**Sleepy Road Game Multiplier:** Analysis of 89 letdown games (2022-2024) showed clear venue effect:
- Home letdown: 52.4% ATS, +0.1 pts vs spread (crowd keeps team engaged)
- Away letdown: 48.9% ATS, -2.5 pts vs spread (sleepy road game)

The 1.25x away multiplier captures this: home = -2.0 pts, away = -2.5 pts.

**Sandwich Spot:** The most dangerous scheduling spot in CFB. When a team is coming off a massive emotional win (letdown) AND has a massive game on deck next week (lookahead), the unranked team in the middle is the "meat" of the sandwich. This is a rare spot (requires BOTH conditions simultaneously), with initial analysis showing sandwich teams cover ~36% ATS. Total penalty: -4.5 to -5.0 pts. *Note: Small sample size due to rarity of both conditions triggering together.*

**Historical Rankings:** Letdown detection uses **ranking at time of game**, not current ranking. JP+ fetches AP poll week-by-week from CFBD `/rankings` endpoint. Example: If Oregon beat #2 Ohio State in Week 7 (who later dropped to #20), Week 8 still shows letdown spot.

*Note: All situational factors feed into the consolidated AdjustmentAggregator (see Game Context section) for four-bucket smoothing.*

#### Learned Situational Adjustment (LSA) â€” Optional

**Purpose:** Replace fixed situational constants with coefficients learned via walk-forward ridge regression on prediction residuals. Acts as a high-confidence filter for 5+ edge picks.

**CLI:** `--learned-situ` to enable (default OFF for production)

**Architecture:**
- 16 situational features (rest differential, bye/short week, letdown, lookahead, sandwich, rivalry, consecutive road, game shape opener)
- Multi-year pooling: ~3,000+ training samples by week 4 (pools all prior seasons)
- Walk-forward safe: Only trains on games from weeks < prediction week
- EMA smoothing (beta=0.3) for coefficient stability week-to-week
- **Turnover adjustment:** Training residuals adjusted to remove turnover noise (see below)

**Grid Sweep Results (2022-2025, Core weeks 4-15, Closing Line):**

| Config | 3+ Edge | 5+ Edge |
|--------|---------|---------|
| Fixed baseline | **53.4%** | 54.5% |
| LSA + TO-adj | 52.5% | **55.8%** |

**Turnover Adjustment (Training Signal Quality):**

Raw residuals include turnover-driven variance that doesn't reflect situational factors. The turnover adjustment removes this noise:

```python
adjusted_residual = raw_residual - (turnover_margin Ã— turnover_point_value)
# Default: turnover_point_value = 4.0 pts/turnover
```

**Rationale:** If Team A won by 28 but had +3 turnovers, the raw residual is inflated by ~12 pts of turnover luck. Adjusting for this produces cleaner coefficient estimates for situational features like letdown/lookahead.

**Impact:** +0.2pp on 5+ Edge (Close) vs unadjusted LSA (55.6% â†’ 55.8%)

**Parameters (optimized):**
| Parameter | Default | Description |
|-----------|---------|-------------|
| `lsa_alpha` | 300.0 | Ridge regularization strength |
| `lsa_min_games` | 150 | Minimum games before switching from fixed |
| `lsa_ema` | 0.3 | EMA smoothing factor (30% new, 70% prior) |
| `lsa_clamp_max` | 4.0 | Coefficient clamp safety net (no effect at alpha=300) |
| `lsa_adjust_turnovers` | True | Enable turnover-adjusted residuals |
| `lsa_turnover_pts` | 4.0 | Points per turnover for adjustment |

**Key Finding â€” Rivalry Underdog Boost REMOVED (2026-02-12):**

Ablation testing confirmed the +1.0 pt rivalry underdog boost was noise, not signal:

| Metric | With Boost | Without Boost |
|--------|------------|---------------|
| Core 5+ Edge (Close) | 54.7% | **55.1%** (+0.4%) |
| Core 5+ Edge (Open) | 57.2% | 57.1% (neutral) |

The boost has been **removed from production**. Historical analysis showed favorites in rivalry games tend to **WIN BIG**, not cover less â€” the boost was directionally wrong. LSA forensics (108 rivalry underdog home games) showed -3.52 pt actual residual despite +1.0 boost applied.

**Trade-off:** LSA improves 5+ Edge (Close) by +1.3pp (54.5% â†’ 55.8%) while reducing 3+ Edge by -0.9pp (53.4% â†’ 52.5%). This is acceptable because 5+ Edge bets have ~2% over vig vs ~1.3% for 3+ Edge â€” use LSA when filtering to high-conviction plays only.

#### Edge-Aware Production Mode

**Problem:** LSA excels at 5+ edge closing lines but *degrades* 3+ edge. Fixed excels at opening lines. How do we get the best of both?

**Solution:** Edge-aware mode is now the **default behavior** in `run_weekly.py`. No flags needed â€” the engine automatically selects Fixed or LSA based on timing and edge size:

```python
# Implementation in run_weekly.py (automatic, no flags needed)
if days_until_game >= lsa_threshold_days:  # Default: 4 days
    recommendation = "fixed"   # Opening line: always fixed
elif abs(edge_lsa) >= 5.0:
    recommendation = "lsa"     # Closing line, 5+ edge: LSA wins
else:
    recommendation = "fixed"   # Closing line, 3-5 edge: fixed wins
```

**Performance by Timing + Edge:**
| Bet Timing | Edge Size | Mode | ATS % | Rationale |
|------------|-----------|------|-------|-----------|
| Opening (4+ days) | Any | Fixed | **56.5%** (5+) | Raw market inefficiency not yet priced |
| Closing (<4 days) | **5+ pts** | LSA | **55.1%** | LSA's filter excels at high conviction |
| Closing (<4 days) | 3-5 pts | Fixed | **52.9%** | Fixed beats LSA at 3+ edge |

**CLI:**
```bash
# Default behavior - edge-aware mode (no flags needed)
python3 scripts/run_weekly.py --year 2026 --week 5

# Disable LSA entirely (use Fixed for all bets)
python3 scripts/run_weekly.py --year 2026 --week 5 --no-lsa

# Custom timing threshold
python3 scripts/run_weekly.py --year 2026 --week 5 --lsa-threshold-days 3
```

**Output Columns:**
- `jp_spread_fixed` â€” Prediction using fixed situational constants
- `jp_spread_lsa` â€” Prediction using learned coefficients
- `bet_timing_rec` â€” "fixed" or "lsa" based on timing and edge
- `jp_spread_recommended` â€” The spread matching the recommendation

---

### Opponent & Pace Adjustments

#### FCS Opponent Penalty (Dynamic Estimator)

JP+ uses a **walk-forward-safe FCS strength estimator** that calculates per-team penalties from prior FBS-vs-FCS game margins with Bayesian shrinkage.

**Shrinkage Formula:**
```
shrink_factor = n_games / (n_games + k)
shrunk_margin = baseline + (raw_margin - baseline) * shrink_factor
avg_loss = abs(shrunk_margin)  # Convert to positive loss amount
penalty = clamp(intercept + slope * avg_loss, min_pen, max_pen)
```

**Default Parameters (calibrated to match historical static baseline):**
| Parameter | Value | Description |
|-----------|-------|-------------|
| k | 8.0 | Games for 50% trust in data |
| baseline | -28.0 | Prior margin (FCS - FBS, negative = FCS loses) |
| intercept | 10.0 | Base penalty for elite FCS (avg_loss â‰ˆ 0) |
| slope | 0.8 | Penalty increase per point of avg loss |
| min_pen | 10.0 | Floor for elite FCS |
| max_pen | 45.0 | Ceiling for weak FCS |

**Example Penalties:**
| Avg Loss to FBS | Games Observed | FBS Spread Bonus | Example Teams |
|-----------------|----------------|------------------|---------------|
| ~10 pts | 8+ | +18 pts | Elite FCS (NDSU, Montana State) |
| ~28 pts | Any | +32 pts | Average FCS (baseline) |
| 40+ pts | Any | +45 pts | Weak FCS (capped) |

**Walk-Forward Safety:** Estimator only uses games from weeks < current prediction week. No data leakage.

**Fallback:** Use `--fcs-static` for original tiered system (elite=18, standard=32 pts).

#### Pace Adjustment (Triple-Option)

Triple-option teams (Army, Navy, Air Force, Kennesaw State) run ~55 plays/game vs ~70 normal. Analysis shows 30% worse MAE (16.09 vs 12.36, p=0.001).

JP+ compresses spreads 10% toward zero for triple-option games (15% if both teams). This reflects fundamental uncertainty in low-possession games.

**Triple-Option Rating Boost (+6 pts):** Service academies are systematically underrated by efficiency metrics. JP+ applies rating boost and uses 100% prior (no talent blend) to correct this.

---

### QB Continuous Rating (DEFAULT)

Walk-forward-safe QB quality estimates that automatically adjust spreads based on quarterback performance. **Enabled by default** for all predictions.

#### How It Works

1. **Data Source:** CFBD `get_predicted_points_added_by_player_game` for QB PPA, `get_game_player_stats` for dropbacks
2. **Shrinkage:** K=200 (~250 dropbacks â†’ 55% weight on raw signal)
3. **Prior Season:** Decay factor 0.3 for Week 1 projections
4. **Starter ID:** Conservative logic â€” only switch if new QB leads team in most recent game with MIN_RECENT_DB=15 and MIN_CUM_DB=50

#### Phase1-only Mode (DEFAULT)

The key insight: by Week 4, the EFM has already "baked in" QB quality through efficiency metrics. Applying additional QB adjustment causes double-counting and degrades Core ATS.

**Phase1-only mode** applies QB adjustment only for Weeks 1-3, then disables for Core:

| Phase | QB Adjustment | Rationale |
|-------|---------------|-----------|
| Weeks 1-3 | ENABLED | EFM hasn't captured current QB yet |
| Weeks 4+ | DISABLED | EFM efficiency metrics include QB performance |

**Results (2022-2025):**

| Metric | Without QB | With QB Phase1-only | Delta |
|--------|------------|---------------------|-------|
| Phase 1 5+ Edge (Close) | 50.2% | 50.8% | **+0.6%** |
| Phase 1 5+ Edge (Open) | ~50.2% | 50.7% | **+0.5%** |
| Phase 1 MAE | 15.33 | 15.31 | -0.02 |
| Core 5+ Edge | 54.5% | 54.5% | **0.0%** |

**CLI:** `--no-qb-continuous` to disable, `--no-qb-phase1-only` to test full mode (warning: degrades Core)

---

### Manual Adjustments

#### QB Injury

For known injuries NOT captured by the continuous system. Manual flagging system:

1. Pre-compute depth charts from CFBD player PPA data (starter = most pass attempts)
2. Calculate PPA differential between starter and backup
3. Adjustment = `PPA_drop Ã— 30 plays/game`

| Team (2024) | Starter | PPA | Backup | PPA | Adjustment |
|-------------|---------|-----|--------|-----|------------|
| Georgia | Beck | 0.353 | Stockton | 0.125 | **-6.8 pts** |
| Ohio State | Howard | 0.575 | Brown | 0.243 | **-10.0 pts** |
| Texas | Ewers | 0.322 | A. Manning | 0.589 | **+8.0 pts** |
| Alabama | Milroe | 0.321 | Simpson | 0.215 | **-3.2 pts** |

**Usage:** `python scripts/run_weekly.py --qb-out Georgia Texas`

---

### Weather Adjustments (Totals Only)

Weather adjustments use **non-linear thresholds** based on sharp betting research. The edge is in **timing** â€” capture forecasts Thursday before market moves, confirm Saturday with accurate 6-12h forecasts.

#### Data Source
- **API:** Tomorrow.io Hourly Forecast API (free tier: 25 calls/hour, 500/day)
- **Database:** `data/weather_forecasts.db` (SQLite)
- **Venue data:** 795 FBS/FCS stadiums with coordinates + dome detection
- **Rate limiting:** Scripts default to `--limit 20` per run (free tier safe)

#### Confidence Gating

**All weather adjustments are scaled by forecast confidence** based on hours until kickoff:

| Hours Until Game | Confidence Factor | Effect on -6.0 raw |
|------------------|-------------------|-------------------|
| â‰¤6h | 0.95 | -5.7 pts |
| 6-12h | 0.90 | -5.4 pts |
| 12-24h | 0.85 | -5.1 pts |
| 24-48h | 0.75 | -4.5 pts |
| >48h (Thursday) | 0.65 | -3.9 pts |

**HIGH_VARIANCE Flag:** If `confidence < 0.75` AND `abs(raw_adjustment) > 3.0`, the game is flagged `high_variance=True`. **Rule: Never bet OVER on these games** â€” weather is uncertain but potentially severe.

#### Wind Thresholds (Non-Linear Tiers)

Wind is the #1 driver of totals movement. Uses **effective wind = (wind_speed + wind_gust) / 2**.

| Effective Wind | Base Adjustment | Rationale |
|----------------|-----------------|-----------|
| <12 mph | 0.0 pts | No impact |
| 12-15 mph | -1.5 pts | Deep passing degraded |
| 15-20 mph | -4.0 pts | Kicking range reduced, deep ball erased |
| >20 mph | -6.0 pts | Run-only game profiles, clock runs constantly |

**"Passing Team" Multiplier:** Continuous scaling based on combined pass rate:
```
multiplier = combined_pass_rate / 0.50 (clamped to [0.5, 1.5])
```

| Team Style | Pass Rate | Multiplier | 20 mph Wind (after scaling) |
|------------|-----------|------------|----------------------------|
| Triple Option (Army) | 35% | 0.70x | -4.2 pts |
| Run-Heavy | 40% | 0.80x | -4.8 pts |
| Balanced | 50% | 1.00x | -6.0 pts |
| Pass-Heavy | 60% | 1.20x | -7.2 pts |
| Air Raid (Ole Miss) | 65% | 1.30x | -7.8 pts |

#### Temperature Thresholds

| Temperature | Adjustment | Rationale |
|-------------|------------|-----------|
| >32Â°F | 0.0 pts | No impact |
| 20-32Â°F | -1.0 pts | "Rock effect" â€” cold balls harder to catch/kick |
| <20Â°F | -3.0 pts | Severe mechanics impact |

#### Precipitation Thresholds

**The "Slick Trap":** Light rain does NOT hurt totals. Defenders slip, miss tackles, games can go OVER.

| Condition | Adjustment | Rationale |
|-----------|------------|-----------|
| Light rain (<0.1 in/hr) | 0.0 pts | The "slick trap" â€” no penalty |
| Heavy rain (>0.3 in/hr) | -2.5 pts | Ball security issues, conservative playcalling |
| Snow with wind (â‰¥12 mph) | -3.0 pts | Visual impairment, footing, swirling snow |
| Snow without wind | 0.0 pts | "Overreaction Fade" â€” sharps bet OVER |

**"Snow Overreaction Fade":** Public loves betting "Snow Unders" but snow without wind often goes OVER. Defenders slip, receivers know their routes. Only apply snow penalty if wind â‰¥12 mph.

#### Two-Stage Capture Workflow

| Stage | Timing | Confidence | Purpose |
|-------|--------|------------|---------|
| Thursday 6 AM | 72h out | 65% | Early alert, bet before market moves |
| Saturday 8 AM | 6-12h out | 90%+ | Confirmation, final model input |

**Saturday comparison:** Uses **earliest** forecast per game (not latest) to ensure comparison against original Thursday morning capture, even if script was re-run for debugging.

**Cron automation:** `./scripts/setup_weather_cron.sh install`

#### Integration with JP+ TotalsModel

The Thursday/Saturday capture scripts:
1. Train TotalsModel walk-forward on weeks 1 to (current_week - 1)
2. Predict JP+ total for each game
3. Apply weather adjustment to JP+ prediction
4. Compare to Vegas total to calculate edge
5. Generate watchlist sorted by edge (most negative = strongest UNDER signal)

**Edge interpretation:**
- Edge < -3 pts = ðŸ”¥ STRONG UNDER
- Edge < 0 pts = ðŸ“‰ LEAN UNDER
- Edge > 0 pts = Skip (JP+ higher than Vegas)

**Indoor games** (via dome detection) receive no weather adjustment.

**Scripts:**
- `scripts/weather_thursday_capture.py` â€” Main capture + watchlist
- `scripts/weather_thursday_capture.py --saturday` â€” Saturday confirmation mode

---

### Adjustments Key Files

| File | Purpose |
|------|---------|
| `src/predictions/spread_generator.py` | Combines all components |
| `src/adjustments/aggregator.py` | Four-bucket smoothing for all adjustments |
| `src/adjustments/home_field.py` | Team-specific HFA & trajectory |
| `src/adjustments/travel.py` | Distance/timezone |
| `src/adjustments/altitude.py` | Altitude adjustment |
| `src/adjustments/situational.py` | Rest, letdown, lookahead, rivalry (raw values) |
| `src/adjustments/qb_adjustment.py` | QB injury system |
| `src/adjustments/weather.py` | Weather adjuster (non-linear thresholds, pass rate scaling) |
| `src/api/tomorrow_io.py` | Tomorrow.io forecast API client + venue database |
| `scripts/weather_thursday_capture.py` | Thursday/Saturday capture workflow |

---

## Preseason Priors

Bayesian blending of preseason expectations with in-season performance.

### Prior Sources (weighted blend)
1. **Previous year's SP+ ratings** (60%) - Regressed toward mean based on returning production
2. **Composite recruiting rankings** (40%) - Talent level

### Returning Production Adjustment

The regression factor for prior year ratings is adjusted based on returning production (% of PPA returning):

| Returning PPA | Regression Factor | Effect |
|---------------|-------------------|--------|
| 100% | 10% | Trust prior rating (same team) |
| 50% | 30% | Baseline regression |
| 0% | 50% | Heavy regression (roster turnover) |

This prevents overvaluing teams that lost key players and undervaluing teams returning most of their production.

### Credible Rebuild Adjustment

**Problem:** Low-RP teams get heavy regression, but some have legitimate reasons for optimism: elite recruiting classes or strong portal additions that RP data can't capture.

**Solution:** Credible Rebuild identifies teams with extremely low RP (â‰¤35%) who have strong talent signals, and reduces their regression penalty during Weeks 1-3 before EFM captures their quality.

#### Qualification Criteria

- Returning Production â‰¤ 35%
- AND at least one of:
  - Talent (recruiting) normalized score â‰¥ 0.65
  - Portal normalized score â‰¥ 0.65

#### Relief Calculation

| Parameter | Default | Description |
|-----------|---------|-------------|
| `rp_cutoff` | 0.35 | Max RP to trigger |
| `max_relief` | 0.25 | Max regression reduction (25%) |
| `talent_threshold` | 0.65 | Min talent_norm to qualify |
| `portal_threshold` | 0.65 | Min portal_norm to qualify |
| `week_end` | 5 | Week by which relief tapers to 0 |

**Credibility Score:** `0.5 Ã— talent_norm + 0.5 Ã— portal_norm`

**Relief Formula:** `relief = max_relief Ã— credibility` (capped so `reg_new >= reg_cutoff`)

**Week Taper:** Linear from 100% (Week 1) to 0% (Week 5)

#### Trigger Rate by Year

| Year | Triggered | Total | Rate | Mean Relief |
|------|-----------|-------|------|-------------|
| 2022 | 14 | 234 | 6.0% | +0.31 pts |
| 2023 | 14 | 239 | 5.9% | +0.18 pts |
| 2024 | 13 | 135 | 9.6% | +0.24 pts |
| 2025 | 17 | 137 | 12.4% | +0.34 pts |

#### Notable Examples

| Team | Year | RP | Relief | Rationale |
|------|------|-----|--------|-----------|
| Ole Miss | 2022 | 3% | +0.97 pts | Lane Kiffin's portal army |
| Florida State | 2024 | 21% | +0.39 pts | Post-CFP exodus |
| Colorado | 2025 | 7% | +0.35 pts | Strong recruiting despite portal loss |

#### Backtest Impact

| Metric | Without Rebuild | With Rebuild | Delta |
|--------|-----------------|--------------|-------|
| Phase 1 5+ Edge | 50.2% | 50.4% | **+0.2%** |
| Core 5+ Edge | 55.1% | 55.1% | unchanged |

**Design principle:** Conservative by design â€” triggers on <15% of teams, applies modest relief (+0.2-0.4 pts average), and tapers to zero before Core phase begins.

**CLI:** `--no-credible-rebuild` to disable.

### Asymmetric Regression

Standard regression pulls all teams toward the mean uniformlyâ€”but this compresses the true spread between elite and terrible teams. A very bad team at -25 shouldn't gain 7.5 points just from regression.

JP+ applies **asymmetric regression**: teams far from the mean regress less than teams near the mean.

| Distance from Mean | Regression Multiplier | Effective Regression |
|-------------------|----------------------|---------------------|
| Â±8 pts | 1.0x | 30% (baseline) |
| Â±14 pts | 0.67x | 20% |
| Â±20+ pts | 0.33x | 10% |

**Example:** Kent State at raw -25 rating:
- Old (uniform): -25 Ã— 0.7 = -17.5 (lost 7.5 pts of badness)
- New (asymmetric): -25 Ã— 0.9 = -22.5 (kept most of badness)

**Extremity-Weighted Talent:** For extreme teams (20+ pts from mean), talent blend weight is reduced from 40% to 20%. This trusts proven performance over talent projections for outlier teams, preventing the talent component from compressing ratings back toward average.

### Transfer Portal Adjustment

The returning production metric only captures players who stayedâ€”it doesn't account for incoming transfers. JP+ uses a **unit-level approach** with scarcity-based position weights and level-up discounts to value all portal activity (100% coverage vs the old 18% player-matching approach).

#### Scarcity-Based Position Weights

Reflects 2026 market reality where elite trench play is the primary driver of rating stability:

| Tier | Position | Weight | Rationale |
|------|----------|--------|-----------|
| Premium | QB | 1.00 | Highest impact position |
| Premium | OT | 0.90 | Elite blindside protector |
| Anchor | EDGE | 0.75 | Premium pass rushers |
| Anchor | IDL | 0.75 | Interior pressure + run stuffing |
| Support | IOL | 0.60 | Interior OL (guards/centers) |
| Support | LB, S | 0.55 | Run defense, coverage |
| Skill | WR, CB | 0.45 | Higher replacement rate |
| Skill | RB | 0.40 | Most replaceable skill position |

#### Level-Up Discount (G5 â†’ P4 Transfers)

Players transferring from G5 to P4 conferences receive position-based discounts reflecting the competition gap:

| Position Type | Discount | Rationale |
|---------------|----------|-----------|
| Trench (OT, IOL, IDL, LB, EDGE) | 25% | Physicality Tax - steep curve in P4 trench play |
| Skill (WR, RB, CB, S) | 10% | Athleticism translates more easily |
| P4 â†’ P4 | 0% | No discount for lateral moves |
| P4 â†’ G5 | -10% | Boost for proven higher-level players |

#### Continuity Tax

Losing incumbents hurts more than raw talent value suggests (chemistry, scheme fit, experience). Outgoing player values are amplified by ~11% (factor of 0.90).

#### Parameters

| Parameter | Value | Description |
|-----------|-------|-------------|
| `portal_scale` | 0.06 | Converts raw value to % impact |
| `impact_cap` | Â±12% | Maximum team-wide adjustment |
| `continuity_tax` | 0.90 | Loss amplification factor |

#### Example 2024 Portal Winners/Losers

| Winners | Impact | Losers | Impact |
|---------|--------|--------|--------|
| Ole Miss | +12% | USC | -12% |
| Colorado | +5% | Stanford | -12% |
| SMU | +7% | Washington | -12% |
| Rice | +8% | Texas | -12% |

#### Blue Blood Validation

Blue Bloods hitting the -12% portal cap show minimal final rating impact because their elite talent composite offsets the losses:

| Team | Portal Impact | Talent Score | Rating Î” |
|------|---------------|--------------|----------|
| Alabama | -12% | +26.0 | -0.3 pts |
| Ohio State | -12% | +24.6 | -0.3 pts |
| Georgia | -12% | +25.2 | -0.4 pts |

The model correctly captures heavy portal losses while talent integration provides the expected offset.

#### Backtest Impact (2024-2025)

A/B comparison shows minimal but slightly positive effect on Core Season 5+ edge:

| Phase | With Portal | Without Portal | Î” |
|-------|-------------|----------------|---|
| Calibration (1-3) 5+ Edge | 47.5% | 48.2% | -0.7% |
| Core (4-15) 5+ Edge | **55.5%** | 54.8% | **+0.7%** |

The muted effect is expected: portal adjusts regression factor (indirect), talent composite provides primary Blue Blood offset, and preseason priors fade by week 8.

### Coaching Change Regression

When a new head coach arrives at an underperforming team (talent rank > performance rank), JP+ dampens the prior year's "drag" and weights talent more heavily. This captures the reality that a talented team stuck under a bad coach may improve significantly with new leadership.

#### The "Forget Factor"

```
talent_gap = performance_rank - talent_rank  (positive = underperformer)
base_forget = min(0.5, talent_gap / 60)
final_forget = min(0.5, base_forget Ã— coach_pedigree)

prior_weight = 0.6 Ã— (1 - final_forget)
talent_weight = 1 - prior_weight
```

#### Coach Pedigree (Data-Driven)

Pedigree scores are calculated from historical coaching records:
- **Career win %** - Primary driver (+0.25 for 70%+, -0.15 for <45%)
- **P5 HC experience** - +0.03 per year, capped at +0.12
- **Longevity bonus** - +0.03 if 5+ years HC experience

| Tier | Pedigree | Example Coaches |
|------|----------|-----------------|
| Elite | 1.27 - 1.30 | Kiffin (67%, 10 P5 yrs), Kirby Smart (85%), DeBoer (78%) |
| Strong | 1.20 - 1.25 | Cignetti (83% at JMU), Sumrall (78% at Tulane) |
| Above Avg | 1.10 - 1.19 | Rhule (51%, 5 P5 yrs), Venables (56%) |
| Average | 1.05 - 1.09 | Brent Key (53%), Sam Pittman (49%) |
| Neutral | 1.00 | First-time HCs, no record |
| Below Avg | 0.88 - 0.97 | Clark Lea (33%), Jeff Lebby (17%) |

#### Impact Examples

| Scenario | Talent | Perf | Gap | Pedigree | Weight Shift | Rating Î” |
|----------|--------|------|-----|----------|--------------|----------|
| Florida 2025 (Sumrall) | #8 | #45 | 37 | 1.25 | 60/40 â†’ 30/70 | +2 to +4 pts |
| Indiana 2024 (Cignetti) | #50 | #85 | 35 | 1.25 | 60/40 â†’ 30/70 | +2 to +4 pts |
| LSU 2026 (Kiffin) | #6 | #15 | 9 | 1.30 | 60/40 â†’ 48/52 | +0.5 pts |
| Alabama 2024 (DeBoer) | #3 | #5 | 2 | 1.30 | No change | 0 pts |

**Key insight:** First-time HCs (like Brent Key at Georgia Tech, Deion Sanders at Colorado) are **excluded entirely** from the adjustment. We have no basis to predict they'll improve the program, so they receive no boost. The model won't predict their breakout, but it also won't penalize the program.

**Known limitation:** Career win % embeds "opportunity" (better jobs â†’ higher win %), not purely coaching skill. A 65% win rate at Alabama means something different than 65% at Kansas. Ideally we'd normalize by prior team talent, but this adds complexity for a feature with small sample size.

**Backtest validation:** The coaching change adjustment showed neutral impact on MAE/ATS across 2023-2025 (sample of affected games too small). This is a qualitative signal with limited statistical powerâ€”included for conceptual completeness but shouldn't be expected to provide measurable ATS lift.

### Decay Schedule
| Week | Preseason Weight | In-Season Weight |
|------|------------------|------------------|
| 1 | 100% | 0% |
| 4 | 62% | 38% |
| 8 | 15% | 85% |
| 12+ | 0% | 100% |

#### Key Files
- `src/models/preseason_priors.py` - Prior calculation, returning production adjustment, and blending

---

## Data Pipeline

### Data Sources
- **College Football Data API (CFBD)** - Games, plays, betting lines, team info
- API client: `src/api/cfbd_client.py`

### Data Flow
```
CFBD API
    â”‚
    â”œâ”€â”€ Games (scores, neutral site, dates)
    â”œâ”€â”€ Betting Lines (spreads, totals)
    â”œâ”€â”€ Play-by-Play (down, distance, yards, PPA)
    â”œâ”€â”€ Field Goal Plays (distance, made/missed)
    â”œâ”€â”€ Transfer Portal (player movements, ratings)
    â”œâ”€â”€ Player Usage (prior-year PPA by player)
    â”œâ”€â”€ Returning Production (% PPA returning)
    â”œâ”€â”€ Team Info (FBS teams, conferences)
    â”œâ”€â”€ Weather (temperature, wind, precipitation, indoor flag)
    â”œâ”€â”€ SP+ Ratings (external benchmark)
    â””â”€â”€ FPI Ratings (ESPN, external benchmark)
    â”‚
    â–¼
Preseason Priors
    â”‚
    â”œâ”€â”€ Prior SP+ ratings (regressed)
    â”œâ”€â”€ Talent composite
    â”œâ”€â”€ Transfer portal net impact
    â””â”€â”€ Coaching change adjustment
    â”‚
    â–¼
EFM Training
    â”‚
    â”œâ”€â”€ Success Rate calculation per play
    â”œâ”€â”€ Garbage time filtering
    â”œâ”€â”€ Ridge regression for opponent adjustment
    â””â”€â”€ FG efficiency calculation (PAAE)
    â”‚
    â–¼
SpreadGenerator
    â”‚
    â””â”€â”€ Apply adjustments â†’ Predicted Spread
```

---

## File Structure

```
CFB Power Ratings Model/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py              # Configuration management
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ cfbd_client.py       # CFBD API client
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ processors.py        # Data processing
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ efficiency_foundation_model.py  # Core EFM engine (includes RZ Leverage)
â”‚   â”‚   â”œâ”€â”€ preseason_priors.py  # Preseason ratings & coaching regression
â”‚   â”‚   â”œâ”€â”€ special_teams.py     # FG + punt + kickoff efficiency
â”‚   â”‚   â””â”€â”€ finishing_drives.py  # [SHELVED] RZ model (replaced by RZ Leverage in EFM)
â”‚   â”œâ”€â”€ adjustments/
â”‚   â”‚   â”œâ”€â”€ home_field.py        # Team-specific HFA & trajectory
â”‚   â”‚   â”œâ”€â”€ travel.py            # Travel adjustments
â”‚   â”‚   â”œâ”€â”€ altitude.py          # Altitude adjustments
â”‚   â”‚   â”œâ”€â”€ situational.py       # Situational factors
â”‚   â”‚   â”œâ”€â”€ qb_adjustment.py     # QB injury adjustment system
â”‚   â”‚   â””â”€â”€ weather.py           # Weather adjustments for totals
â”‚   â””â”€â”€ predictions/
â”‚       â”œâ”€â”€ spread_generator.py  # Combines all components
â”‚       â””â”€â”€ vegas_comparison.py  # Compare to Vegas lines
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ backtest.py              # Walk-forward backtesting
â””â”€â”€ docs/
    â””â”€â”€ MODEL_ARCHITECTURE.md    # This file
```

---

## Usage

### Running Backtests

```bash
# Standard JP+ backtest (uses optimized defaults)
python scripts/backtest.py --use-efm

# Parameter sweep
python scripts/backtest.py --use-efm --sweep

# Custom parameters
python scripts/backtest.py --years 2024 2025 --use-efm --alpha 50 --fcs-k 8 --fcs-intercept 10
```

### CLI Options

| Flag | Default | Description |
|------|---------|-------------|
| `--years` | 2022-2025 | Years to backtest |
| `--start-week` | 4 | First week to predict |
| `--use-efm` | Required | Use JP+ (EFM-based) model - always include this flag |
| `--alpha` | 50.0 | Ridge regularization strength (optimized via sweep) |
| `--hfa` | 2.5 | Base home field advantage in points |
| `--fcs-static` | False | Use static FCS elite list instead of dynamic estimator |
| `--fcs-k` | 8.0 | FCS shrinkage k (games for 50% trust in data) |
| `--fcs-intercept` | 10.0 | Base FCS penalty for elite FCS (calibrated to historical baseline) |
| `--fcs-slope` | 0.8 | FCS penalty increase per point of avg loss |
| `--fcs-max-pen` | 45.0 | Maximum FCS penalty (capped for weak FCS) |
| `--fcs-penalty-elite` | 18.0 | Points for elite FCS (only used with --fcs-static) |
| `--fcs-penalty-standard` | 32.0 | Points for standard FCS (only used with --fcs-static) |
| `--no-asymmetric-garbage` | False | Disable asymmetric garbage time (enabled by default) |
| `--no-portal` | False | Disable transfer portal adjustment |
| `--portal-scale` | 0.15 | Weight for transfer portal impact |
| `--sweep` | False | Run parameter grid search |
| `--no-priors` | False | Disable preseason priors |

### Weekly Predictions (run_weekly.py)

```bash
# Generate predictions for current week
python scripts/run_weekly.py --year 2025 --week 10

# With QB injury adjustments
python scripts/run_weekly.py --year 2025 --week 10 --qb-out Georgia Texas

# With delta cache (only fetches current week from API, loads historical from Parquet cache)
python scripts/run_weekly.py --year 2025 --week 10 --use-delta-cache
```

| Flag | Default | Description |
|------|---------|-------------|
| `--year` | Current | Season year |
| `--week` | Current | Week to predict |
| `--qb-out` | None | Teams whose starting QB is out (space-separated) |
| `--use-delta-cache` | Off | Load historical weeks from Parquet cache, fetch only current week from API |

### Edge Execution Engine

The Edge Execution Engine is the decision layer that transforms raw predictions into actionable bet recommendations. It implements probability-based filtering validated across 3,445 games.

#### Statistical Foundation

**Breakeven Requirement:** At standard -110 odds, the breakeven win rate is:

```
breakeven = 110 / (100 + 110) = 52.38%
```

Every threshold, mode, and filter is evaluated against this bar. A feature that improves MAE but drops ATS below breakeven is rejected.

**Edge Threshold Sweep (Regular Season, 2022-2025):**

| Threshold | N Games | ATS (Close) | ATS (Open) | EV vs Vig |
|-----------|---------|-------------|------------|-----------|
| 1+ pts | 3,121 | 50.6% | 51.4% | -1.8% / -1.0% |
| 3+ pts | 2,009 | 51.5% | 53.5% | -0.9% / +1.1% |
| **5+ pts** | **1,305** | **53.6%** | **54.9%** | **+1.2% / +2.5%** |
| 7+ pts | 797 | 53.2% | 54.7% | +0.8% / +2.3% |
| 10+ pts | 387 | 52.7% | 53.5% | +0.3% / +1.1% |

The 5+ threshold maximizes the product of (edge over vig) Ã— (sample size). Higher thresholds have diminishing returns; lower thresholds fail to clear breakeven reliably.

#### Edge Calculation

Edge follows the VegasComparison sign convention:

```python
# Internal spread: positive = home favored
# Vegas spread: negative = home favored
edge = (-model_spread_internal) - vegas_spread

# Interpretation:
#   edge < 0 â†’ Model likes HOME more than Vegas â†’ Bet HOME
#   edge > 0 â†’ Model likes AWAY more than Vegas â†’ Bet AWAY
```

**Example:**
- JP+ spread: +7.0 (home favored by 7)
- Vegas spread: -3.0 (home favored by 3)
- Edge: (-7.0) - (-3.0) = -4.0 â†’ JP+ likes home 4 pts more â†’ Bet HOME

#### Edge-Aware Mode Selection

The engine selects Fixed or LSA mode based on timing and edge magnitude:

```python
def get_recommendation(days_until_game: int, edge_lsa: float) -> str:
    if days_until_game >= 4:  # Opening line
        return "fixed"        # Fixed: 56.5% at 5+ edge
    elif abs(edge_lsa) >= 5.0:  # Closing, high conviction
        return "lsa"          # LSA: 55.1% at 5+ edge
    else:                     # Closing, moderate conviction
        return "fixed"        # Fixed: 52.9% at 3+ edge
```

**Validation (Core Weeks 4-15, N=2,485):**

| Context | Mode | N (5+ Edge) | ATS % | 95% CI |
|---------|------|-------------|-------|--------|
| Opening (4+ days) | Fixed | 476 | 56.5% | [52.0%, 61.0%] |
| Closing, 5+ edge | LSA | 391 | 55.1% | [50.1%, 60.1%] |
| Closing, 3-5 edge | Fixed | 550 | 52.9% | [48.7%, 57.1%] |

Confidence intervals computed via bootstrap resampling (10,000 iterations).

#### Phase 1 Risk Controls

Phase 1 (Weeks 1-3) has distinct characteristics requiring separate handling:

**Phase 1 vs Core Comparison:**

| Metric | Phase 1 | Core | Delta |
|--------|---------|------|-------|
| Prior dependence | 92% | 35% | Model is SP+ wrapper early |
| Error Std | 17.55 | 15.81 | Higher variance |
| 5+ Edge ATS (Close) | 51.1% | 55.1% | -4.0% |
| Mean Signed Error | +0.90 | +0.46 | Home bias amplified |

#### CLI Reference

```bash
# Edge-Aware Mode (default, no flags needed)
python scripts/run_weekly.py --year 2026 --week 5

# Disable LSA (Fixed only)
python scripts/run_weekly.py --no-lsa

# Custom timing threshold
python scripts/run_weekly.py --lsa-threshold-days 3
```

| Flag | Default | Description |
|------|---------|-------------|
| `--no-lsa` | Off | Disable LSA, use Fixed for all predictions |
| `--lsa-threshold-days` | 4 | Days before game to switch from Fixed to LSA |

#### Output Schema

The engine produces the following columns in `comparison_df`:

| Column | Type | Description |
|--------|------|-------------|
| `jp_spread_fixed` | float | Spread using Fixed situational |
| `jp_spread_lsa` | float | Spread using LSA coefficients |
| `edge_fixed` | float | Edge vs Vegas (Fixed) |
| `edge_lsa` | float | Edge vs Vegas (LSA) |
| `bet_timing_rec` | str | "fixed" or "lsa" |
| `jp_spread_recommended` | float | Spread per recommendation |
| `edge_recommended` | float | Edge per recommendation |
| `sp_spread` | float | SP+ spread (Phase 1 only) |
| `sp_edge` | float | SP+ edge vs Vegas |
| `sp_gate_category` | str | "confirms", "neutral", "opposes", "missing" |
| `phase1_sp_gate_passed` | bool | Whether game passes gate |

### Production Spread Betting System (2026+)

The production spread betting system converts JP+ predictions into actionable bet recommendations with calibrated EV estimation, phase-aware routing, and automated logging.

**Implementation:** `scripts/run_spread_weekly.py`

#### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SpreadGenerator â”‚â”€â”€â”€â”€â–¶â”‚  EV Calibration   â”‚â”€â”€â”€â”€â–¶â”‚ Selection Policy â”‚
â”‚  (predictions)   â”‚     â”‚  (edge â†’ P(cover))â”‚     â”‚  (filtering)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â–¼                            â–¼                â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  List A   â”‚              â”‚  List B   â”‚      â”‚ CSV Log  â”‚
                        â”‚ (EV bets) â”‚              â”‚ (5+ edge) â”‚      â”‚ (append) â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Phase Routing

The system uses different configurations for different parts of the season:

| Phase | Weeks | Calibration | Policy | ev_floor | Stake | Note |
|-------|-------|-------------|--------|----------|-------|------|
| **Phase 1** | 1-3 | `weighted` | EV_THRESHOLD | 2% | 0.5x | âš ï¸ Calibration less reliable |
| **Phase 2** | 4-15 | `phase2_only` | TOP_N (n=3) | 1% | 1.0x | Primary betting phase |
| **Phase 3** | 16+ | `phase2_only` | TOP_N (n=3) | 1% | 1.0x | Postseason |

**Phase 1 Rationale:** Early-season predictions rely heavily on priors (51.1% ATS at 5+ edge vs 55.1% in Core). The system uses:
- **EV_THRESHOLD policy** â€” Takes ALL bets above 2% EV (no arbitrary cap)
- **Higher EV floor (2%)** â€” Only highest-conviction plays
- **Half stakes (0.5x)** â€” Reduced exposure during uncertain period

This approach is more principled than an arbitrary bet cap: if 5 games have legitimate 3%+ EV, bet them all at half stakes rather than picking 2 arbitrarily.

#### Selection Policy Presets

Three presets are available, with `balanced` as the production default:

| Preset | Policy | top_n | ev_floor | ev_min | max_bets |
|--------|--------|-------|----------|--------|----------|
| `conservative` | TOP_N_PER_WEEK | 2 | 2.0% | 3.0% | 2 |
| **`balanced`** | **TOP_N_PER_WEEK** | **3** | **1.0%** | **3.0%** | **3** |
| `aggressive` | EV_THRESHOLD | â€” | 0.5% | 2.0% | 5 |

**TOP_N_PER_WEEK:** Takes the top N bets by EV each week, subject to ev_floor minimum. This ensures consistent volume while avoiding marginal bets.

**EV_THRESHOLD:** Takes all bets above ev_min threshold. Higher variance, more bets in good weeks, fewer in bad weeks.

#### EV Calculation

Expected Value is computed from calibrated cover probability:

```python
# Calibration: logistic regression trained on walk-forward edge â†’ cover outcomes
p_cover = predict_cover_probability(edge_abs, calibration_result)

# EV at standard -110 odds
implied_prob = 110 / 210  # 0.524
ev = (p_cover * 1.909) + ((1 - p_cover) * -1.0) - 1.0
# Simplified: ev = p_cover - implied_prob (approximately)
```

**Calibration Modes:**
- `weighted`: Uses Phase 1 + Phase 2 data with Phase 2 weighted higher (for weeks 1-3)
- `phase2_only`: Uses only Core season data (for weeks 4+)

#### Output Lists

The system produces two distinct bet lists:

| List | Selection Criteria | Purpose |
|------|-------------------|---------|
| **List A** | EV â‰¥ ev_floor, passes selection policy | Primary betting recommendations |
| **List B** | Edge â‰¥ 5 pts, NOT in List A | Diagnostic â€” high disagreement games |

List B captures games where JP+ strongly disagrees with Vegas but EV doesn't meet threshold. These are tracked for analysis but not recommended for betting.

#### CLI Usage

```bash
# Generate weekly recommendations (balanced preset, weighted Phase 1)
python scripts/run_spread_weekly.py --year 2026 --week 5

# Use aggressive preset
python scripts/run_spread_weekly.py --year 2026 --week 5 --preset aggressive

# Skip Phase 1 EV bets (List B only for weeks 1-3)
python scripts/run_spread_weekly.py --year 2026 --week 2 --phase1-policy skip

# Dry run (no CSV logging)
python scripts/run_spread_weekly.py --year 2026 --week 5 --dry-run

# Settle completed bets
python scripts/run_spread_weekly.py --year 2026 --week 5 --settle
```

| Flag | Default | Description |
|------|---------|-------------|
| `--preset` | `balanced` | Selection policy preset |
| `--phase1-policy` | `weighted` | Phase 1 mode: `weighted` (EV bets) or `skip` (List B only) |
| `--phase1-stake` | `0.5` | Stake multiplier for Phase 1 bets |
| `--dry-run` | Off | Print recommendations without logging |
| `--settle` | Off | Update CSV with actual results |

#### CSV Logging

Bets are logged to `data/spread_selection/logs/spread_bets_{year}.csv` with deduplication by `(year, week, game_id, side)`.

**Key columns:**
- `run_timestamp`: When recommendation was generated
- `phase`, `calibration_name`: Routing info
- `ev`, `p_cover`, `edge_pts`: EV calculation inputs
- `stake`, `stake_multiplier_used`: Position sizing
- `list_type`: "A" (EV bet) or "B" (5+ edge diagnostic)
- `guardrail_reason`: Why game is in List B (e.g., "BELOW_EV_THRESHOLD")
- `actual_margin`, `covered`, `profit_units`: Filled by settlement

#### Settlement

Settlement updates unsettled rows with actual results:

```bash
python scripts/run_spread_weekly.py --year 2026 --week 5 --settle
```

Adds:
- `actual_margin`: Home margin from CFBD
- `covered`: "W", "L", or "P" (push)
- `profit_units`: +0.909 (win), -1.0 (loss), 0.0 (push)
- `settled_timestamp`: When settled

---

## Key Design Decisions

### 1. Why Efficiency-Based (not Margin-Based)?
- Margins are noisy (turnovers, garbage time, late scores)
- Success Rate is more stable and predictive
- Play-level data captures *how* teams perform, not just outcomes

### 2. Why Ridge Regression?
- Handles opponent adjustment naturally (sparse team IDs as features)
- Regularization prevents overfitting to small samples
- Fast and interpretable

### 3. Why Preseason Priors?
- Early season has insufficient data
- Recruiting rankings and prior performance are predictive
- Bayesian blending smoothly transitions to in-season data

### 4. Double-Counting Prevention
- Base ratings contain ONLY the EFM output + preseason blend
- All adjustments (HFA, FCS penalty, FG efficiency, etc.) applied ONCE at prediction time
- SpreadGenerator is the single point where components combine

### 5. Neutral-Field Ridge Regression

JP+ uses a neutral-field ridge regression to produce true team strength ratings that are independent of home field advantage.

**The Problem (before fix):** The CFBD EPA values (which feed into EFM) implicitly contain home field advantageâ€”home teams naturally generate better EPA due to crowd noise, familiarity, etc. Without correction, the ridge regression learns team coefficients that include this implicit HFA. When SpreadGenerator adds explicit HFA, this caused double-counting and a systematic -6.7 mean error.

**The Solution:** Add a home field indicator column to the ridge regression design matrix:
- `+1` when the offense is the home team (home advantage)
- `-1` when the defense is the home team (away disadvantage)
- `0` for neutral site plays

This allows the model to separately learn:
1. **Team strength** (neutral-field) - the team coefficients
2. **Implicit HFA** - the home indicator coefficient

**Results:**
| Metric | Before | After |
|--------|--------|-------|
| Mean Error (2024) | -6.7 pts | **-0.40 pts** |
| Mean Error (2022-2024) | ~-6.7 pts | **+0.51 pts** |

The mean error is now essentially zero, confirming that double-counting has been eliminated.

**Learned Implicit HFA:**
- Success Rate: ~0.006 (home teams have ~0.6% higher SR)
- IsoPPP: ~0.02 (home teams have ~0.02 higher EPA on successful plays)
- Combined in points: ~0.8 pts of implicit HFA in the play-level data

The learned implicit HFA is small (~0.8 pts) compared to the explicit HFA (~2.5 pts) applied by SpreadGenerator. This is expectedâ€”most HFA manifests at the scoring/outcome level (special teams, turnovers, momentum) rather than pure play-by-play efficiency.

### 6. Opponent-Adjusted Metric Caching

Ridge regression for Success Rate and IsoPPP is computationally intensive. During walk-forward backtesting, this led to O(nÂ²) work accumulationâ€”each prediction week recomputes from scratch, rebuilding the sparse design matrix and fitting the model.

**Two-tier caching strategy:**

**Tier 1 â€” X_base Matrix Cache:** The sparse design matrix (team indicators + home field) is cached separately from weights and targets. X_base depends only on play structure (which teams, which plays) and is independent of time decay, so it can be reused when only the eval_week changes.

```python
# X_base cache key: hash of play structure (teams, home_team, n_plays)
# X_base cache value: (sparse CSR matrix, has_home_info)
```

**Tier 2 â€” Result Cache:** Full Ridge regression results cached by `(season, eval_week, metric_name, ridge_alpha, time_decay, data_hash)`:

```python
# Result cache key structure
cache_key = (2024, 5, "is_success", 50.0, 1.0, "a1b2c3d4e5f6")
#            ^     ^   ^              ^     ^     ^
#            |     |   |              |     |     â””â”€ Data fingerprint
#            |     |   |              |     â””â”€ Time decay factor
#            |     |   |              â””â”€ Ridge alpha
#            |     |   â””â”€ Metric column
#            |     â””â”€ Max training week
#            â””â”€ Season year
```

**Weight pipeline (in `_prepare_plays`):**
- `base_weight` = GT Ã— OOC Ã— RZ Ã— empty_yards (all non-temporal weights, cacheable with X_base)
- `weight` = `base_weight` Ã— time_decay (applied dynamically per eval_week in `_ridge_adjust_metric`)

**Why caching is safe:**
- Ridge regression is deterministic: same inputs â†’ same outputs
- Cache keys include all parameters that affect results
- `data_hash` guards against edge cases where same (season, week) has different data
- X_base is purely structural (team indicators) â€” independent of weights, targets, and time decay

**API:**
```python
from src.models.efficiency_foundation_model import (
    clear_ridge_cache,          # Clear result cache and return stats
    clear_base_matrix_cache,    # Clear X_base cache and return stats
    get_ridge_cache_stats,      # Get hits, misses, size, hit_rate
)
```

---

## Totals Model Baseline (2023-2025)

Separate model for over/under prediction using game-level scoring data (not play-level efficiency like EFM).

### Architecture

- **Training data:** Each game â†’ 2 rows: home team scores X vs away defense, away team scores Y vs home defense
- **Ridge regression:** Solves for team off/def adjustments relative to FBS average (~24 ppg)
- **Learned HFA:** Home field advantage learned via Ridge column (+3.5 to +4.5 pts typical)
- **Walk-forward:** Only uses games from weeks prior to prediction week

**Prediction formula:**
```
home_expected = baseline + (home_off_adj + away_def_adj) / 2 + hfa_coef
away_expected = baseline + (away_off_adj + home_def_adj) / 2
predicted_total = home_expected + away_expected
```

### Performance by Phase (vs Closing Line)

| Phase | Weeks | Games | MAE | ATS % | 3+ Edge | 5+ Edge |
|-------|-------|-------|-----|-------|---------|---------|
| Calibration | 1-3 | 169 | 12.42 | 57.9% | 56.7% (59-45) | **61.1%** (44-28) |
| **Core** | **4-15** | **1,824** | **13.09** | **53.9%** | **54.7%** (539-446) | **54.5%** (334-279) |
| **Regular Season** | **1-15** | **1,993** | **13.03** | **54.3%** | **54.9%** (598-491) | **55.0%** (378-307) |

### Performance by Phase (vs Opening Line)

| Phase | Weeks | Games | MAE | ATS % | 3+ Edge | 5+ Edge |
|-------|-------|-------|-----|-------|---------|---------|
| Calibration | 1-3 | 169 | 12.42 | 55.4% | 57.0% (57-43) | **58.7%** (37-26) |
| **Core** | **4-15** | **1,824** | **13.09** | **53.4%** | **54.2%** (528-447) | **55.3%** (330-267) |
| **Regular Season** | **1-15** | **1,993** | **13.03** | **53.6%** | **54.4%** (585-490) | **55.6%** (367-293) |

### Full Season by Year

| Year | Games | MAE | 3+ Edge (Close) | 3+ Edge (Open) | 5+ Edge (Close) | 5+ Edge (Open) |
|------|-------|-----|-----------------|----------------|-----------------|----------------|
| 2023 | 713 | 13.37 | 55.0% (204-167) | 53.5% (192-167) | 54.0% (143-122) | 55.3% (135-109) |
| **2024** | **706** | **13.03** | **56.2%** (230-179) | **55.6%** (225-180) | **58.6%** (143-101) | **58.2%** (139-100) |
| 2025 | 708 | 12.80 | 53.5% (208-181) | 54.3% (213-179) | 53.2% (118-104) | 53.2% (117-103) |

### Configuration

| Parameter | Value | Notes |
|-----------|-------|-------|
| Years | 2023-2025 | 2022 excluded (scoring environment transition, 49% ATS) |
| Ridge Alpha | 10.0 | Optimal for 5+ Edge |
| Decay Factor | 1.0 | No within-season decay (walk-forward handles temporality) |
| Learned HFA | +3.5 to +4.5 pts | Via Ridge column, not fixed value |
| OT Protection | Disabled | Final scores used (Vegas prices OT potential) |
| Weather | Optional | Available but no ATS improvement |

### Key Findings

- **Calibration phase strongest** â€” opposite of spreads model. Early-season totals more predictable.
- **2024 exceptional** â€” 59.5% 5+ Edge may reflect market recalibration after scoring shift.
- **Learned HFA critical** â€” improved 5+ Edge by +1.6% (Close), +2.1% (Open) vs no/fixed HFA.

---

## Open Items

### Needs Validation
- [x] **EFM alpha parameter sweep** - âœ… DONE. Swept alphas 25-200 across 2022-2025. Optimal: alpha=50 (MAE 12.54, 5+ edge 56.0% vs 55.3% at alpha=100). Updated defaults.

---

## Future Improvements

### High Priority
- [x] **Expose separate O/D/ST ratings** - âœ… DONE. JP+ now exposes separate offensive, defensive, and special teams ratings via `get_offensive_rating()`, `get_defensive_rating()`, `get_special_teams_rating()`, and in `get_ratings_df()` output. This enables future game totals prediction.
- [x] **Add quarterback-specific adjustments for injuries** - âœ… DONE. Added `QBInjuryAdjuster` class that pre-computes depth charts from CFBD player PPA data. Manual flagging via `--qb-out TEAM` CLI flag. Adjustment = PPA drop Ã— 30 plays/game.
- [x] **Game totals prediction (over/under)** - âœ… DONE. Separate TotalsModel using Ridge regression on game-level points (not play-level efficiency). Learned HFA via Ridge column (+3.5 to +4.5 pts). Core 5+ Edge: 54.5% (Close), 55.3% (Open). See "Totals Model Baseline" section.
- [x] **Improve situational adjustment calibration** - âœ… DONE. Two major calibrations: (1) HFA Global Offset (-0.50 pts) reduced systematic home bias from +0.90 to +0.46, improving 5+ Edge by +0.6%; (2) Correlated stack smoothing applies soft cap when HFA+travel+altitude exceeds 5 pts. Both validated via error cohort analysis.

### Medium Priority
- [x] **Multi-year backtesting to validate stability** - âœ… DONE. Walk-forward backtest across 2022-2025 (4 seasons). See "Backtest Performance" section at top of file for current metrics.
- [x] **Weather impact modeling** - âœ… DONE. Full weather system for totals: Tomorrow.io API for forecasts (not CFBD look-back), non-linear thresholds (wind tiers at 12/15/20 mph), "slick trap" (light rain = no penalty), "passing team multiplier" (wind scaled by combined pass rate), "snow overreaction fade" (snow without wind = no penalty). Two-stage capture: Thursday 6 AM (early alert) + Saturday 8 AM (confirmation). Backtest shows market already prices weather (no ATS improvement), but timing edge exists for early movers.
- [x] **Expand special teams beyond FG** - âœ… DONE. Added punt and kickoff ratings to complete ST model. All components expressed as PBTA (Points Better Than Average) per game. Punt rating: net yards vs expected (40 yds) converted to points + inside-20/touchback adjustments. Kickoff rating: coverage (touchback rate, return yards allowed) + returns (return yards gained). Overall = FG + Punt + Kickoff. FBS distribution: mean ~0, std ~1.0, 95% within Â±2 pts/game.

### Low Priority
- [ ] Real-time line movement tracking

### 2026 Production Planning

#### Bet Execution Automation

**Problem:** Major US sportsbooks (DraftKings, FanDuel, BetMGM, Caesars) prohibit API-based betting. All wagers must be placed manually through their apps/websites, creating friction between model signal and bet execution.

**Solution: Discord-Based Alert System with Deep Links**

1. **Discord Bot Integration**
   - Model generates betting signals (Thursday weather watchlist, weekly spread picks)
   - Bot posts to private Discord channel with formatted alerts
   - Alerts include: matchup, JP+ line, Vegas line, edge, recommended stake
   - Supports role-based notifications (@weather-bets, @spread-bets, @5pt-edge)

2. **Mobile Deep Links**
   - Generate sportsbook-specific deep links that open directly to the bet slip
   - DraftKings: `draftkings://sportsbook/event/{event_id}`
   - FanDuel: `fanduel://sportsbook/event/{event_id}`
   - One-tap from Discord notification â†’ pre-populated bet slip
   - Reduces execution time from ~60 seconds to ~10 seconds

3. **Execution Tracking**
   - Bot tracks which alerts were acted on (reaction-based confirmation)
   - Logs actual bet placement for P&L tracking
   - Compares intended vs actual execution for slippage analysis

**Implementation:** `src/notifications/discord_bot.py`, `src/notifications/deep_links.py`

#### API Betting Exchanges (Full Automation)

**Opportunity:** Sports betting exchanges allow programmatic order placement, enabling true automation without manual intervention.

**Platforms to Evaluate:**

1. **Sporttrade**
   - US-regulated exchange (NJ, CO)
   - REST API for order placement
   - Spread betting via limit orders
   - Commission: ~2% on winnings
   - **Key question:** Liquidity depth on CFB spreads/totals. NFL likely deep, CFB may be thin.

2. **ProphetX (Prophet Exchange)**
   - US-regulated (NJ)
   - WebSocket API for real-time odds
   - Supports spread and total markets
   - Commission: ~2% on winnings
   - **Key question:** Can we get filled at our target price, or do we move the market?

3. **Novig**
   - Peer-to-peer model
   - Lower margins than traditional books
   - API access available
   - **Key question:** Counterparty availability for CFB markets

**Liquidity Analysis Required:**
- Monitor order book depth for 20+ CFB games across 4 weeks
- Measure bid-ask spread at various stake sizes ($100, $500, $1000)
- Track fill rates and slippage on simulated orders
- Compare effective odds to DK/FD closing lines

**If Liquidity Sufficient:**
- Full automation pipeline: Model signal â†’ API order â†’ Execution confirmation
- Kelly-sized stakes based on edge magnitude
- Real-time P&L dashboard
- Automatic hedging on line movement

**Implementation:** `src/betting/exchange_client.py`, `src/betting/order_manager.py`

#### Kelly Criterion Stake Sizing

**Problem:** Current system treats all bets equally (flat betting). A 3-point edge and an 8-point edge get the same stake, leaving money on the table.

**Solution: Kelly Criterion for Optimal Bankroll Growth**

The Kelly formula maximizes long-term bankroll growth by sizing bets proportional to edge:

```
f* = (bp - q) / b

where:
  f* = fraction of bankroll to wager
  b  = decimal odds - 1 (for -110 juice, b = 0.909)
  p  = probability of winning (derived from JP+ edge)
  q  = probability of losing (1 - p)
```

**Edge-to-Win-Probability Conversion:**

| JP+ Edge | Implied Win % | Full Kelly | Half Kelly |
|----------|---------------|------------|------------|
| 3 pts | 54.5% | 4.5% | 2.25% |
| 5 pts | 57.5% | 9.5% | 4.75% |
| 7 pts | 60.0% | 14.0% | 7.0% |
| 10 pts | 64.0% | 21.0% | 10.5% |

**Practical Implementation:**
1. **Use Half-Kelly or Quarter-Kelly** â€” Full Kelly is mathematically optimal but assumes perfect edge estimation. Fractional Kelly reduces variance and accounts for model uncertainty.
2. **Cap maximum stake** â€” Never exceed 5% of bankroll on single bet regardless of calculated Kelly.
3. **Bankroll tracking** â€” Maintain running bankroll ledger to recalculate stakes weekly.
4. **Confidence adjustment** â€” Scale Kelly fraction by model confidence (Phase 1 bets get smaller Kelly than Phase 2).

**Bankroll Simulation (Backtest):**
- Simulate 2022-2025 seasons with Kelly sizing vs flat betting
- Measure: Total return, max drawdown, Sharpe ratio, risk of ruin
- Validate that Kelly outperforms flat betting on historical data

**Implementation:** `src/betting/kelly.py`, `src/betting/bankroll.py`

#### Totals Preseason Priors (Week 0/1 Predictions)

**Problem:** Current totals model can't predict week 0/1 games because it trains only on same-season data. The walk-forward approach requires weeks 1-2 as training data before predicting week 3+. This leaves early-season totals bets without model signal.

**Solution: Prior-Year Carry-Forward with Decay**

1. **End-of-Season Snapshot**
   - After each season, save team-level offensive/defensive adjustments from final TotalsModel
   - Store as `data/totals_priors_{year}.json` (e.g., `totals_priors_2025.json` for 2026 predictions)
   - Include: team name, offensive adjustment, defensive adjustment, baseline PPG

2. **Regression to Mean**
   - Apply shrinkage to prior-year ratings (teams regress toward league average)
   - Suggested: 30-40% regression (similar to spreads priors decay)
   - Elite offenses won't stay elite forever; bad defenses improve via recruiting

3. **Blending Schedule**
   - Week 0-1: 100% prior-year ratings (no current-season data)
   - Week 2: 70% prior / 30% current (1 game of data)
   - Week 3: 50% prior / 50% current (2 games of data)
   - Week 4+: 30% prior / 70% current (enough data for Ridge to dominate)
   - By week 6+: Prior contribution negligible (current-season signal dominates)

4. **Roster Continuity Adjustment**
   - Teams with high portal churn get heavier regression to mean
   - Returning production % from CFBStats/CFBD could modulate prior weight
   - Similar to how spreads priors handle coaching changes

**Backtest Validation:**
- Modify `backtest_totals.py` to use 2024 priors for 2025 week 1-2 predictions
- Compare ATS performance with priors vs current "no prediction" approach
- Target: Any positive edge > 50% on week 0-2 totals justifies implementation

**Implementation:** `src/models/totals_priors.py`, `scripts/save_totals_priors.py`

### Parking Lot (Needs Evidence Before Implementation)
- [x] **Pace-based margin scaling** - Theory: Fast games have more plays, so efficiency edges should compound into larger margins. JP+ should scale predicted margins by expected pace. **Status:** INVESTIGATED, NOT IMPLEMENTING. Empirical analysis (2023-2025) shows the theory doesn't match reality: (1) Fast games actually have smaller margins (RÂ²=2.2% correlation), (2) JP+ over-predicts fast game margins (mean error -2.1), not under-predicts, (3) ATS is actually better in fast games (73% vs 67.6%). Vegas already prices pace. Efficiency metrics implicitly capture tempo. Adding pace scaling would add complexity without benefit.
- [x] **Mercy Rule Dampener (non-linear margins)** - Theory: Coaches tap brakes in blowouts, so efficiency models over-predict large margins. Apply logistic dampening to extreme spreads. **Status:** INVESTIGATED, NOT IMPLEMENTING. The bias EXISTS (mean error -38.7 on 21+ spreads), and dampening DOES improve MAE (-1.66 pts). BUT dampening HURTS ATS (-2.8pp) because our large edges against Vegas are correct directionally even when magnitude is off. A spread of -28 vs Vegas -21 may be "wrong" by 7 points but RIGHT about home covering. Since ATS is our optimization target (Rule #3), we accept worse MAE to maintain betting edge.
- [x] **Soft cap on asymmetric garbage time** - Concern: winning team can accumulate unlimited full-weight plays in blowouts, potentially inflating ratings. **Status:** INVESTIGATED, NOT IMPLEMENTING. Tested GT weight variants (leading=0.5, 0.7, symmetric) â€” ALL degraded 5+ Edge from 53.5% to 52.2-52.5%. Asymmetric GT (leading=1.0) generates real predictive signal; winner's GT plays ARE informative. Big 12 bubble (UCF, Baylor, Colorado over-rated) is conference circularity, not GT weighting.
- [x] **Reduce turnover weight to improve 3+ edge** - Turnovers help 5+ edge but slightly hurt 3+ edge. **Status:** INVESTIGATED, KEEPING 10%. The 3+/5+ Edge divergence pattern is documented across 3+ experiments (conf anchor, churn penalty, LASR). 5+ Edge (~2% over vig) is the binding constraint; 3+ Edge (~1.3% over vig) is secondary. Optimizing for 3+ Edge consistently degrades 5+ Edge. Current 10% is optimal.
- [ ] **Normalize coaching pedigree by prior team talent** - Career win % embeds opportunity (better jobs â†’ higher win %), not purely skill. Normalizing by talent level of teams coached would be more accurate. **Status:** Small sample size (~10-15 coaching changes/year) makes this hard to validate. Current neutral backtest impact suggests feature is already appropriately weighted.
- [x] **EV-weighted performance metric** - Current metrics (MAE, ATS %) treat all bets equally. **Status:** PARTIALLY IMPLEMENTED. CLV (Closing Line Value) tracking now integrated into backtest output. CLV measures how much value we capture before market closes â€” monotonically increasing at higher edge thresholds (+0.75 at 5+ edge). Full Kelly criterion sizing not implemented, but core "weight by betting value" concept is captured via edge threshold filtering (3+, 5+ pt edge buckets). Remaining: Kelly fraction calculations, bankroll simulation.

---

## References

### Methodology Inspiration
- **SP+ (Bill Connelly)** - Success Rate + Explosiveness foundation; JP+ naming is an homage to SP+
- FPI (ESPN) - Efficiency-based ratings
- Sagarin - Ridge regression approach

### Key Metrics
- **Success Rate:** % of plays achieving down-specific yardage thresholds
- **IsoPPP (Isolated Points Per Play):** EPA on successful plays only
- **EPA (Expected Points Added):** Point value added by each play

---

## Changelog

### February 2026
- **Totals Model (Over/Under Prediction)** - NEW production module for game totals prediction. Separate architecture from EFM: Ridge regression on game-level points scored/allowed (not play-level efficiency). Key innovation: HFA learned via Ridge column (+3.5 to +4.5 pts) rather than assumed fixed value â€” improved 5+ Edge by +1.6% (Close), +2.1% (Open). Configuration: alpha=10.0, decay=1.0, years 2023-2025 (2022 excluded as scoring transition year). Performance: Core 5+ Edge 54.5% (Close), 55.3% (Open); Full Season 5+ Edge 55.3% (Close), 55.6% (Open). Files: `src/models/totals_model.py`, `scripts/backtest_totals.py`.
- **HFA Global Offset Calibration (-0.50 pts)** - Error cohort analysis revealed +0.90 pts systematic home bias across 2,489 core games. Added `global_offset` parameter to `HomeFieldAdvantage` that subtracts a fixed amount from ALL team HFA values (floor=0.5). 6-variant sweep (0.0, 0.25, 0.375, 0.50, 0.75, 1.00): offset=0.50 optimal â€” 5+ Edge Close +0.6% (54.1%â†’54.7%), Open +0.5% (57.3%â†’57.8%), mean error halved from +0.90 to +0.46, MAE flat. First experiment where 3+ and 5+ Edge improve together without divergence. CLI: `--hfa-offset` (default 0.50). Also applied in `run_weekly.py` for production.
- **Conference Strength Anchor (OOC Weighting + Bayesian Anchors)** - Two-mechanism approach to reduce conference circularity: (1) 1.5x play weight for OOC FBS games in Ridge regression, (2) post-Ridge separate offensive and defensive Bayesian conference anchors using OOC scoring data. Parameters: anchor_scale=0.08, prior_games=30, max_adjustment=Â±2.0. A conference can now have positive offensive anchor but negative defensive anchor. 4-variant sweep tested (0.08, 0.12, 0.15, 0.20) â€” 0.08 preserved 5+ Edge best; larger scales improved 3+ Edge but degraded 5+ Edge (binding constraint).
- **Red Zone Leverage Weighting + Empty Yards Filter** - Play-level weighting in `_prepare_plays()`: inside-10=2.0x, inside-20=1.5x, empty yards zone (opp 40-20)=0.7x for successful plays that don't enter RZ. 5+ Edge +0.2%, MAE +0.02 (within tolerance). No outcome data â€” purely spatial signal.
- **X_base Sparse Matrix Caching** - Refactored EFM Ridge regression pipeline to precompute and cache the sparse design matrix (X_base) separately from sample weights. X_base encodes play structure only (team indicators + home field) and is independent of time decay, enabling reuse when only the eval_week changes. Time decay moved from `_prepare_plays()` to `_ridge_adjust_metric()` for dynamic per-week application. New `base_weight` column stores all non-temporal weights (GT Ã— OOC Ã— RZ Ã— empty_yards). Two-tier caching: X_base by play structure hash, results by (season, week, metric, alpha, time_decay, data_hash). Backtest output identical.
- **Week-Level Delta Cache for run_weekly.py** - Wired up the existing `WeekDataCache` infrastructure to `run_weekly.py` via `--use-delta-cache` flag. When enabled, historical weeks [1, week-2] are loaded from Parquet cache on disk and only the most recent completed week is fetched from the CFBD API. Graceful cold start: first run populates the cache; subsequent runs fetch 1 API week instead of N-1. Schema enforced via explicit Polars dtypes. Zero behavior change when flag is off.
- **Explosiveness Uplift: EFM Weights 54/36/10 â†’ 45/45/10** - Equal weighting of Success Rate and IsoPPP (Explosiveness) better captures boom-or-bust offensive teams. Previous 54/36 split over-weighted consistency vs big plays. Results: Core ATS (Close) improved 51.3% â†’ 52.4% (+1.1%), Core ATS (Open) improved 52.8% â†’ 54.0% (+1.2%). Core 5+ Edge (Open) 56.9%, CLV positive and monotonically increasing (+0.75 at 5+ edge). Core MAE +0.02 (12.49 â†’ 12.51, within strict tolerance). All six files updated: `efficiency_foundation_model.py`, `backtest.py`, `calibrate_situational.py`, `benchmark_backtest.py`, `compare_ratings.py`, and documentation.
- **P0 Audit Fixes (Postseason Chronology + EFM Robustness)** - Fixed 6 structural issues from code audit: (1) Postseason games now mapped to sequential pseudo-weeks by date instead of all lumped into week 16, preserving walk-forward chronology; (2) home_team validated via game join on game_id for reliable neutral-field ridge regression; (3) ATS unmatched mask uses vegas_spread.isna() instead of game_id.isna(); (4) EFM uses pd.notna() for home_team check with coverage logging; (5) Ridge cache hash strengthened with MD5 of team sequences + metric stats; (6) Unused imports removed. Performance tables refreshed with post-fix baseline: Core MAE 12.55, Core ATS 52.0%, Core 5+ Edge 53.2%.
- **Fixed Double-Damping Bug with Unified Environmental Stack** - Major fix to the adjustment aggregator. The previous four-bucket design applied smoothing to the physical bucket (100%/25%) and then soft cap on top, creating two layers of penalty that destroyed valid betting edges. The fix consolidates all environmental factors (HFA, travel, altitude, rest, consecutive_road) into a single stack with one soft cap layer: threshold 5.0 pts, excess weight 60%. Standard games (stack â‰¤5.0) get no dampening at allâ€”only extreme stacks are smoothed. Mental bucket (letdown, lookahead, sandwich) unchanged at 100%/50%/25%. Boosts bucket (rivalry) unchanged as linear sum. Performance restored to baseline: Core MAE 12.21, Core 5+ Edge 57.1%.
- **Consolidated All Adjustment Smoothing into AdjustmentAggregator** - Major architectural refactor to eliminate double-smoothing. All game adjustments (HFA, travel, altitude, rest, letdown, lookahead, sandwich, consecutive road, rivalry) now flow through a single aggregator. Global cap at Â±7.0 points. This replaces the previous separate smoothing in `smooth_correlated_stack()` and `SituationalFactors.__post_init__()`. New file: `src/adjustments/aggregator.py`.
- **Simplified SituationalFactors to Raw Container** - Removed all smoothing logic from SituationalFactors dataclass. It now stores raw adjustment values only. Added `get_matchup_factors()` method that returns raw factors for the aggregator. Legacy `get_matchup_adjustment()` retained for backward compatibility.
- **Added Consecutive Road Games Penalty** - Teams playing their second consecutive road game receive -1.5 pt penalty. Travel fatigue compoundsâ€”back-to-back away games exceed the sum of individual road trips. Implementation checks team's last played game (not necessarily previous week due to byes). Travel-consecutive correlation in aggregator reduces consecutive_road by 50% when travel > 1.5 pts.
- **Refactored Short Week to Non-Linear Penalty** - When one team is on short week (â‰¤5 days) and opponent is on normal/rested schedule (>6 days), a hardcoded -2.5 pt penalty applies instead of linear calculation. Short week disadvantage is severe and non-linearâ€”not just "2 fewer rest days." Linear rest calculation still applies for other scenarios (bye vs bye, mini-bye vs normal, etc.).
- **Added Letdown Persistence Through Bye Weeks** - Letdown spot now persists through bye weeks by finding the team's *last played game* regardless of which week it occurred. If a team has a big win followed by a bye, they still get letdown penalty in their next game. Added 3-week staleness thresholdâ€”after 3+ weeks since the big win, the emotional effect has faded and letdown doesn't trigger.
- **Season Opener Gets Maximum Rest** - Teams playing their first game of the season now get 14 days rest (maximum) instead of 7 days. This correctly models that a fresh team facing a Week 0 opponent has a rest advantage.
- **Integrated The Odds API for Betting Lines** - Added dual-source approach for betting line data: CFBD API for historical data (2022-2025, 91% FBS opening line coverage), The Odds API for future seasons (2026+). Created `src/api/odds_api_client.py` for API access, `src/api/betting_lines.py` for unified data merging, `scripts/capture_odds.py` for backfill/one-time captures, and `scripts/weekly_odds_capture.py` for scheduled weekly captures (opening lines Sunday, closing lines Saturday). Data stored in SQLite at `data/odds_api_lines.db`. Cost: 2 credits/week for ongoing captures. Note: Historical backfill requires paid Odds API plan; free tier (500 credits/month) supports current odds only.
- **Added 2022-2025 Backtest Performance Section** - Comprehensive walk-forward backtest results across 4 seasons (3,273 games total, 2,485 Core weeks 4-15). Key findings: Core MAE 12.55, ATS 52.0% vs closing lines. At 5+ point edge: 53.2% vs closing, 57.0% vs opening. Opening line performance significantly exceeds closing line, indicating model captures value that the market prices out by game time. Results broken down by year show consistent improvement in MAE (12.87â†’12.21) and stable ATS performance. Added P3.4 sanity report infrastructure for data and prediction validation.
- **Implemented Correlated Stack Smoothing** - Fixed systematic over-prediction in high-stack games (HFA + travel + altitude combined). Analysis of 2024-2025 data revealed games with >5 pts combined adjustment over-predicted home team margins by ~2.3 pts. The fix applies two mechanisms: (1) **Altitude-travel interaction**: When travel > 1.5 pts AND altitude > 0, reduce altitude by 30% to account for partial overlap between effects; (2) **Soft cap**: When combined stack exceeds 5 pts, reduce excess by 50% and distribute reduction proportionally across all three components. Example: stack of 7 â†’ 5 + (7-5)Ã—0.5 = 6 effective. Results: max stack reduced from 6.41 to 5.71 pts, error-per-stack-point reduced from 0.94 to 0.88. Added `smooth_correlated_stack()` function to `spread_generator.py` with parameters `smooth_stacks`, `stack_cap_start`, `stack_cap_factor`, `altitude_travel_interaction`. Enabled by default.
- **Added Distance-Based Timezone Penalty Dampening** - Fixed over-aggressive timezone penalty for short-distance regional games. Analysis showed 500-800mi games crossing timezone lines (due to DST quirks or CT/ET border) had +3.83 mean error vs -0.87 for no-TZ games. The fix: (1) **<400 miles**: TZ penalty eliminated entirely (truly regional games like Illinois @ Purdue); (2) **400-700 miles**: TZ penalty reduced by 50% (e.g., Arizona @ Colorado at 623mi now gets 0.25 pts instead of 0.50); (3) **>700 miles**: Full TZ penalty (true cross-country travel). This ensures timezone effects are only applied when there's meaningful travel fatigue. Updated `get_total_travel_adjustment()` in `travel.py`.
- **Expanded Special Teams to Full PBTA Model** - Complete overhaul of special teams from FG-only to comprehensive FG + Punt + Kickoff model. All components now expressed as PBTA (Points Better Than Average) - the marginal point contribution per game compared to a league-average unit. Key changes: (1) Added `YARDS_TO_POINTS = 0.04` constant for field position value conversion, (2) Punt rating now converts net yards above expected (40 yds) to points + inside-20 bonus (+0.5 pts) + touchback penalty (-0.3 pts), (3) Kickoff rating combines coverage (touchback rate, return yards allowed) and returns (return yards gained), all converted to points, (4) Overall ST = simple sum of components (no weighting needed since all in points). FBS distribution: mean ~0, std ~1.0, 95% range [-2, +2] pts/game. Top 2024 ST unit: Vanderbilt (+2.34 pts/game), worst: UTEP (-2.83 pts/game). Added `calculate_punt_ratings_from_plays()`, `calculate_kickoff_ratings_from_plays()`, and `calculate_all_st_ratings_from_plays()` to `src/models/special_teams.py`.
- **Implemented Neutral-Field Ridge Regression (MAJOR FIX)** - Fixed systematic -6.7 mean error caused by double-counting home field advantage. The issue: CFBD EPA data implicitly contains HFA (home teams naturally generate better EPA), so ridge regression learned team coefficients with HFA baked in. When SpreadGenerator added explicit HFA, this caused double-counting. The fix: Add a home field indicator column to the ridge regression design matrix (+1 for offense=home, -1 for offense=away, 0 for neutral). This separates true team strength from implicit HFA. The learned implicit HFA is ~0.006 SR (~0.6% success rate advantage) and ~0.02 IsoPPP (~0.8 pts combined)â€”much smaller than explicit HFA (~2.5 pts), confirming most HFA manifests at scoring/outcome level rather than play-level efficiency. Results: Mean error improved from -6.7 to -0.40 (2024) and +0.51 (2022-2024), a 94% reduction in systematic bias. ATS performance maintained at 50.9% overall, 56.2% at 5+ edge.
- **Added Weather Adjustment Module** - New `WeatherAdjuster` class for totals prediction. Fetches weather data from CFBD API (`get_weather` endpoint) and calculates adjustments based on wind speed (>10 mph: -0.3 pts/mph, capped at -6.0), temperature (<40Â°F: -0.15 pts/degree, capped at -4.0), and precipitation (>0.02 in: -3.0 pts, >0.05 in: -5.0 pts). Indoor games (`game_indoors=True`) receive no adjustment. Added `get_weather()` method to `CFBDClient`. Weather data includes temperature, wind speed/direction, precipitation, snowfall, humidity, and weather condition text. Analysis of 2024 late-season games showed: 19/757 indoor games, temperatures ranging 16Â°F-86Â°F, wind up to 26 mph, 39 games with precipitation.
- **Added FPI Ratings Comparison** - New `scripts/compare_ratings.py` for 3-way JP+ vs FPI vs SP+ validation. Added `get_fpi_ratings()` and fixed `get_sp_ratings()` in CFBD client to use correct `RatingsApi` endpoint. Initial 2025 comparison shows JP+ correlates r=0.956 with FPI, r=0.937 with SP+. Key divergence: JP+ ranks Ohio State #1, Indiana #2; FPI/SP+ have Indiana #1.
- **Fixed Sign Convention Bugs** - Complete audit found 2 bugs: (1) `spread_generator.py:386` had `home_is_favorite = prelim_spread < 0` (wrong, should be `> 0`), causing rivalry boost to be applied to favorites instead of underdogs; (2) `html_report.py:250` had inverted CSS class logic. Backtest comparison: 3+ edge ATS improved from 53.3% to **54.0%** (+0.7%, +8 net wins). MAE improved from 12.39 to 12.37. Documented sign conventions in SESSION_LOG Rules section.
- **Investigated Mercy Rule Dampener (NOT implemented)** - Theory: coaches tap brakes in blowouts, so apply non-linear dampening to extreme spreads. Finding: Bias exists (-38.7 mean error on 21+ spreads) and dampening improves MAE (-1.66), BUT hurts ATS (-2.8pp). Our large edges are correct directionally even when magnitude is off. Decision: Accept worse MAE to maintain betting edge.
- **Investigated Pace-Based Margin Scaling (NOT implemented)** - Theory suggested fast games should have larger margins (more plays to compound efficiency edge). Empirical analysis showed opposite: fast games have smaller margins (RÂ²=2.2%), JP+ over-predicts (not under-predicts) fast games, and ATS is actually better in fast games (73% vs 67.6%). Vegas already prices pace. Decision: Do not implement.
- **Documented Mean Error vs ATS Trade-off** - Investigated -6.7 mean error. Root cause: CFBD EPA data implicitly contains home field advantage, causing double-counting with explicit HFA. **UPDATE:** This issue was FIXED in February 2026 via neutral-field ridge regression (see above). Mean error is now ~0.
- **Updated 2025 Top 25 with Full CFP Data** - Top 25 now includes all 46 postseason games and 6,223 playoff plays. Indiana (#2, National Champions) beat Alabama 38-3, Oregon 56-22, and Miami 27-21 in CFP.
- **Added Rules & Conventions to SESSION_LOG** - Critical rules: (1) Top 25 must use end-of-season + playoffs, (2) ATS from walk-forward only, (3) optimize for ATS not mean error, (4) parameters flow through config, (5) sign conventions documented.
- **Added Asymmetric Regression for Preseason Priors** - Fixed spread compression problem for blowout games. Standard regression pulled ALL teams toward mean uniformly, causing bad teams (Kent State -25) to gain 7.5 pts they didn't earn. Now regression scales by distance from mean: teams within Â±8 pts get normal 30% regression, teams 20+ pts from mean get only 10% regression. Additionally, talent weight is halved (40%â†’20%) for extreme teams to trust proven performance over talent projections. Result: rating spread preserved at 90% vs 70% before.
- **Added Triple-Option Team Adjustment** - Fixed systematic underrating of triple-option teams (Navy, Army, Air Force, Kennesaw State). These teams were showing as underdogs when Vegas had them as favorites because: (1) SP+ efficiency metrics don't capture their scheme's value, (2) service academies have artificially low recruiting rankings. Applied +6 pt boost to raw SP+ ratings and 100% prior weight (no talent blend). Result: 2024 early season ATS improved from 49.5% to 51.1%.
- **Added QB Injury Adjustment System** - Manual flagging system for starter injuries. Pre-computes depth charts from CFBD player PPA data, calculates starter/backup differential, applies adjustment = PPA_drop Ã— 30 plays/game. Usage: `--qb-out TEAM` CLI flag. Example adjustments: Georgia -6.8 pts, Ohio State -10.0 pts, Texas +8.0 pts (Arch Manning backup is better).
- **Added Time Decay Parameter (but NOT used)** - Tested time decay (weighting recent games more) in 2D sweep with alpha. Finding: decay consistently hurts performance across all alpha values. Best config is alpha=50, decay=1.0 (no decay). Walk-forward already ensures temporal validity. Parameter added but defaults to 1.0.
- **Tested Havoc Rate (NOT implemented)** - Investigated replacing turnovers with Havoc Rate (TFLs, sacks, PBUs). Finding: Havoc correlates with turnovers forced (r=0.425) but neither provides ATS edgeâ€”Vegas already prices both. Kept current turnover approach.
- **Tested Style Mismatch Adjustment (NOT implemented)** - Tested rush/pass style profiles for matchup advantages. Finding: Made predictions worse (ATS -0.2pp, MAE +0.09). Vegas already prices style matchups efficiently.
- **Added Turnover Margin Component (10%)** - JP+ now includes per-game turnover margin as 10% of the overall rating, matching SP+'s approach. Turnovers are identified from play-by-play data (interceptions, fumble recoveries) and converted to point value using 4.5 points per turnover. The efficiency and explosiveness weights were adjusted from 60/40 to 54/36 to accommodate the new component. (Later rebalanced to 45/45/10 via Explosiveness Uplift.) **Bayesian shrinkage** (prior_strength=10) regresses turnover margin toward 0 based on games played, preventing overweighting of small-sample luck while trusting sustained performance. This captures teams like Indiana (+15 margin) and Notre Dame (+17 margin) who create systematic turnover advantages that pure efficiency metrics miss.
- **Reduced Red Zone Regression Strength (20â†’10)** - The prior_strength for RZ TD rate regression was reduced from 20 to 10 to better credit elite RZ teams at end of season. Impact: 5+ edge ATS improved from 54.8% to 55.3%.
- **Added FBS-Only Filtering** - Ridge regression training data now excludes plays involving FCS opponents. FCS teams have insufficient games against FBS opponents to estimate reliable coefficients, so including them pollutes the regression. FCS games are handled separately via the FCS Penalty (+24 pts). Impact: 5+ pt edge improved from 54.0% â†’ 54.8% (+0.8%). This is the cleanest data pipeline for opponent adjustment.
- **Validated Asymmetric Garbage Time** - After implementing FBS-only filtering, re-tested symmetric vs asymmetric GT. Asymmetric remains superior: 5+ edge 54.8% vs 53.0% for symmetric. Asymmetric GT also improves Indiana's ranking (#4 â†’ #2), properly crediting teams that maintain efficiency in blowouts.

### January 2026
- **Added Transfer Portal Integration** - Preseason priors now incorporate net transfer portal impact on rosters. Fetches portal entries from CFBD API, matches transfers to prior-year player usage (PPA), and calculates net incoming - outgoing production for each team. The portal adjustment modifies effective returning production with `portal_scale=0.15` and caps at Â±15%. This addresses the gap where returning production only captured players who stayed, not incoming transfers. Impact: 5+ pt edge improved from 53.3% â†’ 53.7% (+0.4%). Added `fetch_transfer_portal()`, `fetch_player_usage()`, `calculate_portal_impact()` to `preseason_priors.py`. New CLI flags: `--no-portal`, `--portal-scale`.
- **Tuned efficiency/explosiveness weights from 65/35 to 60/40** - Comparison with SP+ identified that explosive teams (Ole Miss, Texas Tech) were being underrated with 35% explosiveness weight. Tested weight configurations across 2022-2025: 60/40 showed best multi-year performance (MAE 12.63, ATS 51.3%, 5+ edge 54.5%). This better captures big-play ability while maintaining efficiency as the dominant signal.
- **Exposed separate O/D/ST ratings** - EFM now calculates and exposes separate offensive, defensive, and special teams ratings. The `TeamEFMRating` dataclass includes `offensive_rating`, `defensive_rating`, and `special_teams_rating` fields. New methods: `get_offensive_rating()`, `get_defensive_rating()`, `get_special_teams_rating()`, `set_special_teams_rating()`. The `get_ratings_df()` output now includes offense, defense, and special_teams columns. This enables future game totals prediction by predicting each team's expected points scored.
- **Added FG Efficiency Adjustment** - Integrated field goal Points Above Average Expected (PAAE) into spread predictions. Calculates each team's kicking efficiency vs expected make rates by distance (<30yd: 92%, 30-40: 83%, 40-50: 72%, 50-55: 55%, 55+: 30%). The FG differential is applied as an adjustment to the spread. Impact: ATS improved from 50.6% â†’ 51.2% (+0.6%), MAE improved from 12.57 â†’ 12.47 (-0.10). Added `calculate_fg_ratings_from_plays()` and `get_fg_differential()` to `src/models/special_teams.py`.
- **Added FCS Penalty (+24 pts)** - When FBS teams play FCS opponents, add 24 points to the FBS team's predicted margin. Diagnostic analysis revealed JP+ was under-predicting blowouts by 26 points (99.5% of errors were under-predictions). The penalty directly addresses this: MAE improved from 13.11 â†’ 12.57 (-0.54 pts), 5+ edge ATS improved to 53.2%. Only affects ~3% of games (FCS matchups).
- **Named the overall model JP+** (homage to SP+); EFM remains the core engine
- **Added Returning Production adjustment** - Prior year ratings now regressed based on % of PPA returning. High returning production = less regression, low returning = more regression. Improved ATS from 51.0% to 51.3%.
- **Implemented team-specific HFA** - Replaced flat 2.5 pt HFA with curated team-specific values (1.5-4.0 range) based on stadium environment. Elite venues like LSU (4.0) get more credit; weak environments like UMass (1.5) get less. Conference defaults used for unlisted teams.
- **Added HFA trajectory modifier** - Dynamic adjustment (Â±0.5 pts) for rising/declining programs. Compares recent win % (1 year) to baseline (prior 3 years). Rising programs like Vanderbilt and Indiana get HFA boost; declining programs get penalty. Captures that home field advantage evolves with program trajectory.
- **Added Coaching Change Regression** - When a new HC arrives at an underperforming team, JP+ dampens prior year drag and weights talent more heavily. Uses data-driven coach pedigree scores (calculated from career win %, P5 experience) to determine how much to "forget" prior underperformance. Elite coaches (Kiffin, Cignetti, Sumrall) at talent-rich programs can see +2 to +4 point rating boosts. First-time HCs receive neutral treatment (no prediction, no penalty).
- Created Efficiency Foundation Model (EFM) as the core engine
- Added garbage time filtering (down-weight blowout plays)
- Fixed double-counting issues in adjustment layer
- Comprehensive documentation created
- **Added Red Zone regression (Finishing Drives)** - Implemented Bayesian regression for red zone TD rate toward league mean (58%). Uses prior_strength=10 to pull extreme rates toward average while trusting actual performance. Multi-year validation showed consistent improvement: MAE improved 0.04-0.10 pts and ATS improved 1-2% across all four years (2022-2025). This is now part of the EFM pipeline.
- **Reduced Red Zone regression strength (prior_strength 20â†’10)** - Analysis showed the original prior_strength=20 was too aggressive for end-of-season ratings. With 150+ RZ plays per team, elite RZ performance (like Indiana's 87% TD rate) is a genuine skill, not luck. Reducing to 10 better credits teams that sustain elite RZ efficiency over a full season. This fixed an issue where regression was flipping Indiana's RZ advantage over Ohio State.

### Explored but Not Included
- **OOC Credibility Weighting (Rejection #12)** - Hypothesis: weight intra-conference plays by opponent's OOC exposure density to improve relative ordering within G5 conferences. Implementation: Z = ooc_games / league_avg, multiplier `1.0 + scale*(Z-1.0)` for intra-conf plays. 5-variant sweep (0.0, 0.25, 0.50, 0.75, 1.0): monotonic 5+ Edge degradation 54.7%â†’54.1%. Root cause: G5 circularity is variance-driven (<0.5% bias), so no play-level weight geometry change helps. Infrastructure preserved (default 0.0 = disabled).
- **Penalty Discipline PPA (Rejection #11)** - Hypothesis: penalty yards per play is a persistent coaching signal not captured by SR/IsoPPP. 3 variants tested (0.5/1.0/2.0 pts per stddev of penalty rate). All degraded 5+ Edge by 0.5-0.9%. Failure mode: market-visible signal â€” penalties are in every box score, so novel to model but not novel to market.
- **LASR Money Down Weighting (Rejection #10)** - Hypothesis: 3rd/4th down plays are more revealing of team quality. Weight multiplier for conversion situations. 5+ Edge degraded -0.7%. Failure mode: sub-metric redundancy â€” success rate already captures conversion efficiency.
- **Roster Churn Penalty (Rejection #9)** - Portal churn percentage as early-season penalty. 3+ Edge improved but 5+ Edge degraded -0.4%. Classic 3+/5+ divergence pattern.
- **Defensive Weight Split (Rejection #7)** - Hypothesis: defense controls SR more than IsoPPP, so shift defensive weighting toward SR. 3 variants (55/35, 60/30, 65/25): all degraded 5+ Edge monotonically. Surprise finding: defensive IsoPPP IS predictive â€” preventing big plays is a persistent trait.
- **MOV Calibration (Rejection #2)** - 4 weights (0.05-0.20) tested. All degraded 5+ Edge. MOV makes model more like market, reducing edge. The model's value is efficiency insights the market doesn't capture.
- **Finishing Drives (Rejections #1, 4 variants)** - Post-hoc sub-model with 70-80% signal overlap with EFM's IsoPPP. Not opponent-adjusted. Games with highest FD contribution had worst MAE. Shelved; RZ efficiency integrated as EFM Ridge feature instead.
- **Time Decay / Recency Weighting** - Full 5Ã—5 grid sweep: 5 alphas Ã— 5 decays (1.0 to 0.92). No decay (1.0) was best across ALL alpha values. Walk-forward already ensures temporal validity; early data provides opponent graph calibration.
- **Defense Full-Weight Garbage Time** - Hypothesis: when a team is winning by 17+ in Q4, their defense should get full weight (1.0) instead of asymmetric weighting (where trailing offense gets 0.1x). This would give defensive dominance full credit in blowouts. Implementation added `defense_full_weight_gt` parameter with separate O/D regression weights. Results: Rankings improved for teams like Indiana (#4â†’#2), Georgia (#9â†’#8), Ole Miss (#14â†’#12), which matched better with consensus rankings. BUT 5+ edge ATS regressed from 57.3% to 56.5% (-0.8%). Decision: **REJECTED**. The "right" rankings hurt predictive accuracy. Current asymmetric GT appears correctly calibratedâ€”giving defense extra credit in garbage time may overcredit "prevent defense" situations that don't reflect true skill. ATS is our optimization target (Rule #4), so we keep standard asymmetric weighting.
- **Dynamic Ridge Alpha** - Hypothesis: use higher regularization (alpha=75) early season when data is noisy, lower (alpha=35) late season to let elite teams separate more. Results: Dynamic alpha (75â†’50â†’35 by week) produced same MAE but hurt 5+ edge ATS from 56.4% to 55.7% (-0.7%). Decision: **REJECTED**. Walk-forward backtesting already self-regularizes via sample size. Lower alpha late-season benefits ALL teams equally, not just elite ones.
- **Increased Turnover Shrinkage** - Hypothesis: turnovers are ~50-70% luck, so prior_strength=10 may over-credit turnover margin. Tested prior_strength 5/10/20/30. Results: prior_strength=10 is optimal for 5+ edge (56.4%). Higher shrinkage (20-30) slightly improved 3+ edge but hurt high-conviction bets. Decision: **KEEP current** prior_strength=10.
- **Turnover-Worthy Plays (TWP) proxy** - Built model using pass breakups and sacks as proxies for interceptable passes and fumble-worthy plays. Multi-year validation showed inconsistent results (helped 2023/2025, hurt 2024). Removed to avoid overfitting.
- **Field Position Component** - Investigated adding field position as JP+ component (SP+ uses 10% weight). Data source: CFBD DrivesApi provides start_yardline. **Problem:** Raw field position is heavily confounded by scheduleâ€”good teams have WORSE raw FP (r = -0.56 with SP+) because they face better punters/coverage and score more TDs (receiving kickoffs at own 25). Even after ridge regression opponent adjustment, correlation remains negative (r = -0.63). Tried cleaner "Return Game Rating" using punt/kick return yards: weak correlation with team quality (r = +0.20) and very weak correlation with overperformance (r = +0.06). Top 30 return teams overperformed by only +5.3 ranks on average. Decision: **TABLED**. Signal too weak to justify complexity. May revisit with proper ATS backtest.

<!-- Last validated: 2026-02-14 by generate_docs.py -->
